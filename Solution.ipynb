{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this notebook we'll try to solve quite a challenging task. Using Blog Authorship Corpus which consists of the collected posts of 19,320 bloggers we'll try using solely text of this posts predict the gender, age, zodiac sign and industry of post author. For this I propose to use SentenceTransformers embeddings generated by Siamese BERT-Networks and classifier which is a small Neural Network with two linear layers. Starting with gender prediction model, which I consider the easiest one due to it's binary nature and nice almost ideal balance of classes, I'll proceed to more complex models trying to solve multiclass prediction problems for balanced and non-balanced classes. To speed up computation I'll use GPU, but if GPU is not available on your machine it will automatically compute everything on CPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content\n",
    "\n",
    "1. [EDA](#EDA)\n",
    "2. [Gender model](#Gender-model)\n",
    "3. [Sign mdoel](#Sign-model)\n",
    "4. [Age model](#Age-model)\n",
    "5. [Topic model](#Topic-model)\n",
    "6. [Summary and alternative approaches](#Summary-and-alternative-approaches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "pd.options.mode.chained_assignment = None\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define device (GPU if available, othervise CPU) and logger for Pytorch Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CometLogger will be initialized in offline mode\n"
     ]
    }
   ],
   "source": [
    "comet_logger = pl_loggers.CometLogger(save_dir='logs/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>14,May,2004</td>\n",
       "      <td>Info has been found (+/- 100 pages,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>13,May,2004</td>\n",
       "      <td>These are the team members:   Drewe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>In het kader van kernfusie op aarde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>testing!!!  testing!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>11,June,2004</td>\n",
       "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id gender  age              topic      sign          date  \\\n",
       "0  2059027   male   15            Student       Leo   14,May,2004   \n",
       "1  2059027   male   15            Student       Leo   13,May,2004   \n",
       "2  2059027   male   15            Student       Leo   12,May,2004   \n",
       "3  2059027   male   15            Student       Leo   12,May,2004   \n",
       "4  3581210   male   33  InvestmentBanking  Aquarius  11,June,2004   \n",
       "\n",
       "                                                text  \n",
       "0             Info has been found (+/- 100 pages,...  \n",
       "1             These are the team members:   Drewe...  \n",
       "2             In het kader van kernfusie op aarde...  \n",
       "3                   testing!!!  testing!!!            \n",
       "4               Thanks to Yahoo!'s Toolbar I can ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/blogtext.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA\n",
    "\n",
    "There are few important things to be noticed during Exploratory Data Analysis in this case. First of all gender and sign are well balanced (classes almost equally distributed). Conversely, age and topic are not-balanced. Text length rarely exceeds threshold of 512 words, which is a cut-off value for BERT. There are records with empty posts. Numerous records have no topic specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(681284, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id         int64\n",
       "gender    object\n",
       "age        int64\n",
       "topic     object\n",
       "sign      object\n",
       "date      object\n",
       "text      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id        0\n",
       "gender    0\n",
       "age       0\n",
       "topic     0\n",
       "sign      0\n",
       "date      0\n",
       "text      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id', 19320),\n",
       " ('gender', 2),\n",
       " ('age', 26),\n",
       " ('topic', 40),\n",
       " ('sign', 12),\n",
       " ('date', 2616),\n",
       " ('text', 611652)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(x, len(df[x].unique())) for x in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_len'] = df.text.apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize = (15, 6))\n",
    "sns.countplot(x = df.gender, ax = ax[0][0])\n",
    "sns.countplot(x = df.age, ax = ax[0][1])\n",
    "sns.countplot(x = df.sign, ax = ax[1][0])\n",
    "sns.distplot(a = df.text_len, ax = ax[1][1])\n",
    "ax[1][0].set_xticklabels(ax[1][0].get_xticklabels(), rotation = 90)\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    681284.000000\n",
       "mean        200.786742\n",
       "std         415.160622\n",
       "min           0.000000\n",
       "50%         112.000000\n",
       "85%         370.000000\n",
       "90%         470.000000\n",
       "95%         663.000000\n",
       "99%        1257.000000\n",
       "max      131169.000000\n",
       "Name: text_len, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text_len.describe([.85, .9, .95, .99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3119, 8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.text_len == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "indUnk                     251015\n",
       "Student                    153903\n",
       "Technology                  42055\n",
       "Arts                        32449\n",
       "Education                   29633\n",
       "Communications-Media        20140\n",
       "Internet                    16006\n",
       "Non-Profit                  14700\n",
       "Engineering                 11653\n",
       "Law                          9040\n",
       "Publishing                   7753\n",
       "Science                      7269\n",
       "Government                   6907\n",
       "Consulting                   5862\n",
       "Religion                     5235\n",
       "Fashion                      4851\n",
       "Marketing                    4769\n",
       "Advertising                  4676\n",
       "BusinessServices             4500\n",
       "Banking                      4049\n",
       "Chemicals                    3928\n",
       "Telecommunications           3891\n",
       "Accounting                   3832\n",
       "Military                     3128\n",
       "Museums-Libraries            3096\n",
       "Sports-Recreation            3038\n",
       "HumanResources               3010\n",
       "RealEstate                   2870\n",
       "Transportation               2326\n",
       "Manufacturing                2272\n",
       "Biotech                      2234\n",
       "Tourism                      1942\n",
       "LawEnforcement-Security      1878\n",
       "Architecture                 1638\n",
       "InvestmentBanking            1292\n",
       "Automotive                   1244\n",
       "Agriculture                  1235\n",
       "Construction                 1093\n",
       "Environment                   592\n",
       "Maritime                      280\n",
       "Name: topic, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.topic.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.groupby('age').text_len.mean().plot(kind = 'bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEyCAYAAAABVZAhAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAiJElEQVR4nO3deZxkVX338c93hlUQwYeGoCwDBvQhIANMEAUJEU2QEFCjIG5o0JEIJkQTRRO3PCbuBreggyAQdRQdEYyYiEQBNQI9gMwgoIAQIAM0YADFbeD7/HFuMTVN9fRS91Z3Xb7v16teXffU8ju91K/PPfcssk1ERLTLvNmuQERE1C/JPSKihZLcIyJaKMk9IqKFktwjIlpovdmuAMCWW27pBQsWzHY1IiKGyvLly++yPdLrsTmR3BcsWMDo6OhsVyMiYqhIunmix9ItExHRQknuEREtlOQeEdFCSe4RES2U5B4R0UJJ7hERLZTkHhHRQknuEREtlOQeEdFCc2KG6rosOPHrM3rdTe/9k5prEsMgfy8RRVruEREtlOQeEdFCSe4RES005/vc267tfcRt//4i5qq03CMiWigt94iIARj0WWxa7hERLTRpy13SdsCZwNaAgSW2PyLp8cAXgQXATcARtn8mScBHgEOAB4BX2r68merHdKUPPOLRYSot99XAG23vCuwLHCdpV+BE4ALbOwMXVMcAzwV2rm6LgZNrr3VERKzTpC1326uAVdX9+yVdAzwROBw4sHraGcB3gDdX5WfaNvADSZtL2qZ6n4gYIjM508tZ3twwrT53SQuAPYFLgK27EvbtlG4bKIn/lq6X3VqVjX+vxZJGJY2OjY1Nt94REbEOU07ukjYFlgEn2L6v+7Gqle7pBLa9xPYi24tGRkam89KIiJjElIZCSlqfktg/Z/srVfEdne4WSdsAd1bltwHbdb1826osonVygTrmqklb7tXol1OBa2x/uOuhc4Gjq/tHA+d0lb9Cxb7Avelvj4gYrKm03PcDXg6skHRlVfZW4L3AWZKOAW4GjqgeO48yDPJ6ylDIV9VZ4YiImNxURst8F9AEDx/U4/kGjuuzXhERjWp7l1qWH4gYIm1PSFGfLD8QEdFCSe4RES2U5B4R0ULpc4+IOSHXE+qVlntERAsluUdEtFCSe0REC6XPfZz0+0VEG6TlHhHRQknuEREtlOQeEdFCSe4RES2U5B4R0UJJ7hERLZTkHhHRQlPZZu80SXdKWtlV9kVJV1a3mzo7NElaIOmXXY99ssG6R0TEBKYyiel04OPAmZ0C20d27kv6EHBv1/NvsL2wpvpFRMQMTGWbvYskLej1WLV59hHAs2quV0RE9KHfPvdnAnfY/klX2Y6SrpB0oaRnTvRCSYsljUoaHRsb67MaERHRrd/kfhSwtOt4FbC97T2BNwCfl7RZrxfaXmJ7ke1FIyMjfVYjIiK6zTi5S1oPeAHwxU6Z7V/bvru6vxy4Adil30pGRMT09NNyfzZwre1bOwWSRiTNr+7vBOwM3NhfFSMiYrqmMhRyKfBfwJMl3SrpmOqhF7N2lwzAAcBV1dDILwPH2r6nxvpGRMQUTGW0zFETlL+yR9kyYFn/1YqIiH5khmpERAsluUdEtFCSe0RECyW5R0S0UJJ7REQLJblHRLRQkntERAsluUdEtFCSe0RECyW5R0S0UJJ7REQLJblHRLRQkntERAsluUdEtFCSe0REC01ls47TJN0paWVX2Tsl3Sbpyup2SNdjb5F0vaTrJP1xUxWPiIiJTaXlfjpwcI/yf7a9sLqdByBpV8oOTb9XveZfOtvuRUTE4Eya3G1fBEx1q7zDgS9UG2X/FLge2KeP+kVExAz00+d+vKSrqm6bLaqyJwK3dD3n1qrsESQtljQqaXRsbKyPakRExHgzTe4nA08CFgKrgA9N9w1sL7G9yPaikZGRGVYjIiJ6mVFyt32H7QdtPwScwpqul9uA7bqeum1VFhERAzSj5C5pm67D5wOdkTTnAi+WtKGkHYGdgUv7q2JEREzXepM9QdJS4EBgS0m3Au8ADpS0EDBwE/BaANtXSzoL+BGwGjjO9oON1DwiIiY0aXK3fVSP4lPX8fx/BP6xn0pFRER/MkM1IqKFktwjIlooyT0iooWS3CMiWijJPSKihZLcIyJaKMk9IqKFktwjIlooyT0iooWS3CMiWijJPSKihZLcIyJaKMk9IqKFktwjIlooyT0iooWS3CMiWmjS5C7pNEl3SlrZVfYBSddKukrS2ZI2r8oXSPqlpCur2ycbrHtERExgKi3304GDx5WdD+xm+6nAj4G3dD12g+2F1e3YeqoZERHTMWlyt30RcM+4sm/aXl0d/gDYtoG6RUTEDNXR5/7nwDe6jneUdIWkCyU9c6IXSVosaVTS6NjYWA3ViIiIjr6Su6S/A1YDn6uKVgHb294TeAPweUmb9Xqt7SW2F9leNDIy0k81IiJinBknd0mvBA4FXmrbALZ/bfvu6v5y4AZglxrqGRER0zCj5C7pYOBNwGG2H+gqH5E0v7q/E7AzcGMdFY2IiKlbb7InSFoKHAhsKelW4B2U0TEbAudLAvhBNTLmAOAfJP0WeAg41vY9Pd84IiIaM2lyt31Uj+JTJ3juMmBZv5WKiIj+ZIZqREQLJblHRLRQkntERAsluUdEtFCSe0RECyW5R0S0UJJ7REQLJblHRLRQkntERAsluUdEtFCSe0RECyW5R0S0UJJ7REQLJblHRLRQkntERAtNKblLOk3SnZJWdpU9XtL5kn5Sfd2iKpekj0q6XtJVkvZqqvIREdHbVFvupwMHjys7EbjA9s7ABdUxwHMp2+vtDCwGTu6/mhERMR1TSu62LwLGb5d3OHBGdf8M4Hld5We6+AGwuaRtaqhrRERMUT997lvbXlXdvx3Yurr/ROCWrufdWpWtRdJiSaOSRsfGxvqoRkREjFfLBVXbBjzN1yyxvcj2opGRkTqqERERlX6S+x2d7pbq651V+W3Adl3P27Yqi4iIAeknuZ8LHF3dPxo4p6v8FdWomX2Be7u6byIiYgDWm8qTJC0FDgS2lHQr8A7gvcBZko4BbgaOqJ5+HnAIcD3wAPCqmuscERGTmFJyt33UBA8d1OO5Bo7rp1IREdGfzFCNiGihJPeIiBZKco+IaKEk94iIFkpyj4hooST3iIgWSnKPiGihJPeIiBZKco+IaKEk94iIFkpyj4hooST3iIgWSnKPiGihJPeIiBZKco+IaKEprefei6QnA1/sKtoJeDuwOfAaoLPr9VttnzfTOBERMX0zTu62rwMWAkiaT9kn9WzKzkv/bPuDdVQwIiKmr65umYOAG2zfXNP7RUREH+pK7i8GlnYdHy/pKkmnSdqi1wskLZY0Kml0bGys11MiImKG+k7ukjYADgO+VBWdDDyJ0mWzCvhQr9fZXmJ7ke1FIyMj/VYjIiK61NFyfy5wue07AGzfYftB2w8BpwD71BAjIiKmoY7kfhRdXTKStul67PnAyhpiRETENMx4tAyApE2A5wCv7Sp+v6SFgIGbxj0WERED0Fdyt/0L4P+MK3t5XzWKiIi+ZYZqREQLJblHRLRQkntERAsluUdEtFCSe0RECyW5R0S0UJJ7REQLJblHRLRQkntERAsluUdEtFCSe0RECyW5R0S0UJJ7REQLJblHRLRQkntERAsluUdEtFBfm3UASLoJuB94EFhte5GkxwNfBBZQdmM6wvbP+o0VERFTU1fL/Q9tL7S9qDo+EbjA9s7ABdVxREQMSFPdMocDZ1T3zwCe11CciIjooY7kbuCbkpZLWlyVbW17VXX/dmDr8S+StFjSqKTRsbGxGqoREREdffe5A/vbvk3SVsD5kq7tftC2JXn8i2wvAZYALFq06BGPR0TEzPXdcrd9W/X1TuBsYB/gDknbAFRf7+w3TkRETF1fyV3SJpIe27kP/BGwEjgXOLp62tHAOf3EiYiI6em3W2Zr4GxJnff6vO1/l3QZcJakY4CbgSP6jBMREdPQV3K3fSOwR4/yu4GD+nnviIiYucxQjYhooST3iIgWSnKPiGihJPeIiBZKco+IaKEk94iIFkpyj4hooST3iIgWSnKPiGihJPeIiBZKco+IaKEk94iIFkpyj4hooST3iIgWSnKPiGihGSd3SdtJ+rakH0m6WtJfVeXvlHSbpCur2yH1VTciIqain806VgNvtH15tdXecknnV4/9s+0P9l+9iIiYiRknd9urgFXV/fslXQM8sa6KRUTEzNXS5y5pAbAncElVdLykqySdJmmLCV6zWNKopNGxsbE6qhEREZW+k7ukTYFlwAm27wNOBp4ELKS07D/U63W2l9heZHvRyMhIv9WIiIgufSV3SetTEvvnbH8FwPYdth+0/RBwCrBP/9WMiIjp6Ge0jIBTgWtsf7irfJuupz0fWDnz6kVExEz0M1pmP+DlwApJV1ZlbwWOkrQQMHAT8No+YkRExAz0M1rmu4B6PHTezKsTERF1yAzViIgWSnKPiGihJPeIiBZKco+IaKEk94iIFkpyj4hooST3iIgWSnKPiGihJPeIiBZKco+IaKEk94iIFkpyj4hooST3iIgWSnKPiGihJPeIiBZKco+IaKHGkrukgyVdJ+l6SSc2FSciIh6pkeQuaT7wCeC5wK6Urfd2bSJWREQ8UlMt932A623faPs3wBeAwxuKFRER48h2/W8qvRA42Parq+OXA0+zfXzXcxYDi6vDJwPXzSDUlsBdfVY38RIv8eZ2rMSb2A62R3o9MOMNsvtlewmwpJ/3kDRqe1FNVUq8xEu8ORgr8WamqW6Z24Dtuo63rcoiImIAmkrulwE7S9pR0gbAi4FzG4oVERHjNNItY3u1pOOB/wDmA6fZvrqBUH116yRe4iXeUMRKvBlo5IJqRETMrsxQjYhooST3iIgWSnKPiOgiaZ6kzWa7Hv1Kcp9DVGw3+TMjHknSFpKeOtv1GEaSPi9pM0mbACuBH0n629muVz+GKrlLepGkx1b3/17SVyTt1ZZ4Lle3z2vq/XuR9ERJz5B0QOfWQIyTqq9fk3Tu+Fvd8cbF3lbS2ZLGJN0paZmkbZuMOUiSvlMlpccDlwOnSPpwQ7H2q5Ifkl4m6cOSdmgiVlfMPSQdX932aDDUrrbvA54HfAPYEXh5g/GQtLWkQ6vbVnW//1Ald+Bttu+XtD/wbOBU4OQWxQO4XNLvNxwDAEnvA74H/D3wt9XtbxoI9a/V1w8CH+pxa9JnKHMstgGeAHytKmuEpH0lXSbp55J+I+lBSfc1FQ94XJWUXgCcaftplL/VJpwMPFAl2TcCNwBnNhQLSX8FfA7Yqrp9VtLrGwq3vqT1Kcn9XNu/BRobSijpCOBS4EXAEcAl1bIt9bE9NDfgiurre4CXdJe1IV71/tcCqykfnKuAFcBVDcW6Dthwtn+vDf88r5xKWY3xRoHfBa6gzPF4FfCeBuOtoPzj+ibw+1VZU38vl1df3w4c013WULyrgE26jjdp8Hv7S8os+vMAATsAFzf4vf0Q2KrreAT4YZ0xZm1tmRm6TdKngOcA75O0Ic2efQw6HsAfN/z+3W4E1gd+PYhgkvYD3kn54KxH+RDZ9k4Nhr1b0suApdXxUcDdDcbD9vWS5tt+EPiMpCuAtzQU7h8okwW/Z/sySTsBP2ko1v2S3gK8DDhA0jzK309TBDzYdfxgVVY72x8FPtpVdLOkP2wiVmWe7Tu7ju+m5twyVJOYJD0GOBhYYfsnkrYBdrf9zTbE64q7P7Cz7c9IGgE2tf3TBuIsA/YALqArwdv+y7pjVfGuBf4aWE7Xh9Z2Y8m26hP+GPB0ymn294G/tP3fDcW7iNIt8mngdmAV8ErbTfYXD4Sk3wFeAlxm+2JJ2wMH2m6ka0bSG4CjgbOroucBp9s+qYFYb+9Vbvsf6o5VxfsA8FTWNDqOpJyVvLm2GEOW3LfvVd7UB7WKOZBE2xXvHcAi4Mm2d5H0BOBLtvdrINbRvcptn1F3rCreJS59wq1V/TO5A9iA8o/sccC/2L6+oXi7UPrCt7a9WzVa5jDb724i3qBVAxj2rw4vtn1FQ3He2HW4EXAocI3tP28iXhXzz4DO5/pi22ev6/nTfv8hS+4rKK0vUX4BOwLX2f69huINLNF2xbwS2JPSl7lnVXaV7VqHuKnslvUt202eeo6P+V5KP/RXWPtM4fIGYw4s+VU/0zNtv7Tu915HzAspF8I/1fX3stL2bg3Eup81Fxk3oHTJ/Nz242qOs5nt+6oRQI9g+546401Qhw2B/7B9YNOxmjJUfe62d+8+rv6rv67BkM+nSrRV/P/pDI1s0G9sW5IBOkPP6mb7QUkPSXqc7XubiNFDp9XevW61gWc1GPMUquQHYPsqSZ8Hak/u1c90B0kbuOxANgiPsX2ptFZX9OomAtl++G9fJeDhwL4NhPo8peW8nDWNuYerATR5jabjMZSlyhsx7h9lx72UC/JvtH1jvzGGKrmPZ/tySU2e5g8k0Y5zVnURd3NJrwH+nJKgmvBzYIWk84FfdAqb6nMf5FlCl4Elv8qNwPeq8fvdP9NGxp4Dd0l6ElWiqIbTrWoo1sNcTvm/Wp3dnljzex9afd2xzvddl65eAShnlyOUi9VNOQm4lfKPTJRl0Z9EaUieBhzYb4ChSu7VBZaOecBewP80GHKQiRYA2x+U9BzgPsr2g2+3fX5D4b5S3Rol6WW2Pzvu9/ewBhMfDD753VDd5gFNn+UBHEdZLvYpkm4DfkoZzVI7SS/oOpxHOQP7VROxxsXcn/L7u9j2VxsKdWjX/dXAHbabbAQcNu4i+xJJV9p+s6S31hFgqJI7a39YVgNfB5Y1FWzAiRYASTtS/ojPr443lrTA9k11x7J9hspmKrtURde5TN6oW+eMZxDJbrxeya+xPnHb74LSb1wOfX9Tsap4NwLPrs4q5zUc70+77q8GbqLBje8l/QtlzkBnRMmxkp5j+7ia48yn9K8/pc73ncQD1USmL1fHL2TNP8p6LoTWOWg+t1omN4wCG3Qdb0AZetZErAOBm4ELgYsoie+A2f4ZNPS9bgI8trp/QoNxFlEmFt1U3X4I7N1gvH8CNu863gJ492z/vGv63q6lGvRRHc+jjGBpItY5wPYD/N52osyWvgsYq+7/LrAxsH8dMYai5S7pJNsnSPoaPf6r2T6s5njftb1/j4senUk3Ta4Yt567LsbZ/k3Vum7Ch4A/sn0dPDyyZCmwdxPBqrOS1wML6DprrPv314vtX3QdvoHS59mE04DX2b4YHh5K+xnKmOYmPNf2w6fxtn8m6RDKkhK1kPQm2++X9DF6f/4auUYDXA9sT2mAQNmXuZEhpZR/ildLupS1r5XU/rdZnSm8zvafTvCU79YRZyiSO2uvTdI42/tXX2ejG2FM0mG2zwWQdDjlv3sT1u8kdgDbP67W12jKVynr83wNeKjBOJNpZJZj5cFOYgew/V1JTfbdzpe0oe1fQ+nGAzasOcY11dfRmt93Mo8FrqkSroF9gNHqYnXdifdtNb7XOrmMqtp/8mf2Z2jGuQ96DHEV72oPth+O6uLf5yiLXAm4BXiFG5gEI+k0SpL9bFX0UmC+G5q4MVcmMUn6b9s9J8T18Z6d1UJfQTm1XkpJSEcCv7Ld82JyDXHfTOkL7yyG9irKwlfvrznOfOB9tptYWG6imH+wrsdtXzioutRN0snAE4EvsfaZQm0DHIYmuUPpLgGe5QGNIZZ0DvB6NzgDdh2xNwWw/fMGY2xIueD48AxAymzKRtaakfQSYGfKIleNTmKaYBwxlH+YG9uu9axV0rfX8bBtNzaWX9LBrFkJ8nzb/9FQnP+y/fQm3rtHrIFOsptggtYvmuqCldRrZVLX2bAatuR+JvB/KUu4Nj6GWGWdkD0pS3N24tl2kyMENgT+jEf2S9c+5rYaYfErlwWuOh+oDW0/UHes6v3fQ1kj+wbWdMs0mvjarvod/tL2Q5KeTBnV9Q03MOppEK3NcfEuAF7gwU2y68R9eIKW7VrH8A/SsPS5dwx6DHF3P5yAZ1ImGzTpHMpMteU0v1rjBZQWX+fsYGNKq/oZDcV7EbDToM68BmkWx/JfBDxT0hbAv1P6xY+kmeGeG1FWL+z+Z2yamysx0El2Xe/f2AStQV6cHqrk7moM8QDjXShpT8pKeC+iDBX8ZMNht7V9cMMxOjbq7vax/XOVlTCbshLYHLhzkucNo3WN5W/y9Fi2H5B0DHBylTiubCKQ7Vc18b7rMJBJdjDQCVrHSvo+a5ZWaMxQJXeVVRnfBPwepRUBQN2n9dWQwKOq213AFykfokH0/31f0u62Vwwg1i8k7dXp85a0N/DLBuNtDlwr6TLW7nNvfChk02x31q55RANE0gkNhpakp1Na6sdUZfMbCrRRFWP856+RC/Ae3CQ7GNwErY8CH6BssHIWsNRNrXQ5ZH3u36Qk2r8BjqWs9TzmGtdAruI8RLm4eExnlIqkG93sphKd2D+iTGb4KSUBdsbW1z5OWmU7vy9QlnAQ8DvAkbaX1x2ritdz9MMwj3qYiiZG53S99x9Qtrz7nu33qWzWcUITXReSvkSZWPQSyrorL6VMKvqrumNV8Q4EzqAkWlHGuR9t+6Im4g2SytLQL65uG1PWmFlqu7aNVoYtuS+3vbe6lsCVdJntWvcclfQ8yg99P0o/5heAT3sACxlpgg2Hbd/cq7yGeOtTLsJBsy2jTrwdKOvjf6vqAprvhqfozzZJt9jebrbr0S9JV9jes/P5q/52LrbdxMqQSFpO2d5yrUl2tmufZDfos5JxsfekTH57qu3azrqGqlsG6CSeVZL+hNLi7Lnmcz9cFif6ajUS4XDgBGCrarTA2W5wJ6ZOElfZDX2jSZ4+I5KeZfs/x/UzAuwiqcnRD68BFlN+Z0+ijLz4JHBQE/HmkNpbUIOetV3pfP7+V9JulJ2mtmogTscgJ9n9K+Ws5I/pOitpKBaS1gOeS2lEHgR8h7IFZX0xhqzlfiilu2Q7ytZpmwHv6szmbDj2FpSLqkfabiwZSTqMsizAEygXHnegnPrWtiGJpHfZfscgxtqOi3slZZbhJV6zscQKj1unfxjNwrj6vW0vH2RXl6RXUxbq2x04HdgUeFvnekMD8RqfZCdpPdurB3VWorIQ4VHAIZQh1l8AzvHay2PUE2uYkvujgaQfUoaafav6Y/tD4GW2j5nkpdONMw94oe2z6nzfSWJeYvtpXR+k9Sg7TjW17kprVd0Ix1Kuz6wATnWzS9QiaUeP22KyV1mN8RqfZCfpctt7SbrU9j7V3JbXUc5KLq37Opuk/6T0ry+z/bM633u8oeqWqVqavU5BG+8XG6Df2r5b0jxJ82x/W9JJdQepJr28iXLFflAuVFmreuOqBfM6yjozMX1nULpJLqac3u8KNHJhs8syyh4K3b5MQwvNUfLTRzpzBDqT7BqKtaQ6O/97yiTJTWlgvZlBTtgbquQO/FvX/Y0o2+A1uVnHbPhflaUHLgI+J+lOuiZw1Oxbkv6GMgKpe5JIU3tUnki5aLWC0vf+ddufbihW2+3a6c6SdCrlFL8Rkp5CudD4uHHXaTajoetClUFMstuqa+JZZxz/J6qvg9h5rTFDldxtr7Uxh6Sl1LQ85myT9LvA1pQLuL8E/prSx7gDZZncJhxZfe3e/KD2PSpVVrbc1vYngFOqC6sjwN6S/tf2l9f9DtHDw6Oaqj7jJmM9mbJT0easPR78fuA1DcYdxCS7+ZRWeq8f4FD3WQ9Vcu9hZ5q9Wj9IJwFv6bqw8hBwhqTdKRsyTLT284wNYmhn5U2svWzDBpRT+U0pqxkmuU/fHpLuq+6L0tV1Hw3sOWD7HOAcSQeMH2Muab+64vQwfpLdIuqfZLfKDazbNBcMVXLvGpGg6uvtQK0TmGbR1r1mpdpeIWlBEwGri3Kvo2uPSuCTtuuedr2B7Vu6jr9bdf3co8FsOt46dY6HnoaTeGSf+8d6lNXlBOBLkjpdr9uw5myzLo2e8symoUrunp3NMwZl83U8tnFDMc+knFp/rDp+CWW874tqjrNF94Ht47sOR2qOFTWrljd4BjCitRdG24wGljqoZk7fYvuyqr//tcALKBMK6x6Z09o5FkOV3LVmQ4Se3MC64AM0Kuk1tk/pLqzGFjeyHACwm+1du46/XS1/ULdLJvjeXkuDFwKjNhtQutDWY+2F0e6jbOxct0+xZn36pwNvpVx3WkjZ7Ly2mA0OHph1QzXOXdIPKKeAV1FOp55KWeL0Vwz5uuCStgbOBn7DmmS+iPLBer7t2xuI+Vng47Z/UB0/DTjO9itqjrMVZYu9XwOdf8B7U4a1Pc/2HXXGi2ZI2qGpZTDGxfmh7T2q+5+grB/1zur4StsLm65DGwxbcv8K8I5O33Q1BfqdtptoPcyKatLSbtXh1bb/s8FY11BGQnR2mtoeuI6yKp7rnlwk6VmUIXXQ8PcW9Rn0UgeSVgILq1FA1wKLOxdyJa20vdu63yFg+JL71eOn4fcqi6nRBIuUdQyilRZz36CXOpD0d5Tp+XdRGhx72XY1XPgM202O0GmNYUvuSymTbbrXmtjE9ktmr1bDb/wiZZ6FPWMjuknalzI65pud4cHVqpCbDvm1tYEZtuS+EfAXlO3uROmb3rHudVceLQaxSFm0h6QVPLJb5l7Kda9327578LWKiQzVaBnbv5L0HUoyOoIyfHDZul4T6/T/gH0Zt0jZLNcp5q5vAA9SFr6CMjHtMZT5JqfTwES7mLmhSO7qve0dHsy2d202kEXKojWebbt7OPKKrlUV0yiYY4YiuVMW0b8YONRrtr3769mtUisMcpGyGH7zJe1j+1J4eLJRZxJTo8sNx/QNS3J/AeUU8NuSOtvetXbacNNmaZGyGH6vBk6rGgSiTGJ6dbWExHtmtWbxCMN2QbWz7d1RlA0tzqThbe/aSNK/URYpWzGufHfgn2yn7zQmJOlxALbvne26xMSGKrl304C2vWsjrWNTcbVk27tohsrexeM3kW7lqorDbt5sV2CmbP/M9pIk9hnZfB2PNbVIWQw5SZ+krMr4ekq3zIsoXXkxBw1tco++jFYbZqyl4UXKYvg9o1p36Ge230VZ1GuXWa5TTGBYLqhGvU4Azpb0UnosUjZblYo5r7NRxgOSngDcQ5lFGnNQkvujULUK4zPGLVL29SzkFZP4N0mbA+9nTaMge+DOUUN7QTUiBqNr84zbq+NXUGYyX0tZlbW1a6IPs/S5R8RkPkXZZwBJBwDvrcrupWyeEXNQumUiYjLzu1rnRwJLbC8Dlkm6cvaqFeuSlntETGa+pE5D8CCg+9pMGohzVH4xETGZpcCFku6ijJi5GB5exiKzVOeoXFCNiEll84zhk+QeEdFC6XOPiGihJPeIiBZKco/oIunTknad7XpE9Ct97hERLZSWezxqSdpE0tcl/VDSSklHSvqOpEXV48dI+rGkSyWdIunjVfnpkj4q6fuSbpT0wtn9TiIeKck9Hs0OBv7H9h62dwP+vfNAterh24B9gf2Ap4x77TbA/sChlOn4EXNKkns8mq0AniPpfZKeOW7buH2AC23fY/u3wJfGvfarth+y/SPKfrQRc0pmqMajlu0fS9oLOAR4t6QLpvHyX3fdz2btMeek5R6PWlXXywO2Pwt8ANir6+HLgD+QtEW1rsqfzUYdI2YqLfd4NNsd+ICkh4DfAn8BfBDA9m2S/gm4lLLj0LVkHZUYIhkKGTEBSZva/nnVcj8bOM322bNdr4ipSLdMxMTeWa1XvhL4KfDVWa1NxDSk5R4R0UJpuUdEtFCSe0RECyW5R0S0UJJ7REQLJblHRLTQ/wffdMM60w15PgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.groupby('sign').text_len.mean().plot(kind = 'bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's filter out empty posts. For good practices I create a copy of existent dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[df.text_len > 0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(678165, 8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fast preprocessing by lowercasing texts and removing redundant spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower().split()\n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.98 s, sys: 444 ms, total: 7.43 s\n",
      "Wall time: 7.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data['prepr_text'] = data.text.apply(lambda x: preprocess(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's encode sentences with SentenceTransformer. It will take a while. On my machine it took slightly above 2 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = SentenceTransformer('roberta-base-nli-stsb-mean-tokens').eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/Cases_recruit/netguru-case/netguru-env/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4210\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4211\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4212\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n",
      "\u001b[0;32m~/Cases_recruit/netguru-case/netguru-env/lib/python3.7/site-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, is_pretokenized, device, num_workers)\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0miterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Batches\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                 \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Cases_recruit/netguru-case/netguru-env/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Cases_recruit/netguru-case/netguru-env/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Cases_recruit/netguru-case/netguru-env/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Cases_recruit/netguru-case/netguru-env/lib/python3.7/site-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36msmart_batching_collate_text_only\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m             \u001b[0msentence_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sentence_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_seq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfeature_name\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeature_lists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Cases_recruit/netguru-case/netguru-env/lib/python3.7/site-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36mget_sentence_features\u001b[0;34m(self, *features)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_sentence_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sentence_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_sentence_embedding_dimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Cases_recruit/netguru-case/netguru-env/lib/python3.7/site-packages/sentence_transformers/models/Transformer.py\u001b[0m in \u001b[0;36mget_sentence_features\u001b[0;34m(self, tokens, pad_seq_length)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_for_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_seq_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max_length'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprepend_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_for_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_seq_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max_length'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'longest_first'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprepend_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Cases_recruit/netguru-case/netguru-env/lib/python3.7/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mprepare_for_model\u001b[0;34m(self, ids, pair_ids, add_special_tokens, padding, truncation, max_length, stride, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, prepend_batch_axis, **kwargs)\u001b[0m\n\u001b[1;32m   2703\u001b[0m                 \u001b[0mnum_tokens_to_remove\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_len\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2704\u001b[0m                 \u001b[0mtruncation_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtruncation_strategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2705\u001b[0;31m                 \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2706\u001b[0m             )\n\u001b[1;32m   2707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Cases_recruit/netguru-case/netguru-env/lib/python3.7/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mtruncate_sequences\u001b[0;34m(self, ids, pair_ids, num_tokens_to_remove, truncation_strategy, stride)\u001b[0m\n\u001b[1;32m   2815\u001b[0m                         \u001b[0mwindow_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2816\u001b[0m                     \u001b[0moverflowing_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mwindow_len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2817\u001b[0;31m                     \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2818\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2819\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moverflowing_tokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data['vectors'] = data.prepr_text.apply(lambda x: st.encode(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure it's still no missings in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id            0\n",
       "gender        0\n",
       "age           0\n",
       "topic         0\n",
       "sign          0\n",
       "date          0\n",
       "text          0\n",
       "text_len      0\n",
       "prepr_text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving to pickle to not repeat sentences encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_pickle('./data/blogtext_vec.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>text_len</th>\n",
       "      <th>prepr_text</th>\n",
       "      <th>vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>14,May,2004</td>\n",
       "      <td>Info has been found (+/- 100 pages,...</td>\n",
       "      <td>28</td>\n",
       "      <td>info has been found (+/- 100 pages, and 4.5 mb...</td>\n",
       "      <td>[-0.022713589, -0.03159448, -0.1542669, -0.791...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>13,May,2004</td>\n",
       "      <td>These are the team members:   Drewe...</td>\n",
       "      <td>20</td>\n",
       "      <td>these are the team members:   drewes van der l...</td>\n",
       "      <td>[0.2918729, -0.55179924, 0.3165975, 1.6449755,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>In het kader van kernfusie op aarde...</td>\n",
       "      <td>4326</td>\n",
       "      <td>in het kader van kernfusie op aarde:  maak je ...</td>\n",
       "      <td>[-0.19521914, -0.8037003, -0.5050227, -0.47326...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>testing!!!  testing!!!</td>\n",
       "      <td>2</td>\n",
       "      <td>testing!!!  testing!!!</td>\n",
       "      <td>[0.00037696637, -0.9026388, 0.32372972, 0.5517...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>11,June,2004</td>\n",
       "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
       "      <td>65</td>\n",
       "      <td>thanks to yahoo!'s toolbar i can now 'capture'...</td>\n",
       "      <td>[0.8108719, -0.2522956, -0.44623092, -0.710690...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id gender  age              topic      sign          date  \\\n",
       "0  2059027   male   15            Student       Leo   14,May,2004   \n",
       "1  2059027   male   15            Student       Leo   13,May,2004   \n",
       "2  2059027   male   15            Student       Leo   12,May,2004   \n",
       "3  2059027   male   15            Student       Leo   12,May,2004   \n",
       "4  3581210   male   33  InvestmentBanking  Aquarius  11,June,2004   \n",
       "\n",
       "                                                text  text_len  \\\n",
       "0             Info has been found (+/- 100 pages,...        28   \n",
       "1             These are the team members:   Drewe...        20   \n",
       "2             In het kader van kernfusie op aarde...      4326   \n",
       "3                   testing!!!  testing!!!                   2   \n",
       "4               Thanks to Yahoo!'s Toolbar I can ...        65   \n",
       "\n",
       "                                          prepr_text  \\\n",
       "0  info has been found (+/- 100 pages, and 4.5 mb...   \n",
       "1  these are the team members:   drewes van der l...   \n",
       "2  in het kader van kernfusie op aarde:  maak je ...   \n",
       "3                             testing!!!  testing!!!   \n",
       "4  thanks to yahoo!'s toolbar i can now 'capture'...   \n",
       "\n",
       "                                             vectors  \n",
       "0  [-0.022713589, -0.03159448, -0.1542669, -0.791...  \n",
       "1  [0.2918729, -0.55179924, 0.3165975, 1.6449755,...  \n",
       "2  [-0.19521914, -0.8037003, -0.5050227, -0.47326...  \n",
       "3  [0.00037696637, -0.9026388, 0.32372972, 0.5517...  \n",
       "4  [0.8108719, -0.2522956, -0.44623092, -0.710690...  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_pickle('./data/blogtext_vec.pkl')\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gender model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert gender labels to format acceptable by Neural Net we should map it to labels 0 and 1 for `female` and `male` respectively. We create dictionary to map gender values to labels and inverse dictionary to be able to identify which value predicted by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_class2idx = {k: v for v, k in enumerate(sorted(df2['gender'].unique()))}\n",
    "gender_idx2class = {v: k for k, v in gender_class2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'female': 0, 'male': 1}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_class2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['gender'] = df2['gender'].map(gender_class2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.506509\n",
       "0    0.493491\n",
       "Name: gender, dtype: float64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.gender.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we perform split on train, validation and test samples. I do this with two steps, firstly separating test sample, then spliting train and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2['vectors'].values\n",
    "y = df2['gender'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=17)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.3, stratify=y_trainval, random_state=43)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen stratified split resulted in almost identical share of classes throughout all three samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49349083 0.50650917]\n",
      "[0.49348734 0.50651266]\n",
      "[0.49349347 0.50650653]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y_train, return_counts=True)[1]/len(y_train))\n",
    "print(np.unique(y_val, return_counts=True)[1]/len(y_val))\n",
    "print(np.unique(y_test, return_counts=True)[1]/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379772 162760 135633\n"
     ]
    }
   ],
   "source": [
    "print(X_train.size, X_val.size, X_test.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first run is simple sanity check. We just want to make sure, that there is no serious bug in the code of model implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'fast_dev_run': True,\n",
    "    'pin_memory': True,\n",
    "    'device': device,\n",
    "    'num_workers': 12,\n",
    "    'shuffle': False,\n",
    "    'batch_size': 32,\n",
    "    'logger': comet_logger\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EarlyStopping mode set to min for monitoring avg_val_loss.\n"
     ]
    }
   ],
   "source": [
    "model = Model(X_train, y_train, X_val, y_val, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Running in fast_dev_run mode: will run a full train, val and test loop using a single batch\n",
      "\n",
      "  | Name | Type | Params\n",
      "------------------------------\n",
      "0 | net  | Net  | 98.7 K\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|█████     | 1/2 [00:01<00:01,  1.11s/it, loss=0.708, v_num=f71c]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating: 100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: avg_val_loss reached 0.73017 (best 0.73017), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 2/2 [00:02<00:00,  1.15s/it, loss=0.708, v_num=f71c]\n",
      "Epoch 0: 100%|██████████| 2/2 [00:02<00:00,  1.26s/it, loss=0.708, v_num=f71c]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: ----------------------------------\n",
      "COMET INFO: Comet.ml OfflineExperiment Summary\n",
      "COMET INFO: ----------------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : [OfflineExperiment will get URL after upload]\n",
      "COMET INFO:   Metrics:\n",
      "COMET INFO:     avg_train_loss : 0.7083345055580139\n",
      "COMET INFO:     avg_val_loss   : 0.7301679849624634\n",
      "COMET INFO:   Others:\n",
      "COMET INFO:     offline_experiment : True\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     batch_size   : 32\n",
      "COMET INFO:     device       : cuda\n",
      "COMET INFO:     fast_dev_run : True\n",
      "COMET INFO:     logger       : <pytorch_lightning.loggers.comet.CometLogger object at 0x7f316c4eec90>\n",
      "COMET INFO:     num_workers  : 12\n",
      "COMET INFO:     pin_memory   : True\n",
      "COMET INFO:     shuffle      : 1\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     code                     : 1 (2 KB)\n",
      "COMET INFO:     environment details      : 1\n",
      "COMET INFO:     filename                 : 1\n",
      "COMET INFO:     git metadata             : 1\n",
      "COMET INFO:     git-patch (uncompressed) : 1 (439 bytes)\n",
      "COMET INFO:     installed packages       : 1\n",
      "COMET INFO:     notebook                 : 1\n",
      "COMET INFO:     os packages              : 1\n",
      "COMET INFO: ----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Saving offline stats to disk before program termination (may take several seconds)\n",
      "COMET INFO: Starting saving the offline archive\n",
      "COMET INFO: To upload this offline experiment, run:\n",
      "    comet upload logs/a80d5ff0764c4788a291eda0a9ccf71c.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.6 s, sys: 2.86 s, total: 4.46 s\n",
      "Wall time: 6.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check went well. Then to make sure NN is learning I try to overfit on small subsaple. And as can be seen below, model does it successfuly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'overfit_batches': 1e-3,\n",
    "    'num_warmup_steps': 0,\n",
    "    'pin_memory': True,\n",
    "    'device': device,\n",
    "    'num_workers': 12,\n",
    "    'max_epochs': 40,\n",
    "    'lr': 1e-3,\n",
    "    'logger': comet_logger,\n",
    "    'shuffle': False # it's important not to shuffle training samples\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EarlyStopping mode set to min for monitoring avg_val_loss.\n"
     ]
    }
   ],
   "source": [
    "model = Model(X_train, y_train, X_val, y_val, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type | Params\n",
      "------------------------------\n",
      "0 | net  | Net  | 98.7 K\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|█████     | 11/22 [00:01<00:01,  8.83it/s, loss=0.710, v_num=d466]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  59%|█████▉    | 13/22 [00:02<00:01,  5.19it/s, loss=0.710, v_num=d466]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: avg_val_loss reached 0.61816 (best 0.61816), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v0.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 22/22 [00:02<00:00,  7.99it/s, loss=0.710, v_num=d466]\n",
      "Epoch 1:  55%|█████▍    | 12/22 [00:01<00:01,  8.23it/s, loss=0.645, v_num=d466]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:12,  1.29s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: avg_val_loss reached 0.54207 (best 0.54207), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v1.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 22/22 [00:02<00:00,  7.33it/s, loss=0.645, v_num=d466]\n",
      "Epoch 2:  55%|█████▍    | 12/22 [00:01<00:01,  8.27it/s, loss=0.555, v_num=d466]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:13,  1.31s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: avg_val_loss reached 0.45747 (best 0.45747), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v0.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 22/22 [00:03<00:00,  7.31it/s, loss=0.555, v_num=d466]\n",
      "Epoch 3:  55%|█████▍    | 12/22 [00:01<00:00, 10.69it/s, loss=0.470, v_num=d466]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:13,  1.36s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: avg_val_loss reached 0.36837 (best 0.36837), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v1.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 22/22 [00:02<00:00,  8.03it/s, loss=0.470, v_num=d466]\n",
      "Epoch 4:  55%|█████▍    | 12/22 [00:01<00:01,  9.02it/s, loss=0.381, v_num=d466]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:13,  1.38s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: avg_val_loss reached 0.27995 (best 0.27995), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v0.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 22/22 [00:02<00:00,  7.44it/s, loss=0.381, v_num=d466]\n",
      "Epoch 5:  55%|█████▍    | 12/22 [00:01<00:00, 10.16it/s, loss=0.292, v_num=d466]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:11,  1.12s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: avg_val_loss reached 0.20306 (best 0.20306), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v1.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 22/22 [00:02<00:00,  8.62it/s, loss=0.292, v_num=d466]\n",
      "Epoch 6:  55%|█████▍    | 12/22 [00:01<00:01,  9.04it/s, loss=0.214, v_num=d466]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:12,  1.29s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: avg_val_loss reached 0.14545 (best 0.14545), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v0.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 22/22 [00:02<00:00,  7.59it/s, loss=0.214, v_num=d466]\n",
      "Epoch 7:  55%|█████▍    | 12/22 [00:01<00:01,  8.83it/s, loss=0.152, v_num=d466]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:12,  1.26s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: avg_val_loss reached 0.10935 (best 0.10935), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v1.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 22/22 [00:02<00:00,  7.67it/s, loss=0.152, v_num=d466]\n",
      "Epoch 8:  55%|█████▍    | 12/22 [00:01<00:01,  8.22it/s, loss=0.109, v_num=d466]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:14,  1.44s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: avg_val_loss reached 0.08004 (best 0.08004), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v0.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 22/22 [00:03<00:00,  7.00it/s, loss=0.109, v_num=d466]\n",
      "Epoch 9:  55%|█████▍    | 12/22 [00:01<00:00, 10.58it/s, loss=0.084, v_num=d466]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:12,  1.20s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: avg_val_loss reached 0.05743 (best 0.05743), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v1.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 22/22 [00:02<00:00,  8.45it/s, loss=0.084, v_num=d466]\n",
      "Epoch 10:  55%|█████▍    | 12/22 [00:01<00:01,  9.82it/s, loss=0.068, v_num=d466]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:12,  1.29s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: avg_val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 22/22 [00:02<00:00,  7.96it/s, loss=0.068, v_num=d466]\n",
      "Epoch 11:  55%|█████▍    | 12/22 [00:01<00:01,  9.41it/s, loss=0.059, v_num=d466]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:15,  1.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: avg_val_loss reached 0.03521 (best 0.03521), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v0.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 22/22 [00:03<00:00,  7.26it/s, loss=0.059, v_num=d466]\n",
      "Epoch 12:  55%|█████▍    | 12/22 [00:01<00:01,  9.86it/s, loss=0.046, v_num=d466]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:12,  1.27s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: avg_val_loss reached 0.03313 (best 0.03313), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v1.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 22/22 [00:02<00:00,  8.03it/s, loss=0.046, v_num=d466]\n",
      "Epoch 13:  55%|█████▍    | 12/22 [00:01<00:01,  9.23it/s, loss=0.034, v_num=d466]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:12,  1.24s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: avg_val_loss reached 0.02355 (best 0.02355), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v0.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 22/22 [00:02<00:00,  7.91it/s, loss=0.034, v_num=d466]\n",
      "Epoch 14:  55%|█████▍    | 12/22 [00:01<00:01,  9.46it/s, loss=0.024, v_num=d466]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:12,  1.21s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: avg_val_loss reached 0.01915 (best 0.01915), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v1.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 22/22 [00:02<00:00,  8.05it/s, loss=0.024, v_num=d466]\n",
      "Epoch 15:  55%|█████▍    | 12/22 [00:01<00:01,  9.51it/s, loss=0.019, v_num=d466]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:13,  1.35s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: avg_val_loss reached 0.01646 (best 0.01646), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v0.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 22/22 [00:02<00:00,  7.70it/s, loss=0.019, v_num=d466]\n",
      "Epoch 16:  55%|█████▍    | 12/22 [00:01<00:01,  9.69it/s, loss=0.017, v_num=d466]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:13,  1.40s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: avg_val_loss reached 0.01469 (best 0.01469), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v1.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 22/22 [00:02<00:00,  7.64it/s, loss=0.017, v_num=d466]\n",
      "Epoch 17:  55%|█████▍    | 12/22 [00:01<00:01,  8.30it/s, loss=0.015, v_num=d466]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:14,  1.43s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: avg_val_loss reached 0.01331 (best 0.01331), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v0.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 22/22 [00:03<00:00,  7.04it/s, loss=0.015, v_num=d466]\n",
      "Epoch 18:  55%|█████▍    | 12/22 [00:01<00:01,  9.32it/s, loss=0.013, v_num=d466]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:12,  1.24s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: avg_val_loss reached 0.01221 (best 0.01221), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v1.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 22/22 [00:02<00:00,  7.97it/s, loss=0.013, v_num=d466]\n",
      "Epoch 19:  55%|█████▍    | 12/22 [00:01<00:01,  8.87it/s, loss=0.012, v_num=d466]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:13,  1.33s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: avg_val_loss reached 0.01130 (best 0.01130), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v0.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 22/22 [00:02<00:00,  7.50it/s, loss=0.012, v_num=d466]\n",
      "Epoch 20:  55%|█████▍    | 12/22 [00:01<00:01,  9.91it/s, loss=0.011, v_num=d466]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:12,  1.27s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: avg_val_loss reached 0.01056 (best 0.01056), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v1.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 22/22 [00:02<00:00,  8.05it/s, loss=0.011, v_num=d466]\n",
      "Epoch 21:  55%|█████▍    | 12/22 [00:01<00:01,  9.07it/s, loss=0.011, v_num=d466]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:13,  1.35s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: avg_val_loss reached 0.00994 (best 0.00994), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v0.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 22/22 [00:02<00:00,  7.53it/s, loss=0.011, v_num=d466]\n",
      "Epoch 22:  55%|█████▍    | 12/22 [00:01<00:01,  9.62it/s, loss=0.010, v_num=d466]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:12,  1.25s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: avg_val_loss reached 0.00942 (best 0.00942), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v1.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 22/22 [00:02<00:00,  8.03it/s, loss=0.010, v_num=d466]\n",
      "Epoch 23:  55%|█████▍    | 12/22 [00:01<00:01,  8.53it/s, loss=0.009, v_num=d466]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:11,  1.18s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: avg_val_loss reached 0.00898 (best 0.00898), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v0.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 22/22 [00:02<00:00,  7.79it/s, loss=0.009, v_num=d466]\n",
      "Epoch 24:  55%|█████▍    | 12/22 [00:01<00:01,  9.38it/s, loss=0.009, v_num=d466]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:12,  1.22s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: avg_val_loss reached 0.00860 (best 0.00860), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v1.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 22/22 [00:02<00:00,  7.99it/s, loss=0.009, v_num=d466]\n",
      "Epoch 25:  55%|█████▍    | 12/22 [00:01<00:01,  8.63it/s, loss=0.009, v_num=d466]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:13,  1.35s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: avg_val_loss reached 0.00829 (best 0.00829), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v0.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 22/22 [00:02<00:00,  7.37it/s, loss=0.009, v_num=d466]\n",
      "Epoch 26:  55%|█████▍    | 12/22 [00:01<00:01,  7.99it/s, loss=0.008, v_num=d466]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:13,  1.38s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: avg_val_loss reached 0.00802 (best 0.00802), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v1.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 22/22 [00:03<00:00,  7.05it/s, loss=0.008, v_num=d466]\n",
      "Epoch 27:  55%|█████▍    | 12/22 [00:01<00:01,  9.00it/s, loss=0.008, v_num=d466]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:12,  1.21s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: avg_val_loss reached 0.00779 (best 0.00779), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v0.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 22/22 [00:02<00:00,  7.89it/s, loss=0.008, v_num=d466]\n",
      "Epoch 28:  55%|█████▍    | 12/22 [00:01<00:01,  8.34it/s, loss=0.008, v_num=d466]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:12,  1.26s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: avg_val_loss reached 0.00760 (best 0.00760), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v1.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 22/22 [00:02<00:00,  7.37it/s, loss=0.008, v_num=d466]\n",
      "Epoch 28: 100%|██████████| 22/22 [00:03<00:00,  6.80it/s, loss=0.008, v_num=d466]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: ----------------------------------\n",
      "COMET INFO: Comet.ml OfflineExperiment Summary\n",
      "COMET INFO: ----------------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : [OfflineExperiment will get URL after upload]\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     avg_train_loss [29] : (0.00774011155590415, 0.709528923034668)\n",
      "COMET INFO:     avg_val_loss [29]   : (0.007600727025419474, 0.6181642413139343)\n",
      "COMET INFO:   Others:\n",
      "COMET INFO:     offline_experiment : True\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     device           : cuda\n",
      "COMET INFO:     logger           : <pytorch_lightning.loggers.comet.CometLogger object at 0x7f30825ed290>\n",
      "COMET INFO:     lr               : 0.001\n",
      "COMET INFO:     max_epochs       : 40\n",
      "COMET INFO:     num_warmup_steps : 1\n",
      "COMET INFO:     num_workers      : 12\n",
      "COMET INFO:     overfit_batches  : 0.001\n",
      "COMET INFO:     pin_memory       : True\n",
      "COMET INFO:     shuffle          : 1\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     code                     : 1 (2 KB)\n",
      "COMET INFO:     environment details      : 1\n",
      "COMET INFO:     filename                 : 1\n",
      "COMET INFO:     git metadata             : 1\n",
      "COMET INFO:     git-patch (uncompressed) : 1 (439 bytes)\n",
      "COMET INFO:     installed packages       : 1\n",
      "COMET INFO:     notebook                 : 1\n",
      "COMET INFO:     os packages              : 1\n",
      "COMET INFO: ----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Starting saving the offline archive\n",
      "COMET INFO: To upload this offline experiment, run:\n",
      "    comet upload logs/29a55aa469964b0f95ee2aba7efad466.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.6 s, sys: 1min 19s, total: 1min 23s\n",
      "Wall time: 1min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, running the model itself. I specified 2000 warmup steps and learning rate 0.001. Model automatically will stop if validation loss averaged on batches will not reduce for three consecutive epochs at least by 0.001. Additionally it will save the best model in checkpoint folder for us to be able to load it and try on test sample. There are some additional features which are provided by Pytorch Lightning, like learning rate scheduler and different logging possibilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'pin_memory': True,\n",
    "    'device': device,\n",
    "    'num_workers': 12,\n",
    "    'logger': comet_logger,\n",
    "    'max_epochs': 30,\n",
    "    'lr': 1e-3,\n",
    "    'num_warmup_steps': 2000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EarlyStopping mode set to min for monitoring avg_val_loss.\n"
     ]
    }
   ],
   "source": [
    "model = Model(X_train, y_train, X_val, y_val, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (net): Net(\n",
       "    (fc1): Linear(in_features=768, out_features=128, bias=True)\n",
       "    (fc2): Linear(in_features=128, out_features=2, bias=True)\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (loss_func): CrossEntropyLoss()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the mertics before training. By now model is not better than a random one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4239/4239 [00:04<00:00, 1011.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.493     0.995     0.660     66934\n",
      "           1      0.464     0.004     0.008     68699\n",
      "\n",
      "    accuracy                          0.493    135633\n",
      "   macro avg      0.479     0.500     0.334    135633\n",
      "weighted avg      0.478     0.493     0.329    135633\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict_eval(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type | Params\n",
      "------------------------------\n",
      "0 | net  | Net  | 98.7 K\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  70%|██████▉   | 11868/16955 [00:54<00:23, 217.55it/s, loss=0.636, v_num=84fe]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  70%|███████   | 11875/16955 [00:56<00:23, 211.86it/s, loss=0.636, v_num=84fe]\n",
      "Epoch 0:  71%|███████   | 11961/16955 [00:56<00:23, 213.02it/s, loss=0.636, v_num=84fe]\n",
      "Epoch 0:  71%|███████   | 12047/16955 [00:56<00:22, 214.16it/s, loss=0.636, v_num=84fe]\n",
      "Epoch 0:  72%|███████▏  | 12133/16955 [00:56<00:22, 215.30it/s, loss=0.636, v_num=84fe]\n",
      "Epoch 0:  72%|███████▏  | 12219/16955 [00:56<00:21, 216.42it/s, loss=0.636, v_num=84fe]\n",
      "Epoch 0:  73%|███████▎  | 12305/16955 [00:56<00:21, 217.54it/s, loss=0.636, v_num=84fe]\n",
      "Epoch 0:  73%|███████▎  | 12391/16955 [00:56<00:20, 218.62it/s, loss=0.636, v_num=84fe]\n",
      "Epoch 0:  74%|███████▎  | 12477/16955 [00:56<00:20, 219.74it/s, loss=0.636, v_num=84fe]\n",
      "Epoch 0:  74%|███████▍  | 12563/16955 [00:56<00:19, 220.85it/s, loss=0.636, v_num=84fe]\n",
      "Epoch 0:  75%|███████▍  | 12649/16955 [00:56<00:19, 221.95it/s, loss=0.636, v_num=84fe]\n",
      "Epoch 0:  75%|███████▌  | 12735/16955 [00:57<00:18, 223.05it/s, loss=0.636, v_num=84fe]\n",
      "Epoch 0:  76%|███████▌  | 12821/16955 [00:57<00:18, 224.15it/s, loss=0.636, v_num=84fe]\n",
      "Epoch 0:  76%|███████▌  | 12907/16955 [00:57<00:17, 225.25it/s, loss=0.636, v_num=84fe]\n",
      "Epoch 0:  77%|███████▋  | 12993/16955 [00:57<00:17, 226.34it/s, loss=0.636, v_num=84fe]\n",
      "Epoch 0:  77%|███████▋  | 13079/16955 [00:57<00:17, 227.39it/s, loss=0.636, v_num=84fe]\n",
      "Epoch 0:  78%|███████▊  | 13165/16955 [00:57<00:16, 228.46it/s, loss=0.636, v_num=84fe]\n",
      "Epoch 0:  78%|███████▊  | 13251/16955 [00:57<00:16, 229.53it/s, loss=0.636, v_num=84fe]\n",
      "Epoch 0:  79%|███████▊  | 13337/16955 [00:57<00:15, 230.59it/s, loss=0.636, v_num=84fe]\n",
      "Epoch 0:  79%|███████▉  | 13423/16955 [00:57<00:15, 231.64it/s, loss=0.636, v_num=84fe]\n",
      "Epoch 0:  80%|███████▉  | 13509/16955 [00:58<00:14, 232.70it/s, loss=0.636, v_num=84fe]\n",
      "Validating:  32%|███▏      | 1642/5087 [00:03<00:08, 411.26it/s]\u001b[A\n",
      "Epoch 0:  80%|████████  | 13595/16955 [00:58<00:14, 233.71it/s, loss=0.636, v_num=84fe]\n",
      "Epoch 0:  81%|████████  | 13681/16955 [00:58<00:13, 234.76it/s, loss=0.636, v_num=84fe]\n",
      "Epoch 0:  81%|████████  | 13767/16955 [00:58<00:13, 235.79it/s, loss=0.636, v_num=84fe]\n",
      "Epoch 0:  82%|████████▏ | 13853/16955 [00:58<00:13, 236.84it/s, loss=0.636, v_num=84fe]\n",
      "Epoch 0:  82%|████████▏ | 13939/16955 [00:58<00:12, 237.88it/s, loss=0.636, v_num=84fe]\n",
      "Epoch 0:  83%|████████▎ | 14025/16955 [00:58<00:12, 238.93it/s, loss=0.636, v_num=84fe]\n",
      "Epoch 0:  83%|████████▎ | 14111/16955 [00:58<00:11, 239.96it/s, loss=0.636, v_num=84fe]\n",
      "Epoch 0:  84%|████████▎ | 14197/16955 [00:58<00:11, 240.96it/s, loss=0.636, v_num=84fe]\n",
      "Epoch 0:  84%|████████▍ | 14283/16955 [00:59<00:11, 241.96it/s, loss=0.636, v_num=84fe]\n",
      "Epoch 0:  85%|████████▍ | 14369/16955 [00:59<00:10, 242.98it/s, loss=0.636, v_num=84fe]\n",
      "Epoch 0:  85%|████████▌ | 14455/16955 [00:59<00:10, 243.99it/s, loss=0.636, v_num=84fe]\n",
      "Epoch 0:  86%|████████▌ | 14541/16955 [00:59<00:09, 245.02it/s, loss=0.636, v_num=84fe]\n",
      "Epoch 0:  86%|████████▋ | 14627/16955 [00:59<00:09, 246.02it/s, loss=0.636, v_num=84fe]\n",
      "Epoch 0:  87%|████████▋ | 14713/16955 [00:59<00:09, 247.03it/s, loss=0.636, v_num=84fe]\n",
      "Epoch 0:  87%|████████▋ | 14799/16955 [00:59<00:08, 248.03it/s, loss=0.636, v_num=84fe]\n",
      "Epoch 0:  88%|████████▊ | 14885/16955 [00:59<00:08, 249.02it/s, loss=0.636, v_num=84fe]\n",
      "Epoch 0:  88%|████████▊ | 14971/16955 [00:59<00:07, 250.02it/s, loss=0.636, v_num=84fe]\n",
      "Epoch 0:  89%|████████▉ | 15057/16955 [00:59<00:07, 251.01it/s, loss=0.636, v_num=84fe]\n",
      "Validating:  63%|██████▎   | 3191/5087 [00:05<00:02, 803.73it/s]\u001b[A\n",
      "Epoch 0:  89%|████████▉ | 15143/16955 [01:00<00:07, 251.98it/s, loss=0.636, v_num=84fe]\n",
      "Epoch 0:  90%|████████▉ | 15229/16955 [01:00<00:06, 252.98it/s, loss=0.636, v_num=84fe]\n",
      "Epoch 0:  90%|█████████ | 15315/16955 [01:00<00:06, 253.96it/s, loss=0.636, v_num=84fe]\n",
      "Epoch 0:  91%|█████████ | 15401/16955 [01:00<00:06, 254.93it/s, loss=0.636, v_num=84fe]\n",
      "Epoch 0:  91%|█████████▏| 15487/16955 [01:00<00:05, 255.91it/s, loss=0.636, v_num=84fe]\n",
      "Epoch 0:  92%|█████████▏| 15573/16955 [01:00<00:05, 256.86it/s, loss=0.636, v_num=84fe]\n",
      "Epoch 0:  92%|█████████▏| 15660/16955 [01:00<00:05, 257.87it/s, loss=0.636, v_num=84fe]\n",
      "Epoch 0:  93%|█████████▎| 15747/16955 [01:00<00:04, 258.80it/s, loss=0.636, v_num=84fe]\n",
      "Epoch 0:  93%|█████████▎| 15834/16955 [01:00<00:04, 259.75it/s, loss=0.636, v_num=84fe]\n",
      "Epoch 0:  94%|█████████▍| 15921/16955 [01:01<00:03, 260.72it/s, loss=0.636, v_num=84fe]\n",
      "Epoch 0:  94%|█████████▍| 16008/16955 [01:01<00:03, 261.65it/s, loss=0.636, v_num=84fe]\n",
      "Epoch 0:  95%|█████████▍| 16095/16955 [01:01<00:03, 262.62it/s, loss=0.636, v_num=84fe]\n",
      "Epoch 0:  95%|█████████▌| 16182/16955 [01:01<00:02, 263.59it/s, loss=0.636, v_num=84fe]\n",
      "Epoch 0:  96%|█████████▌| 16269/16955 [01:01<00:02, 264.55it/s, loss=0.636, v_num=84fe]\n",
      "Epoch 0:  96%|█████████▋| 16356/16955 [01:01<00:02, 265.52it/s, loss=0.636, v_num=84fe]\n",
      "Epoch 0:  97%|█████████▋| 16445/16955 [01:01<00:01, 266.53it/s, loss=0.636, v_num=84fe]\n",
      "Epoch 0:  98%|█████████▊| 16534/16955 [01:01<00:01, 267.52it/s, loss=0.636, v_num=84fe]\n",
      "Epoch 0:  98%|█████████▊| 16623/16955 [01:01<00:01, 268.48it/s, loss=0.636, v_num=84fe]\n",
      "Epoch 0:  99%|█████████▊| 16712/16955 [01:02<00:00, 269.45it/s, loss=0.636, v_num=84fe]\n",
      "Epoch 0:  99%|█████████▉| 16801/16955 [01:02<00:00, 270.41it/s, loss=0.636, v_num=84fe]\n",
      "Validating:  97%|█████████▋| 4933/5087 [00:07<00:00, 826.83it/s]\u001b[A\n",
      "Epoch 0: 100%|█████████▉| 16890/16955 [01:02<00:00, 271.38it/s, loss=0.636, v_num=84fe]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: avg_val_loss reached 0.63533 (best 0.63533), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v0.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 16955/16955 [01:02<00:00, 271.00it/s, loss=0.636, v_num=84fe]\n",
      "Epoch 1:  70%|██████▉   | 11868/16955 [00:54<00:23, 217.28it/s, loss=0.638, v_num=84fe]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1:  70%|███████   | 11926/16955 [00:55<00:23, 213.32it/s, loss=0.638, v_num=84fe]\n",
      "Epoch 1:  71%|███████   | 12015/16955 [00:56<00:23, 214.47it/s, loss=0.638, v_num=84fe]\n",
      "Validating:   3%|▎         | 152/5087 [00:01<48:42,  1.69it/s] \u001b[A\n",
      "Epoch 1:  71%|███████▏  | 12104/16955 [00:56<00:22, 215.61it/s, loss=0.638, v_num=84fe]\n",
      "Epoch 1:  72%|███████▏  | 12193/16955 [00:56<00:21, 216.78it/s, loss=0.638, v_num=84fe]\n",
      "Epoch 1:  72%|███████▏  | 12282/16955 [00:56<00:21, 217.95it/s, loss=0.638, v_num=84fe]\n",
      "Epoch 1:  73%|███████▎  | 12371/16955 [00:56<00:20, 219.09it/s, loss=0.638, v_num=84fe]\n",
      "Epoch 1:  73%|███████▎  | 12460/16955 [00:56<00:20, 220.24it/s, loss=0.638, v_num=84fe]\n",
      "Epoch 1:  74%|███████▍  | 12549/16955 [00:56<00:19, 221.37it/s, loss=0.638, v_num=84fe]\n",
      "Epoch 1:  75%|███████▍  | 12638/16955 [00:56<00:19, 222.49it/s, loss=0.638, v_num=84fe]\n",
      "Epoch 1:  75%|███████▌  | 12727/16955 [00:56<00:18, 223.59it/s, loss=0.638, v_num=84fe]\n",
      "Epoch 1:  76%|███████▌  | 12816/16955 [00:57<00:18, 224.70it/s, loss=0.638, v_num=84fe]\n",
      "Validating:  19%|█▊        | 948/5087 [00:02<01:14, 55.59it/s]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 12905/16955 [00:57<00:17, 225.78it/s, loss=0.638, v_num=84fe]\n",
      "Epoch 1:  77%|███████▋  | 12994/16955 [00:57<00:17, 226.89it/s, loss=0.638, v_num=84fe]\n",
      "Epoch 1:  77%|███████▋  | 13083/16955 [00:57<00:16, 228.00it/s, loss=0.638, v_num=84fe]\n",
      "Epoch 1:  78%|███████▊  | 13172/16955 [00:57<00:16, 229.12it/s, loss=0.638, v_num=84fe]\n",
      "Epoch 1:  78%|███████▊  | 13261/16955 [00:57<00:16, 230.23it/s, loss=0.638, v_num=84fe]\n",
      "Epoch 1:  79%|███████▊  | 13350/16955 [00:57<00:15, 231.35it/s, loss=0.638, v_num=84fe]\n",
      "Epoch 1:  79%|███████▉  | 13439/16955 [00:57<00:15, 232.46it/s, loss=0.638, v_num=84fe]\n",
      "Epoch 1:  80%|███████▉  | 13528/16955 [00:57<00:14, 233.57it/s, loss=0.638, v_num=84fe]\n",
      "Epoch 1:  80%|████████  | 13617/16955 [00:58<00:14, 234.62it/s, loss=0.638, v_num=84fe]\n",
      "Epoch 1:  81%|████████  | 13706/16955 [00:58<00:13, 235.71it/s, loss=0.638, v_num=84fe]\n",
      "Validating:  36%|███▌      | 1841/5087 [00:03<00:05, 631.09it/s]\u001b[A\n",
      "Epoch 1:  81%|████████▏ | 13795/16955 [00:58<00:13, 236.76it/s, loss=0.638, v_num=84fe]\n",
      "Epoch 1:  82%|████████▏ | 13884/16955 [00:58<00:12, 237.84it/s, loss=0.638, v_num=84fe]\n",
      "Epoch 1:  82%|████████▏ | 13973/16955 [00:58<00:12, 238.92it/s, loss=0.638, v_num=84fe]\n",
      "Epoch 1:  83%|████████▎ | 14062/16955 [00:58<00:12, 240.00it/s, loss=0.638, v_num=84fe]\n",
      "Epoch 1:  83%|████████▎ | 14151/16955 [00:58<00:11, 241.07it/s, loss=0.638, v_num=84fe]\n",
      "Epoch 1:  84%|████████▍ | 14240/16955 [00:58<00:11, 242.14it/s, loss=0.638, v_num=84fe]\n",
      "Epoch 1:  85%|████████▍ | 14329/16955 [00:58<00:10, 243.20it/s, loss=0.638, v_num=84fe]\n",
      "Epoch 1:  85%|████████▌ | 14418/16955 [00:59<00:10, 244.25it/s, loss=0.638, v_num=84fe]\n",
      "Epoch 1:  86%|████████▌ | 14507/16955 [00:59<00:09, 245.30it/s, loss=0.638, v_num=84fe]\n",
      "Epoch 1:  86%|████████▌ | 14596/16955 [00:59<00:09, 246.37it/s, loss=0.638, v_num=84fe]\n",
      "Epoch 1:  87%|████████▋ | 14685/16955 [00:59<00:09, 247.43it/s, loss=0.638, v_num=84fe]\n",
      "Epoch 1:  87%|████████▋ | 14774/16955 [00:59<00:08, 248.48it/s, loss=0.638, v_num=84fe]\n",
      "Epoch 1:  88%|████████▊ | 14863/16955 [00:59<00:08, 249.51it/s, loss=0.638, v_num=84fe]\n",
      "Epoch 1:  88%|████████▊ | 14952/16955 [00:59<00:07, 250.56it/s, loss=0.638, v_num=84fe]\n",
      "Validating:  61%|██████    | 3084/5087 [00:05<00:02, 825.14it/s]\u001b[A\n",
      "Epoch 1:  89%|████████▊ | 15041/16955 [00:59<00:07, 251.56it/s, loss=0.638, v_num=84fe]\n",
      "Epoch 1:  89%|████████▉ | 15130/16955 [00:59<00:07, 252.58it/s, loss=0.638, v_num=84fe]\n",
      "Epoch 1:  90%|████████▉ | 15219/16955 [01:00<00:06, 253.61it/s, loss=0.638, v_num=84fe]\n",
      "Epoch 1:  90%|█████████ | 15308/16955 [01:00<00:06, 254.63it/s, loss=0.638, v_num=84fe]\n",
      "Epoch 1:  91%|█████████ | 15397/16955 [01:00<00:06, 255.64it/s, loss=0.638, v_num=84fe]\n",
      "Epoch 1:  91%|█████████▏| 15486/16955 [01:00<00:05, 256.64it/s, loss=0.638, v_num=84fe]\n",
      "Epoch 1:  92%|█████████▏| 15575/16955 [01:00<00:05, 257.64it/s, loss=0.638, v_num=84fe]\n",
      "Epoch 1:  92%|█████████▏| 15664/16955 [01:00<00:04, 258.64it/s, loss=0.638, v_num=84fe]\n",
      "Epoch 1:  93%|█████████▎| 15753/16955 [01:00<00:04, 259.63it/s, loss=0.638, v_num=84fe]\n",
      "Epoch 1:  93%|█████████▎| 15842/16955 [01:00<00:04, 260.62it/s, loss=0.638, v_num=84fe]\n",
      "Epoch 1:  94%|█████████▍| 15931/16955 [01:00<00:03, 261.61it/s, loss=0.638, v_num=84fe]\n",
      "Validating:  80%|███████▉  | 4064/5087 [00:06<00:01, 798.79it/s]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 16020/16955 [01:01<00:03, 262.59it/s, loss=0.638, v_num=84fe]\n",
      "Epoch 1:  95%|█████████▌| 16109/16955 [01:01<00:03, 263.59it/s, loss=0.638, v_num=84fe]\n",
      "Epoch 1:  96%|█████████▌| 16198/16955 [01:01<00:02, 264.55it/s, loss=0.638, v_num=84fe]\n",
      "Epoch 1:  96%|█████████▌| 16287/16955 [01:01<00:02, 265.52it/s, loss=0.638, v_num=84fe]\n",
      "Epoch 1:  97%|█████████▋| 16376/16955 [01:01<00:02, 266.50it/s, loss=0.638, v_num=84fe]\n",
      "Epoch 1:  97%|█████████▋| 16465/16955 [01:01<00:01, 267.48it/s, loss=0.638, v_num=84fe]\n",
      "Epoch 1:  98%|█████████▊| 16554/16955 [01:01<00:01, 268.45it/s, loss=0.638, v_num=84fe]\n",
      "Epoch 1:  98%|█████████▊| 16643/16955 [01:01<00:01, 269.44it/s, loss=0.638, v_num=84fe]\n",
      "Epoch 1:  99%|█████████▊| 16732/16955 [01:01<00:00, 270.42it/s, loss=0.638, v_num=84fe]\n",
      "Epoch 1:  99%|█████████▉| 16821/16955 [01:01<00:00, 271.40it/s, loss=0.638, v_num=84fe]\n",
      "Epoch 1: 100%|█████████▉| 16910/16955 [01:02<00:00, 272.37it/s, loss=0.638, v_num=84fe]\n",
      "Validating: 100%|█████████▉| 5068/5087 [00:07<00:00, 836.76it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: avg_val_loss reached 0.62642 (best 0.62642), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v2.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 16955/16955 [01:02<00:00, 271.73it/s, loss=0.638, v_num=84fe]\n",
      "Epoch 2:  70%|██████▉   | 11868/16955 [00:54<00:23, 219.14it/s, loss=0.639, v_num=84fe]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2:  70%|███████   | 11926/16955 [00:55<00:23, 214.30it/s, loss=0.639, v_num=84fe]\n",
      "Validating:   1%|          | 63/5087 [00:01<1:21:56,  1.02it/s]\u001b[A\n",
      "Epoch 2:  71%|███████   | 12015/16955 [00:55<00:22, 215.46it/s, loss=0.639, v_num=84fe]\n",
      "Epoch 2:  71%|███████▏  | 12104/16955 [00:55<00:22, 216.64it/s, loss=0.639, v_num=84fe]\n",
      "Epoch 2:  72%|███████▏  | 12193/16955 [00:55<00:21, 217.83it/s, loss=0.639, v_num=84fe]\n",
      "Epoch 2:  72%|███████▏  | 12282/16955 [00:56<00:21, 219.02it/s, loss=0.639, v_num=84fe]\n",
      "Epoch 2:  73%|███████▎  | 12371/16955 [00:56<00:20, 220.19it/s, loss=0.639, v_num=84fe]\n",
      "Epoch 2:  73%|███████▎  | 12460/16955 [00:56<00:20, 221.33it/s, loss=0.639, v_num=84fe]\n",
      "Epoch 2:  74%|███████▍  | 12549/16955 [00:56<00:19, 222.50it/s, loss=0.639, v_num=84fe]\n",
      "Epoch 2:  75%|███████▍  | 12638/16955 [00:56<00:19, 223.64it/s, loss=0.639, v_num=84fe]\n",
      "Epoch 2:  75%|███████▌  | 12727/16955 [00:56<00:18, 224.78it/s, loss=0.639, v_num=84fe]\n",
      "Epoch 2:  76%|███████▌  | 12816/16955 [00:56<00:18, 225.92it/s, loss=0.639, v_num=84fe]\n",
      "Epoch 2:  76%|███████▌  | 12905/16955 [00:56<00:17, 227.05it/s, loss=0.639, v_num=84fe]\n",
      "Epoch 2:  77%|███████▋  | 12994/16955 [00:56<00:17, 228.16it/s, loss=0.639, v_num=84fe]\n",
      "Epoch 2:  77%|███████▋  | 13083/16955 [00:57<00:16, 229.29it/s, loss=0.639, v_num=84fe]\n",
      "Epoch 2:  78%|███████▊  | 13172/16955 [00:57<00:16, 230.42it/s, loss=0.639, v_num=84fe]\n",
      "Validating:  26%|██▌       | 1309/5087 [00:03<00:22, 170.49it/s]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 13261/16955 [00:57<00:15, 231.52it/s, loss=0.639, v_num=84fe]\n",
      "Epoch 2:  79%|███████▊  | 13350/16955 [00:57<00:15, 232.62it/s, loss=0.639, v_num=84fe]\n",
      "Epoch 2:  79%|███████▉  | 13439/16955 [00:57<00:15, 233.71it/s, loss=0.639, v_num=84fe]\n",
      "Epoch 2:  80%|███████▉  | 13528/16955 [00:57<00:14, 234.79it/s, loss=0.639, v_num=84fe]\n",
      "Epoch 2:  80%|████████  | 13617/16955 [00:57<00:14, 235.89it/s, loss=0.639, v_num=84fe]\n",
      "Epoch 2:  81%|████████  | 13706/16955 [00:57<00:13, 236.98it/s, loss=0.639, v_num=84fe]\n",
      "Epoch 2:  81%|████████▏ | 13795/16955 [00:57<00:13, 238.07it/s, loss=0.639, v_num=84fe]\n",
      "Epoch 2:  82%|████████▏ | 13884/16955 [00:58<00:12, 239.17it/s, loss=0.639, v_num=84fe]\n",
      "Epoch 2:  82%|████████▏ | 13973/16955 [00:58<00:12, 240.23it/s, loss=0.639, v_num=84fe]\n",
      "Epoch 2:  83%|████████▎ | 14062/16955 [00:58<00:11, 241.33it/s, loss=0.639, v_num=84fe]\n",
      "Epoch 2:  83%|████████▎ | 14151/16955 [00:58<00:11, 242.43it/s, loss=0.639, v_num=84fe]\n",
      "Epoch 2:  84%|████████▍ | 14240/16955 [00:58<00:11, 243.51it/s, loss=0.639, v_num=84fe]\n",
      "Epoch 2:  85%|████████▍ | 14329/16955 [00:58<00:10, 244.56it/s, loss=0.639, v_num=84fe]\n",
      "Epoch 2:  85%|████████▌ | 14418/16955 [00:58<00:10, 245.60it/s, loss=0.639, v_num=84fe]\n",
      "Validating:  50%|█████     | 2553/5087 [00:04<00:03, 791.82it/s]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 14507/16955 [00:58<00:09, 246.64it/s, loss=0.639, v_num=84fe]\n",
      "Epoch 2:  86%|████████▌ | 14596/16955 [00:58<00:09, 247.67it/s, loss=0.639, v_num=84fe]\n",
      "Epoch 2:  87%|████████▋ | 14685/16955 [00:59<00:09, 248.72it/s, loss=0.639, v_num=84fe]\n",
      "Epoch 2:  87%|████████▋ | 14774/16955 [00:59<00:08, 249.78it/s, loss=0.639, v_num=84fe]\n",
      "Epoch 2:  88%|████████▊ | 14863/16955 [00:59<00:08, 250.82it/s, loss=0.639, v_num=84fe]\n",
      "Epoch 2:  88%|████████▊ | 14952/16955 [00:59<00:07, 251.85it/s, loss=0.639, v_num=84fe]\n",
      "Epoch 2:  89%|████████▊ | 15041/16955 [00:59<00:07, 252.89it/s, loss=0.639, v_num=84fe]\n",
      "Epoch 2:  89%|████████▉ | 15130/16955 [00:59<00:07, 253.93it/s, loss=0.639, v_num=84fe]\n",
      "Epoch 2:  90%|████████▉ | 15219/16955 [00:59<00:06, 254.95it/s, loss=0.639, v_num=84fe]\n",
      "Epoch 2:  90%|█████████ | 15308/16955 [00:59<00:06, 255.98it/s, loss=0.639, v_num=84fe]\n",
      "Epoch 2:  91%|█████████ | 15397/16955 [00:59<00:06, 256.97it/s, loss=0.639, v_num=84fe]\n",
      "Epoch 2:  91%|█████████▏| 15486/16955 [01:00<00:05, 257.97it/s, loss=0.639, v_num=84fe]\n",
      "Validating:  71%|███████   | 3620/5087 [00:05<00:01, 794.43it/s]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 15575/16955 [01:00<00:05, 258.95it/s, loss=0.639, v_num=84fe]\n",
      "Epoch 2:  92%|█████████▏| 15664/16955 [01:00<00:04, 259.96it/s, loss=0.639, v_num=84fe]\n",
      "Epoch 2:  93%|█████████▎| 15753/16955 [01:00<00:04, 260.97it/s, loss=0.639, v_num=84fe]\n",
      "Epoch 2:  93%|█████████▎| 15842/16955 [01:00<00:04, 261.98it/s, loss=0.639, v_num=84fe]\n",
      "Epoch 2:  94%|█████████▍| 15931/16955 [01:00<00:03, 262.97it/s, loss=0.639, v_num=84fe]\n",
      "Epoch 2:  94%|█████████▍| 16020/16955 [01:00<00:03, 263.95it/s, loss=0.639, v_num=84fe]\n",
      "Epoch 2:  95%|█████████▌| 16109/16955 [01:00<00:03, 264.92it/s, loss=0.639, v_num=84fe]\n",
      "Epoch 2:  96%|█████████▌| 16198/16955 [01:00<00:02, 265.86it/s, loss=0.639, v_num=84fe]\n",
      "Epoch 2:  96%|█████████▌| 16287/16955 [01:01<00:02, 266.84it/s, loss=0.639, v_num=84fe]\n",
      "Epoch 2:  97%|█████████▋| 16376/16955 [01:01<00:02, 267.81it/s, loss=0.639, v_num=84fe]\n",
      "Validating:  89%|████████▊ | 4514/5087 [00:07<00:00, 786.35it/s]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 16465/16955 [01:01<00:01, 268.74it/s, loss=0.639, v_num=84fe]\n",
      "Epoch 2:  98%|█████████▊| 16554/16955 [01:01<00:01, 269.69it/s, loss=0.639, v_num=84fe]\n",
      "Epoch 2:  98%|█████████▊| 16643/16955 [01:01<00:01, 270.66it/s, loss=0.639, v_num=84fe]\n",
      "Epoch 2:  99%|█████████▊| 16732/16955 [01:01<00:00, 271.64it/s, loss=0.639, v_num=84fe]\n",
      "Epoch 2:  99%|█████████▉| 16821/16955 [01:01<00:00, 272.62it/s, loss=0.639, v_num=84fe]\n",
      "Epoch 2: 100%|█████████▉| 16910/16955 [01:01<00:00, 273.54it/s, loss=0.639, v_num=84fe]\n",
      "Validating: 100%|█████████▉| 5082/5087 [00:07<00:00, 799.93it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: avg_val_loss reached 0.62397 (best 0.62397), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v0.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 16955/16955 [01:02<00:00, 272.91it/s, loss=0.639, v_num=84fe]\n",
      "Epoch 3:  70%|██████▉   | 11868/16955 [00:53<00:23, 220.21it/s, loss=0.629, v_num=84fe]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 3:  70%|███████   | 11926/16955 [00:55<00:23, 215.47it/s, loss=0.629, v_num=84fe]\n",
      "Epoch 3:  71%|███████   | 12015/16955 [00:55<00:22, 216.66it/s, loss=0.629, v_num=84fe]\n",
      "Validating:   3%|▎         | 154/5087 [00:01<55:14,  1.49it/s] \u001b[A\n",
      "Epoch 3:  71%|███████▏  | 12104/16955 [00:55<00:22, 217.80it/s, loss=0.629, v_num=84fe]\n",
      "Epoch 3:  72%|███████▏  | 12193/16955 [00:55<00:21, 218.94it/s, loss=0.629, v_num=84fe]\n",
      "Epoch 3:  72%|███████▏  | 12282/16955 [00:55<00:21, 220.11it/s, loss=0.629, v_num=84fe]\n",
      "Epoch 3:  73%|███████▎  | 12371/16955 [00:55<00:20, 221.27it/s, loss=0.629, v_num=84fe]\n",
      "Epoch 3:  73%|███████▎  | 12460/16955 [00:56<00:20, 222.43it/s, loss=0.629, v_num=84fe]\n",
      "Epoch 3:  74%|███████▍  | 12549/16955 [00:56<00:19, 223.58it/s, loss=0.629, v_num=84fe]\n",
      "Epoch 3:  75%|███████▍  | 12638/16955 [00:56<00:19, 224.72it/s, loss=0.629, v_num=84fe]\n",
      "Epoch 3:  75%|███████▌  | 12727/16955 [00:56<00:18, 225.84it/s, loss=0.629, v_num=84fe]\n",
      "Epoch 3:  76%|███████▌  | 12816/16955 [00:56<00:18, 226.97it/s, loss=0.629, v_num=84fe]\n",
      "Epoch 3:  76%|███████▌  | 12905/16955 [00:56<00:17, 228.11it/s, loss=0.629, v_num=84fe]\n",
      "Validating:  20%|██        | 1038/5087 [00:02<00:58, 68.92it/s]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 12994/16955 [00:56<00:17, 229.25it/s, loss=0.629, v_num=84fe]\n",
      "Epoch 3:  77%|███████▋  | 13083/16955 [00:56<00:16, 230.37it/s, loss=0.629, v_num=84fe]\n",
      "Epoch 3:  78%|███████▊  | 13172/16955 [00:56<00:16, 231.47it/s, loss=0.629, v_num=84fe]\n",
      "Epoch 3:  78%|███████▊  | 13261/16955 [00:57<00:15, 232.57it/s, loss=0.629, v_num=84fe]\n",
      "Epoch 3:  79%|███████▊  | 13350/16955 [00:57<00:15, 233.69it/s, loss=0.629, v_num=84fe]\n",
      "Epoch 3:  79%|███████▉  | 13439/16955 [00:57<00:14, 234.78it/s, loss=0.629, v_num=84fe]\n",
      "Epoch 3:  80%|███████▉  | 13528/16955 [00:57<00:14, 235.88it/s, loss=0.629, v_num=84fe]\n",
      "Epoch 3:  80%|████████  | 13617/16955 [00:57<00:14, 237.00it/s, loss=0.629, v_num=84fe]\n",
      "Epoch 3:  81%|████████  | 13706/16955 [00:57<00:13, 238.10it/s, loss=0.629, v_num=84fe]\n",
      "Epoch 3:  81%|████████▏ | 13795/16955 [00:57<00:13, 239.18it/s, loss=0.629, v_num=84fe]\n",
      "Epoch 3:  82%|████████▏ | 13884/16955 [00:57<00:12, 240.27it/s, loss=0.629, v_num=84fe]\n",
      "Epoch 3:  82%|████████▏ | 13973/16955 [00:57<00:12, 241.36it/s, loss=0.629, v_num=84fe]\n",
      "Epoch 3:  83%|████████▎ | 14062/16955 [00:58<00:11, 242.44it/s, loss=0.629, v_num=84fe]\n",
      "Validating:  43%|████▎     | 2194/5087 [00:04<00:03, 757.41it/s]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 14151/16955 [00:58<00:11, 243.50it/s, loss=0.629, v_num=84fe]\n",
      "Epoch 3:  84%|████████▍ | 14240/16955 [00:58<00:11, 244.56it/s, loss=0.629, v_num=84fe]\n",
      "Epoch 3:  85%|████████▍ | 14329/16955 [00:58<00:10, 245.65it/s, loss=0.629, v_num=84fe]\n",
      "Epoch 3:  85%|████████▌ | 14418/16955 [00:58<00:10, 246.72it/s, loss=0.629, v_num=84fe]\n",
      "Epoch 3:  86%|████████▌ | 14507/16955 [00:58<00:09, 247.79it/s, loss=0.629, v_num=84fe]\n",
      "Epoch 3:  86%|████████▌ | 14596/16955 [00:58<00:09, 248.84it/s, loss=0.629, v_num=84fe]\n",
      "Epoch 3:  87%|████████▋ | 14685/16955 [00:58<00:09, 249.89it/s, loss=0.629, v_num=84fe]\n",
      "Epoch 3:  87%|████████▋ | 14774/16955 [00:58<00:08, 250.92it/s, loss=0.629, v_num=84fe]\n",
      "Epoch 3:  88%|████████▊ | 14863/16955 [00:58<00:08, 251.94it/s, loss=0.629, v_num=84fe]\n",
      "Epoch 3:  88%|████████▊ | 14952/16955 [00:59<00:07, 252.95it/s, loss=0.629, v_num=84fe]\n",
      "Epoch 3:  89%|████████▊ | 15041/16955 [00:59<00:07, 253.96it/s, loss=0.629, v_num=84fe]\n",
      "Validating:  62%|██████▏   | 3178/5087 [00:05<00:02, 775.06it/s]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 15130/16955 [00:59<00:07, 254.95it/s, loss=0.629, v_num=84fe]\n",
      "Epoch 3:  90%|████████▉ | 15219/16955 [00:59<00:06, 255.96it/s, loss=0.629, v_num=84fe]\n",
      "Epoch 3:  90%|█████████ | 15308/16955 [00:59<00:06, 256.95it/s, loss=0.629, v_num=84fe]\n",
      "Epoch 3:  91%|█████████ | 15397/16955 [00:59<00:06, 257.94it/s, loss=0.629, v_num=84fe]\n",
      "Epoch 3:  91%|█████████▏| 15486/16955 [00:59<00:05, 258.94it/s, loss=0.629, v_num=84fe]\n",
      "Epoch 3:  92%|█████████▏| 15575/16955 [00:59<00:05, 259.92it/s, loss=0.629, v_num=84fe]\n",
      "Epoch 3:  92%|█████████▏| 15664/16955 [01:00<00:04, 260.94it/s, loss=0.629, v_num=84fe]\n",
      "Epoch 3:  93%|█████████▎| 15753/16955 [01:00<00:04, 261.95it/s, loss=0.629, v_num=84fe]\n",
      "Epoch 3:  93%|█████████▎| 15842/16955 [01:00<00:04, 262.96it/s, loss=0.629, v_num=84fe]\n",
      "Validating:  78%|███████▊  | 3975/5087 [00:06<00:01, 805.96it/s]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 15931/16955 [01:00<00:03, 263.94it/s, loss=0.629, v_num=84fe]\n",
      "Epoch 3:  94%|█████████▍| 16020/16955 [01:00<00:03, 264.92it/s, loss=0.629, v_num=84fe]\n",
      "Epoch 3:  95%|█████████▌| 16109/16955 [01:00<00:03, 265.94it/s, loss=0.629, v_num=84fe]\n",
      "Epoch 3:  96%|█████████▌| 16198/16955 [01:00<00:02, 266.92it/s, loss=0.629, v_num=84fe]\n",
      "Epoch 3:  96%|█████████▌| 16287/16955 [01:00<00:02, 267.88it/s, loss=0.629, v_num=84fe]\n",
      "Epoch 3:  97%|█████████▋| 16376/16955 [01:00<00:02, 268.86it/s, loss=0.629, v_num=84fe]\n",
      "Epoch 3:  97%|█████████▋| 16465/16955 [01:01<00:01, 269.84it/s, loss=0.629, v_num=84fe]\n",
      "Epoch 3:  98%|█████████▊| 16554/16955 [01:01<00:01, 270.84it/s, loss=0.629, v_num=84fe]\n",
      "Epoch 3:  98%|█████████▊| 16643/16955 [01:01<00:01, 271.84it/s, loss=0.629, v_num=84fe]\n",
      "Epoch 3:  99%|█████████▊| 16732/16955 [01:01<00:00, 272.83it/s, loss=0.629, v_num=84fe]\n",
      "Epoch 3:  99%|█████████▉| 16821/16955 [01:01<00:00, 273.79it/s, loss=0.629, v_num=84fe]\n",
      "Epoch 3: 100%|█████████▉| 16910/16955 [01:01<00:00, 274.74it/s, loss=0.629, v_num=84fe]\n",
      "Validating: 100%|█████████▉| 5068/5087 [00:07<00:00, 819.88it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: avg_val_loss reached 0.62299 (best 0.62299), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v2.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 16955/16955 [01:01<00:00, 274.10it/s, loss=0.629, v_num=84fe]\n",
      "Epoch 4:  70%|██████▉   | 11868/16955 [00:53<00:23, 220.66it/s, loss=0.619, v_num=84fe]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 4:  70%|███████   | 11926/16955 [00:55<00:23, 215.92it/s, loss=0.619, v_num=84fe]\n",
      "Validating:   1%|          | 62/5087 [00:01<1:19:27,  1.05it/s]\u001b[A\n",
      "Epoch 4:  71%|███████   | 12015/16955 [00:55<00:22, 217.08it/s, loss=0.619, v_num=84fe]\n",
      "Epoch 4:  71%|███████▏  | 12104/16955 [00:55<00:22, 218.28it/s, loss=0.619, v_num=84fe]\n",
      "Epoch 4:  72%|███████▏  | 12193/16955 [00:55<00:21, 219.46it/s, loss=0.619, v_num=84fe]\n",
      "Epoch 4:  72%|███████▏  | 12282/16955 [00:55<00:21, 220.63it/s, loss=0.619, v_num=84fe]\n",
      "Epoch 4:  73%|███████▎  | 12371/16955 [00:55<00:20, 221.78it/s, loss=0.619, v_num=84fe]\n",
      "Epoch 4:  73%|███████▎  | 12460/16955 [00:55<00:20, 222.96it/s, loss=0.619, v_num=84fe]\n",
      "Epoch 4:  74%|███████▍  | 12549/16955 [00:55<00:19, 224.10it/s, loss=0.619, v_num=84fe]\n",
      "Epoch 4:  75%|███████▍  | 12638/16955 [00:56<00:19, 225.23it/s, loss=0.619, v_num=84fe]\n",
      "Epoch 4:  75%|███████▌  | 12727/16955 [00:56<00:18, 226.38it/s, loss=0.619, v_num=84fe]\n",
      "Epoch 4:  76%|███████▌  | 12816/16955 [00:56<00:18, 227.52it/s, loss=0.619, v_num=84fe]\n",
      "Epoch 4:  76%|███████▌  | 12905/16955 [00:56<00:17, 228.64it/s, loss=0.619, v_num=84fe]\n",
      "Validating:  20%|██        | 1042/5087 [00:02<00:58, 69.62it/s]\u001b[A\n",
      "Epoch 4:  77%|███████▋  | 12994/16955 [00:56<00:17, 229.74it/s, loss=0.619, v_num=84fe]\n",
      "Epoch 4:  77%|███████▋  | 13083/16955 [00:56<00:16, 230.88it/s, loss=0.619, v_num=84fe]\n",
      "Epoch 4:  78%|███████▊  | 13172/16955 [00:56<00:16, 232.02it/s, loss=0.619, v_num=84fe]\n",
      "Epoch 4:  78%|███████▊  | 13261/16955 [00:56<00:15, 233.13it/s, loss=0.619, v_num=84fe]\n",
      "Epoch 4:  79%|███████▊  | 13350/16955 [00:56<00:15, 234.26it/s, loss=0.619, v_num=84fe]\n",
      "Epoch 4:  79%|███████▉  | 13439/16955 [00:57<00:14, 235.39it/s, loss=0.619, v_num=84fe]\n",
      "Epoch 4:  80%|███████▉  | 13528/16955 [00:57<00:14, 236.52it/s, loss=0.619, v_num=84fe]\n",
      "Epoch 4:  80%|████████  | 13617/16955 [00:57<00:14, 237.64it/s, loss=0.619, v_num=84fe]\n",
      "Epoch 4:  81%|████████  | 13706/16955 [00:57<00:13, 238.73it/s, loss=0.619, v_num=84fe]\n",
      "Epoch 4:  81%|████████▏ | 13795/16955 [00:57<00:13, 239.81it/s, loss=0.619, v_num=84fe]\n",
      "Epoch 4:  82%|████████▏ | 13884/16955 [00:57<00:12, 240.88it/s, loss=0.619, v_num=84fe]\n",
      "Epoch 4:  82%|████████▏ | 13973/16955 [00:57<00:12, 241.97it/s, loss=0.619, v_num=84fe]\n",
      "Epoch 4:  83%|████████▎ | 14062/16955 [00:57<00:11, 243.04it/s, loss=0.619, v_num=84fe]\n",
      "Epoch 4:  83%|████████▎ | 14151/16955 [00:57<00:11, 244.10it/s, loss=0.619, v_num=84fe]\n",
      "Validating:  45%|████▌     | 2290/5087 [00:04<00:03, 759.87it/s]\u001b[A\n",
      "Epoch 4:  84%|████████▍ | 14240/16955 [00:58<00:11, 245.14it/s, loss=0.619, v_num=84fe]\n",
      "Epoch 4:  85%|████████▍ | 14329/16955 [00:58<00:10, 246.20it/s, loss=0.619, v_num=84fe]\n",
      "Epoch 4:  85%|████████▌ | 14418/16955 [00:58<00:10, 247.26it/s, loss=0.619, v_num=84fe]\n",
      "Epoch 4:  86%|████████▌ | 14507/16955 [00:58<00:09, 248.30it/s, loss=0.619, v_num=84fe]\n",
      "Epoch 4:  86%|████████▌ | 14596/16955 [00:58<00:09, 249.36it/s, loss=0.619, v_num=84fe]\n",
      "Epoch 4:  87%|████████▋ | 14685/16955 [00:58<00:09, 250.43it/s, loss=0.619, v_num=84fe]\n",
      "Epoch 4:  87%|████████▋ | 14774/16955 [00:58<00:08, 251.45it/s, loss=0.619, v_num=84fe]\n",
      "Epoch 4:  88%|████████▊ | 14863/16955 [00:58<00:08, 252.47it/s, loss=0.619, v_num=84fe]\n",
      "Epoch 4:  88%|████████▊ | 14952/16955 [00:58<00:07, 253.50it/s, loss=0.619, v_num=84fe]\n",
      "Epoch 4:  89%|████████▊ | 15041/16955 [00:59<00:07, 254.51it/s, loss=0.619, v_num=84fe]\n",
      "Epoch 4:  89%|████████▉ | 15130/16955 [00:59<00:07, 255.51it/s, loss=0.619, v_num=84fe]\n",
      "Validating:  64%|██████▍   | 3262/5087 [00:05<00:02, 777.20it/s]\u001b[A\n",
      "Epoch 4:  90%|████████▉ | 15219/16955 [00:59<00:06, 256.53it/s, loss=0.619, v_num=84fe]\n",
      "Epoch 4:  90%|█████████ | 15308/16955 [00:59<00:06, 257.55it/s, loss=0.619, v_num=84fe]\n",
      "Epoch 4:  91%|█████████ | 15397/16955 [00:59<00:06, 258.59it/s, loss=0.619, v_num=84fe]\n",
      "Epoch 4:  91%|█████████▏| 15486/16955 [00:59<00:05, 259.62it/s, loss=0.619, v_num=84fe]\n",
      "Epoch 4:  92%|█████████▏| 15575/16955 [00:59<00:05, 260.66it/s, loss=0.619, v_num=84fe]\n",
      "Epoch 4:  92%|█████████▏| 15664/16955 [00:59<00:04, 261.64it/s, loss=0.619, v_num=84fe]\n",
      "Epoch 4:  93%|█████████▎| 15753/16955 [00:59<00:04, 262.63it/s, loss=0.619, v_num=84fe]\n",
      "Epoch 4:  93%|█████████▎| 15842/16955 [01:00<00:04, 263.61it/s, loss=0.619, v_num=84fe]\n",
      "Epoch 4:  94%|█████████▍| 15931/16955 [01:00<00:03, 264.61it/s, loss=0.619, v_num=84fe]\n",
      "Epoch 4:  94%|█████████▍| 16020/16955 [01:00<00:03, 265.63it/s, loss=0.619, v_num=84fe]\n",
      "Epoch 4:  95%|█████████▌| 16109/16955 [01:00<00:03, 266.63it/s, loss=0.619, v_num=84fe]\n",
      "Epoch 4:  96%|█████████▌| 16198/16955 [01:00<00:02, 267.62it/s, loss=0.619, v_num=84fe]\n",
      "Epoch 4:  96%|█████████▌| 16287/16955 [01:00<00:02, 268.62it/s, loss=0.619, v_num=84fe]\n",
      "Epoch 4:  97%|█████████▋| 16376/16955 [01:00<00:02, 269.63it/s, loss=0.619, v_num=84fe]\n",
      "Epoch 4:  97%|█████████▋| 16465/16955 [01:00<00:01, 270.63it/s, loss=0.619, v_num=84fe]\n",
      "Validating:  90%|█████████ | 4600/5087 [00:07<00:00, 841.95it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 16554/16955 [01:00<00:01, 271.58it/s, loss=0.619, v_num=84fe]\n",
      "Epoch 4:  98%|█████████▊| 16643/16955 [01:01<00:01, 272.55it/s, loss=0.619, v_num=84fe]\n",
      "Epoch 4:  99%|█████████▊| 16732/16955 [01:01<00:00, 273.53it/s, loss=0.619, v_num=84fe]\n",
      "Epoch 4:  99%|█████████▉| 16821/16955 [01:01<00:00, 274.47it/s, loss=0.619, v_num=84fe]\n",
      "Epoch 4: 100%|█████████▉| 16910/16955 [01:01<00:00, 275.41it/s, loss=0.619, v_num=84fe]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: avg_val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 16955/16955 [01:01<00:00, 274.87it/s, loss=0.619, v_num=84fe]\n",
      "Epoch 5:  70%|██████▉   | 11868/16955 [00:53<00:23, 219.79it/s, loss=0.632, v_num=84fe]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 5:  70%|███████   | 11926/16955 [00:55<00:23, 214.93it/s, loss=0.632, v_num=84fe]\n",
      "Epoch 5:  71%|███████   | 12015/16955 [00:55<00:22, 216.13it/s, loss=0.632, v_num=84fe]\n",
      "Epoch 5:  71%|███████▏  | 12104/16955 [00:55<00:22, 217.32it/s, loss=0.632, v_num=84fe]\n",
      "Epoch 5:  72%|███████▏  | 12193/16955 [00:55<00:21, 218.49it/s, loss=0.632, v_num=84fe]\n",
      "Validating:   6%|▋         | 325/5087 [00:01<26:54,  2.95it/s]\u001b[A\n",
      "Epoch 5:  72%|███████▏  | 12282/16955 [00:55<00:21, 219.67it/s, loss=0.632, v_num=84fe]\n",
      "Epoch 5:  73%|███████▎  | 12371/16955 [00:56<00:20, 220.85it/s, loss=0.632, v_num=84fe]\n",
      "Epoch 5:  73%|███████▎  | 12460/16955 [00:56<00:20, 222.03it/s, loss=0.632, v_num=84fe]\n",
      "Epoch 5:  74%|███████▍  | 12549/16955 [00:56<00:19, 223.17it/s, loss=0.632, v_num=84fe]\n",
      "Epoch 5:  75%|███████▍  | 12638/16955 [00:56<00:19, 224.29it/s, loss=0.632, v_num=84fe]\n",
      "Epoch 5:  75%|███████▌  | 12727/16955 [00:56<00:18, 225.42it/s, loss=0.632, v_num=84fe]\n",
      "Epoch 5:  76%|███████▌  | 12816/16955 [00:56<00:18, 226.54it/s, loss=0.632, v_num=84fe]\n",
      "Epoch 5:  76%|███████▌  | 12905/16955 [00:56<00:17, 227.65it/s, loss=0.632, v_num=84fe]\n",
      "Epoch 5:  77%|███████▋  | 12994/16955 [00:56<00:17, 228.78it/s, loss=0.632, v_num=84fe]\n",
      "Epoch 5:  77%|███████▋  | 13083/16955 [00:56<00:16, 229.89it/s, loss=0.632, v_num=84fe]\n",
      "Epoch 5:  78%|███████▊  | 13172/16955 [00:57<00:16, 231.00it/s, loss=0.632, v_num=84fe]\n",
      "Validating:  26%|██▌       | 1304/5087 [00:03<00:22, 168.49it/s]\u001b[A\n",
      "Epoch 5:  78%|███████▊  | 13261/16955 [00:57<00:15, 232.12it/s, loss=0.632, v_num=84fe]\n",
      "Epoch 5:  79%|███████▊  | 13350/16955 [00:57<00:15, 233.23it/s, loss=0.632, v_num=84fe]\n",
      "Epoch 5:  79%|███████▉  | 13439/16955 [00:57<00:15, 234.34it/s, loss=0.632, v_num=84fe]\n",
      "Epoch 5:  80%|███████▉  | 13528/16955 [00:57<00:14, 235.45it/s, loss=0.632, v_num=84fe]\n",
      "Epoch 5:  80%|████████  | 13617/16955 [00:57<00:14, 236.53it/s, loss=0.632, v_num=84fe]\n",
      "Epoch 5:  81%|████████  | 13706/16955 [00:57<00:13, 237.62it/s, loss=0.632, v_num=84fe]\n",
      "Epoch 5:  81%|████████▏ | 13795/16955 [00:57<00:13, 238.71it/s, loss=0.632, v_num=84fe]\n",
      "Epoch 5:  82%|████████▏ | 13884/16955 [00:57<00:12, 239.79it/s, loss=0.632, v_num=84fe]\n",
      "Epoch 5:  82%|████████▏ | 13973/16955 [00:58<00:12, 240.88it/s, loss=0.632, v_num=84fe]\n",
      "Epoch 5:  83%|████████▎ | 14062/16955 [00:58<00:11, 241.95it/s, loss=0.632, v_num=84fe]\n",
      "Epoch 5:  83%|████████▎ | 14151/16955 [00:58<00:11, 243.03it/s, loss=0.632, v_num=84fe]\n",
      "Epoch 5:  84%|████████▍ | 14240/16955 [00:58<00:11, 244.07it/s, loss=0.632, v_num=84fe]\n",
      "Validating:  47%|████▋     | 2373/5087 [00:04<00:03, 768.21it/s]\u001b[A\n",
      "Epoch 5:  85%|████████▍ | 14329/16955 [00:58<00:10, 245.12it/s, loss=0.632, v_num=84fe]\n",
      "Epoch 5:  85%|████████▌ | 14418/16955 [00:58<00:10, 246.14it/s, loss=0.632, v_num=84fe]\n",
      "Epoch 5:  86%|████████▌ | 14507/16955 [00:58<00:09, 247.15it/s, loss=0.632, v_num=84fe]\n",
      "Epoch 5:  86%|████████▌ | 14596/16955 [00:58<00:09, 248.18it/s, loss=0.632, v_num=84fe]\n",
      "Epoch 5:  87%|████████▋ | 14685/16955 [00:58<00:09, 249.21it/s, loss=0.632, v_num=84fe]\n",
      "Epoch 5:  87%|████████▋ | 14774/16955 [00:59<00:08, 250.25it/s, loss=0.632, v_num=84fe]\n",
      "Epoch 5:  88%|████████▊ | 14863/16955 [00:59<00:08, 251.29it/s, loss=0.632, v_num=84fe]\n",
      "Epoch 5:  88%|████████▊ | 14952/16955 [00:59<00:07, 252.30it/s, loss=0.632, v_num=84fe]\n",
      "Epoch 5:  89%|████████▊ | 15041/16955 [00:59<00:07, 253.32it/s, loss=0.632, v_num=84fe]\n",
      "Validating:  62%|██████▏   | 3173/5087 [00:05<00:02, 785.55it/s]\u001b[A\n",
      "Epoch 5:  89%|████████▉ | 15130/16955 [00:59<00:07, 254.32it/s, loss=0.632, v_num=84fe]\n",
      "Epoch 5:  90%|████████▉ | 15219/16955 [00:59<00:06, 255.35it/s, loss=0.632, v_num=84fe]\n",
      "Epoch 5:  90%|█████████ | 15308/16955 [00:59<00:06, 256.37it/s, loss=0.632, v_num=84fe]\n",
      "Epoch 5:  91%|█████████ | 15397/16955 [00:59<00:06, 257.38it/s, loss=0.632, v_num=84fe]\n",
      "Epoch 5:  91%|█████████▏| 15486/16955 [00:59<00:05, 258.41it/s, loss=0.632, v_num=84fe]\n",
      "Epoch 5:  92%|█████████▏| 15575/16955 [01:00<00:05, 259.41it/s, loss=0.632, v_num=84fe]\n",
      "Epoch 5:  92%|█████████▏| 15664/16955 [01:00<00:04, 260.43it/s, loss=0.632, v_num=84fe]\n",
      "Epoch 5:  93%|█████████▎| 15753/16955 [01:00<00:04, 261.43it/s, loss=0.632, v_num=84fe]\n",
      "Epoch 5:  93%|█████████▎| 15842/16955 [01:00<00:04, 262.43it/s, loss=0.632, v_num=84fe]\n",
      "Epoch 5:  94%|█████████▍| 15931/16955 [01:00<00:03, 263.42it/s, loss=0.632, v_num=84fe]\n",
      "Epoch 5:  94%|█████████▍| 16020/16955 [01:00<00:03, 264.43it/s, loss=0.632, v_num=84fe]\n",
      "Epoch 5:  95%|█████████▌| 16109/16955 [01:00<00:03, 265.42it/s, loss=0.632, v_num=84fe]\n",
      "Validating:  83%|████████▎ | 4241/5087 [00:06<00:01, 815.21it/s]\u001b[A\n",
      "Epoch 5:  96%|█████████▌| 16198/16955 [01:00<00:02, 266.40it/s, loss=0.632, v_num=84fe]\n",
      "Epoch 5:  96%|█████████▌| 16287/16955 [01:00<00:02, 267.41it/s, loss=0.632, v_num=84fe]\n",
      "Epoch 5:  97%|█████████▋| 16376/16955 [01:01<00:02, 268.39it/s, loss=0.632, v_num=84fe]\n",
      "Epoch 5:  97%|█████████▋| 16465/16955 [01:01<00:01, 269.37it/s, loss=0.632, v_num=84fe]\n",
      "Epoch 5:  98%|█████████▊| 16554/16955 [01:01<00:01, 270.36it/s, loss=0.632, v_num=84fe]\n",
      "Epoch 5:  98%|█████████▊| 16643/16955 [01:01<00:01, 271.33it/s, loss=0.632, v_num=84fe]\n",
      "Epoch 5:  99%|█████████▊| 16732/16955 [01:01<00:00, 272.29it/s, loss=0.632, v_num=84fe]\n",
      "Epoch 5:  99%|█████████▉| 16821/16955 [01:01<00:00, 273.19it/s, loss=0.632, v_num=84fe]\n",
      "Epoch 5: 100%|█████████▉| 16910/16955 [01:01<00:00, 274.14it/s, loss=0.632, v_num=84fe]\n",
      "Validating: 100%|█████████▉| 5075/5087 [00:07<00:00, 793.46it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: avg_val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 16955/16955 [01:01<00:00, 273.53it/s, loss=0.632, v_num=84fe]\n",
      "Epoch 5: 100%|██████████| 16955/16955 [01:02<00:00, 270.26it/s, loss=0.632, v_num=84fe]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: ----------------------------------\n",
      "COMET INFO: Comet.ml OfflineExperiment Summary\n",
      "COMET INFO: ----------------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : [OfflineExperiment will get URL after upload]\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     avg_train_loss [6] : (0.6114534139633179, 0.6377289891242981)\n",
      "COMET INFO:     avg_val_loss [6]   : (0.62298583984375, 0.6353290677070618)\n",
      "COMET INFO:   Others:\n",
      "COMET INFO:     offline_experiment : True\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     device           : cuda\n",
      "COMET INFO:     logger           : <pytorch_lightning.loggers.comet.CometLogger object at 0x7f3082566190>\n",
      "COMET INFO:     lr               : 0.001\n",
      "COMET INFO:     max_epochs       : 30\n",
      "COMET INFO:     num_warmup_steps : 2000\n",
      "COMET INFO:     num_workers      : 12\n",
      "COMET INFO:     pin_memory       : True\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     code                     : 1 (2 KB)\n",
      "COMET INFO:     environment details      : 1\n",
      "COMET INFO:     filename                 : 1\n",
      "COMET INFO:     git metadata             : 1\n",
      "COMET INFO:     git-patch (uncompressed) : 1 (439 bytes)\n",
      "COMET INFO:     installed packages       : 1\n",
      "COMET INFO:     notebook                 : 1\n",
      "COMET INFO:     os packages              : 1\n",
      "COMET INFO: ----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Starting saving the offline archive\n",
      "COMET INFO: To upload this offline experiment, run:\n",
      "    comet upload logs/086406ea3ad14099be20c2c57cde84fe.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 13s, sys: 1min 7s, total: 7min 20s\n",
      "Wall time: 6min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the best model from checkpoint and see quite a good performance. The model is able to predict blogger's gender quite successfuly. All metrics are above 60%, F1 score is apx. 65%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EarlyStopping mode set to min for monitoring avg_val_loss.\n",
      "INFO:lightning:EarlyStopping mode set to min for monitoring avg_val_loss.\n"
     ]
    }
   ],
   "source": [
    "gender_model = Model.load_from_checkpoint(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, hparams=hparams,\\\n",
    "                                   checkpoint_path=\"./checkpoints/model-outputs-v2.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (net): Net(\n",
       "    (fc1): Linear(in_features=768, out_features=128, bias=True)\n",
       "    (fc2): Linear(in_features=128, out_features=2, bias=True)\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (loss_func): CrossEntropyLoss()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4239/4239 [00:04<00:00, 1000.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.638     0.655     0.646     66934\n",
      "           1      0.655     0.638     0.646     68699\n",
      "\n",
      "    accuracy                          0.646    135633\n",
      "   macro avg      0.646     0.646     0.646    135633\n",
      "weighted avg      0.646     0.646     0.646    135633\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gender_model = model.predict_eval(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sign model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's proceed with more challenging model. Multiclass classification task - sign prediciton. As previously, classes are well balanced. Let's create label mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_class2idx = {k: v for v, k in enumerate(sorted(df2['sign'].unique()))}\n",
    "sign_idx2class = {v: k for k, v in sign_class2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Aquarius': 0,\n",
       " 'Aries': 1,\n",
       " 'Cancer': 2,\n",
       " 'Capricorn': 3,\n",
       " 'Gemini': 4,\n",
       " 'Leo': 5,\n",
       " 'Libra': 6,\n",
       " 'Pisces': 7,\n",
       " 'Sagittarius': 8,\n",
       " 'Scorpio': 9,\n",
       " 'Taurus': 10,\n",
       " 'Virgo': 11}"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sign_class2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['sign'] = df2['sign'].map(sign_class2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exactly the same stratified samples splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2['vectors'].values\n",
    "y = df2['sign'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=17)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.3, stratify=y_trainval, random_state=43)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check and overfitting on small subsample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'fast_dev_run': True,\n",
    "    'pin_memory': True,\n",
    "    'device': device,\n",
    "    'num_workers': 12,\n",
    "    'shuffle': False,\n",
    "    'batch_size': 32,\n",
    "    'logger': comet_logger\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EarlyStopping mode set to min for monitoring avg_val_loss.\n"
     ]
    }
   ],
   "source": [
    "model = Model(X_train, y_train, X_val, y_val, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Running in fast_dev_run mode: will run a full train, val and test loop using a single batch\n",
      "\n",
      "  | Name | Type | Params \n",
      "-------------------------------\n",
      "0 | net  | Net  | 100.0 K\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|█████     | 1/2 [00:01<00:01,  1.35s/it, loss=2.510, v_num=acc5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating: 100%|██████████| 1/1 [00:01<00:00,  1.44s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: avg_val_loss reached 2.48216 (best 2.48216), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v0.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it, loss=2.510, v_num=acc5]\n",
      "Epoch 0: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it, loss=2.510, v_num=acc5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: ----------------------------------\n",
      "COMET INFO: Comet.ml OfflineExperiment Summary\n",
      "COMET INFO: ----------------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : [OfflineExperiment will get URL after upload]\n",
      "COMET INFO:   Metrics:\n",
      "COMET INFO:     avg_train_loss : 2.5097577571868896\n",
      "COMET INFO:     avg_val_loss   : 2.4821643829345703\n",
      "COMET INFO:   Others:\n",
      "COMET INFO:     offline_experiment : True\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     batch_size   : 32\n",
      "COMET INFO:     device       : cuda\n",
      "COMET INFO:     fast_dev_run : True\n",
      "COMET INFO:     logger       : <pytorch_lightning.loggers.comet.CometLogger object at 0x7f308252c4d0>\n",
      "COMET INFO:     num_workers  : 12\n",
      "COMET INFO:     pin_memory   : True\n",
      "COMET INFO:     shuffle      : 1\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     code                     : 1 (4 KB)\n",
      "COMET INFO:     environment details      : 1\n",
      "COMET INFO:     filename                 : 1\n",
      "COMET INFO:     git metadata             : 1\n",
      "COMET INFO:     git-patch (uncompressed) : 1 (439 bytes)\n",
      "COMET INFO:     installed packages       : 1\n",
      "COMET INFO:     notebook                 : 1\n",
      "COMET INFO:     os packages              : 1\n",
      "COMET INFO: ----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Starting saving the offline archive\n",
      "COMET INFO: To upload this offline experiment, run:\n",
      "    comet upload logs/9dc47277e5b8486681301f03fbc2acc5.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 128 ms, sys: 3.05 s, total: 3.18 s\n",
      "Wall time: 4.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'overfit_batches': 1e-3,\n",
    "    'num_warmup_steps': 0,\n",
    "    'pin_memory': True,\n",
    "    'device': device,\n",
    "    'num_workers': 12,\n",
    "    'max_epochs': 40,\n",
    "    'lr': 1e-3,\n",
    "    'logger': comet_logger,\n",
    "    'shuffle': False # it's important not to shuffle training samples\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EarlyStopping mode set to min for monitoring avg_val_loss.\n"
     ]
    }
   ],
   "source": [
    "model = Model(X_train, y_train, X_val, y_val, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type | Params \n",
      "-------------------------------\n",
      "0 | net  | Net  | 100.0 K\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|█████     | 11/22 [00:01<00:01,  7.06it/s, loss=2.500, v_num=1925]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  59%|█████▉    | 13/22 [00:03<00:02,  4.30it/s, loss=2.500, v_num=1925]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: avg_val_loss reached 2.26759 (best 2.26759), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v3.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 22/22 [00:03<00:00,  6.59it/s, loss=2.500, v_num=1925]\n",
      "Epoch 1:  55%|█████▍    | 12/22 [00:01<00:01,  9.35it/s, loss=2.339, v_num=1925]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:14,  1.45s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: avg_val_loss reached 2.04776 (best 2.04776), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v4.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 22/22 [00:03<00:00,  7.27it/s, loss=2.339, v_num=1925]\n",
      "Epoch 2:  55%|█████▍    | 12/22 [00:01<00:01,  8.43it/s, loss=2.098, v_num=1925]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:14,  1.44s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: avg_val_loss reached 1.84188 (best 1.84188), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v3.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 22/22 [00:03<00:00,  6.97it/s, loss=2.098, v_num=1925]\n",
      "Epoch 3:  55%|█████▍    | 12/22 [00:01<00:01,  7.26it/s, loss=1.893, v_num=1925]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:14,  1.41s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: avg_val_loss reached 1.64989 (best 1.64989), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v4.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 22/22 [00:03<00:00,  6.64it/s, loss=1.893, v_num=1925]\n",
      "Epoch 4:  55%|█████▍    | 12/22 [00:01<00:01,  8.69it/s, loss=1.699, v_num=1925]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:14,  1.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: avg_val_loss reached 1.46831 (best 1.46831), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v3.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 22/22 [00:03<00:00,  7.00it/s, loss=1.699, v_num=1925]\n",
      "Epoch 5:  55%|█████▍    | 12/22 [00:01<00:01,  8.22it/s, loss=1.517, v_num=1925]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:14,  1.48s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: avg_val_loss reached 1.29799 (best 1.29799), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v4.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 22/22 [00:03<00:00,  6.83it/s, loss=1.517, v_num=1925]\n",
      "Epoch 6:  55%|█████▍    | 12/22 [00:01<00:01,  8.19it/s, loss=1.347, v_num=1925]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:14,  1.45s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: avg_val_loss reached 1.13889 (best 1.13889), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v3.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 22/22 [00:03<00:00,  6.97it/s, loss=1.347, v_num=1925]\n",
      "Epoch 7:  55%|█████▍    | 12/22 [00:01<00:01,  9.93it/s, loss=1.187, v_num=1925]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:15,  1.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: avg_val_loss reached 0.99200 (best 0.99200), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v4.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 22/22 [00:03<00:00,  7.32it/s, loss=1.187, v_num=1925]\n",
      "Epoch 8:  55%|█████▍    | 12/22 [00:01<00:01,  7.51it/s, loss=1.039, v_num=1925]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:14,  1.46s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: avg_val_loss reached 0.85717 (best 0.85717), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v3.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 22/22 [00:03<00:00,  6.61it/s, loss=1.039, v_num=1925]\n",
      "Epoch 9:  55%|█████▍    | 12/22 [00:01<00:00, 10.33it/s, loss=0.903, v_num=1925]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:13,  1.40s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: avg_val_loss reached 0.73485 (best 0.73485), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v4.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 22/22 [00:02<00:00,  7.78it/s, loss=0.903, v_num=1925]\n",
      "Epoch 10:  55%|█████▍    | 12/22 [00:01<00:01,  7.99it/s, loss=0.778, v_num=1925]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:14,  1.48s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: avg_val_loss reached 0.62617 (best 0.62617), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v3.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 22/22 [00:03<00:00,  6.73it/s, loss=0.778, v_num=1925]\n",
      "Epoch 11:  55%|█████▍    | 12/22 [00:01<00:01,  8.08it/s, loss=0.665, v_num=1925]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:15,  1.55s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: avg_val_loss reached 0.52989 (best 0.52989), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v4.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 22/22 [00:03<00:00,  6.67it/s, loss=0.665, v_num=1925]\n",
      "Epoch 12:  55%|█████▍    | 12/22 [00:01<00:01,  7.89it/s, loss=0.565, v_num=1925]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:12,  1.29s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: avg_val_loss reached 0.44643 (best 0.44643), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v3.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 22/22 [00:03<00:00,  7.15it/s, loss=0.565, v_num=1925]\n",
      "Epoch 13:  55%|█████▍    | 12/22 [00:01<00:01,  8.41it/s, loss=0.478, v_num=1925]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:15,  1.53s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: avg_val_loss reached 0.37453 (best 0.37453), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v4.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 22/22 [00:03<00:00,  6.84it/s, loss=0.478, v_num=1925]\n",
      "Epoch 14:  55%|█████▍    | 12/22 [00:01<00:01,  7.34it/s, loss=0.401, v_num=1925]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:14,  1.42s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: avg_val_loss reached 0.31476 (best 0.31476), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v3.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 22/22 [00:03<00:00,  6.65it/s, loss=0.401, v_num=1925]\n",
      "Epoch 15:  55%|█████▍    | 12/22 [00:01<00:01,  7.39it/s, loss=0.337, v_num=1925]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:14,  1.47s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: avg_val_loss reached 0.26465 (best 0.26465), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v4.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 22/22 [00:03<00:00,  6.56it/s, loss=0.337, v_num=1925]\n",
      "Epoch 16:  55%|█████▍    | 12/22 [00:01<00:01,  7.42it/s, loss=0.283, v_num=1925]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:15,  1.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: avg_val_loss reached 0.22390 (best 0.22390), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v3.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 22/22 [00:03<00:00,  6.49it/s, loss=0.283, v_num=1925]\n",
      "Epoch 17:  55%|█████▍    | 12/22 [00:01<00:01,  7.42it/s, loss=0.239, v_num=1925]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:14,  1.43s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: avg_val_loss reached 0.19080 (best 0.19080), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v4.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 22/22 [00:03<00:00,  6.64it/s, loss=0.239, v_num=1925]\n",
      "Epoch 18:  55%|█████▍    | 12/22 [00:01<00:01,  7.69it/s, loss=0.203, v_num=1925]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:14,  1.46s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: avg_val_loss reached 0.16450 (best 0.16450), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v3.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 22/22 [00:03<00:00,  6.74it/s, loss=0.203, v_num=1925]\n",
      "Epoch 19:  55%|█████▍    | 12/22 [00:01<00:01,  7.64it/s, loss=0.174, v_num=1925]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:13,  1.30s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: avg_val_loss reached 0.14359 (best 0.14359), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v4.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 22/22 [00:03<00:00,  7.02it/s, loss=0.174, v_num=1925]\n",
      "Epoch 20:  55%|█████▍    | 12/22 [00:01<00:01,  7.22it/s, loss=0.151, v_num=1925]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:14,  1.45s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: avg_val_loss reached 0.12700 (best 0.12700), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v3.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 22/22 [00:03<00:00,  6.53it/s, loss=0.151, v_num=1925]\n",
      "Epoch 21:  55%|█████▍    | 12/22 [00:01<00:01,  8.26it/s, loss=0.133, v_num=1925]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:14,  1.48s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: avg_val_loss reached 0.11386 (best 0.11386), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v4.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 22/22 [00:03<00:00,  6.88it/s, loss=0.133, v_num=1925]\n",
      "Epoch 22:  55%|█████▍    | 12/22 [00:01<00:01,  9.42it/s, loss=0.118, v_num=1925]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:13,  1.39s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: avg_val_loss reached 0.10328 (best 0.10328), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v3.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 22/22 [00:02<00:00,  7.51it/s, loss=0.118, v_num=1925]\n",
      "Epoch 23:  55%|█████▍    | 12/22 [00:01<00:01,  8.07it/s, loss=0.107, v_num=1925]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:13,  1.40s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: avg_val_loss reached 0.09479 (best 0.09479), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v4.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 22/22 [00:03<00:00,  6.99it/s, loss=0.107, v_num=1925]\n",
      "Epoch 24:  55%|█████▍    | 12/22 [00:01<00:01,  7.38it/s, loss=0.098, v_num=1925]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:12,  1.29s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: avg_val_loss reached 0.08794 (best 0.08794), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v3.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 22/22 [00:03<00:00,  6.82it/s, loss=0.098, v_num=1925]\n",
      "Epoch 25:  55%|█████▍    | 12/22 [00:01<00:01,  8.15it/s, loss=0.090, v_num=1925]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:14,  1.43s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: avg_val_loss reached 0.08241 (best 0.08241), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v4.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 22/22 [00:03<00:00,  6.91it/s, loss=0.090, v_num=1925]\n",
      "Epoch 26:  55%|█████▍    | 12/22 [00:01<00:01,  7.66it/s, loss=0.084, v_num=1925]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:14,  1.47s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: avg_val_loss reached 0.07798 (best 0.07798), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v3.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 22/22 [00:03<00:00,  6.66it/s, loss=0.084, v_num=1925]\n",
      "Epoch 27:  55%|█████▍    | 12/22 [00:01<00:01,  8.16it/s, loss=0.080, v_num=1925]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:15,  1.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: avg_val_loss reached 0.07442 (best 0.07442), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v4.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 22/22 [00:03<00:00,  6.81it/s, loss=0.080, v_num=1925]\n",
      "Epoch 28:  55%|█████▍    | 12/22 [00:01<00:01,  8.17it/s, loss=0.076, v_num=1925]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:12,  1.27s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: avg_val_loss reached 0.07158 (best 0.07158), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v3.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 22/22 [00:03<00:00,  7.33it/s, loss=0.076, v_num=1925]\n",
      "Epoch 29:  55%|█████▍    | 12/22 [00:01<00:01,  7.62it/s, loss=0.073, v_num=1925]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:13,  1.39s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: avg_val_loss reached 0.06927 (best 0.06927), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v4.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 22/22 [00:03<00:00,  6.79it/s, loss=0.073, v_num=1925]\n",
      "Epoch 30:  55%|█████▍    | 12/22 [00:01<00:01,  8.07it/s, loss=0.070, v_num=1925]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:13,  1.36s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: avg_val_loss reached 0.06743 (best 0.06743), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v3.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 22/22 [00:03<00:00,  7.10it/s, loss=0.070, v_num=1925]\n",
      "Epoch 31:  55%|█████▍    | 12/22 [00:01<00:01,  8.56it/s, loss=0.068, v_num=1925]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:15,  1.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: avg_val_loss reached 0.06598 (best 0.06598), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v4.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 22/22 [00:03<00:00,  6.91it/s, loss=0.068, v_num=1925]\n",
      "Epoch 32:  55%|█████▍    | 12/22 [00:01<00:01,  8.42it/s, loss=0.067, v_num=1925]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:14,  1.41s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: avg_val_loss reached 0.06484 (best 0.06484), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v3.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 22/22 [00:03<00:00,  7.11it/s, loss=0.067, v_num=1925]\n",
      "Epoch 33:  55%|█████▍    | 12/22 [00:01<00:01,  7.57it/s, loss=0.066, v_num=1925]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:13,  1.40s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: avg_val_loss reached 0.06398 (best 0.06398), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v4.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 22/22 [00:03<00:00,  6.79it/s, loss=0.066, v_num=1925]\n",
      "Epoch 34:  55%|█████▍    | 12/22 [00:01<00:01,  8.76it/s, loss=0.065, v_num=1925]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:13,  1.37s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: avg_val_loss reached 0.06335 (best 0.06335), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v3.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 22/22 [00:03<00:00,  7.31it/s, loss=0.065, v_num=1925]\n",
      "Epoch 35:  55%|█████▍    | 12/22 [00:01<00:01,  8.29it/s, loss=0.064, v_num=1925]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:13,  1.39s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: avg_val_loss reached 0.06291 (best 0.06291), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v4.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 22/22 [00:03<00:00,  7.10it/s, loss=0.064, v_num=1925]\n",
      "Epoch 36:  55%|█████▍    | 12/22 [00:01<00:01,  8.39it/s, loss=0.063, v_num=1925]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:14,  1.45s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: avg_val_loss reached 0.06263 (best 0.06263), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v3.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 22/22 [00:03<00:00,  7.00it/s, loss=0.063, v_num=1925]\n",
      "Epoch 37:  55%|█████▍    | 12/22 [00:01<00:01,  8.88it/s, loss=0.063, v_num=1925]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:14,  1.47s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: avg_val_loss reached 0.06247 (best 0.06247), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v4.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 22/22 [00:03<00:00,  7.14it/s, loss=0.063, v_num=1925]\n",
      "Epoch 37: 100%|██████████| 22/22 [00:03<00:00,  6.57it/s, loss=0.063, v_num=1925]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: ----------------------------------\n",
      "COMET INFO: Comet.ml OfflineExperiment Summary\n",
      "COMET INFO: ----------------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : [OfflineExperiment will get URL after upload]\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     avg_train_loss [38] : (0.06259336322546005, 2.5002431869506836)\n",
      "COMET INFO:     avg_val_loss [38]   : (0.062467437237501144, 2.2675886154174805)\n",
      "COMET INFO:   Others:\n",
      "COMET INFO:     offline_experiment : True\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     device           : cuda\n",
      "COMET INFO:     logger           : <pytorch_lightning.loggers.comet.CometLogger object at 0x7f306e6f0510>\n",
      "COMET INFO:     lr               : 0.001\n",
      "COMET INFO:     max_epochs       : 40\n",
      "COMET INFO:     num_warmup_steps : 1\n",
      "COMET INFO:     num_workers      : 12\n",
      "COMET INFO:     overfit_batches  : 0.001\n",
      "COMET INFO:     pin_memory       : True\n",
      "COMET INFO:     shuffle          : 1\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     code                     : 1 (4 KB)\n",
      "COMET INFO:     environment details      : 1\n",
      "COMET INFO:     filename                 : 1\n",
      "COMET INFO:     git metadata             : 1\n",
      "COMET INFO:     git-patch (uncompressed) : 1 (439 bytes)\n",
      "COMET INFO:     installed packages       : 1\n",
      "COMET INFO:     notebook                 : 1\n",
      "COMET INFO:     os packages              : 1\n",
      "COMET INFO: ----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Starting saving the offline archive\n",
      "COMET INFO: To upload this offline experiment, run:\n",
      "    comet upload logs/36638a1ddfd246db882aea0fd58f1925.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.7 s, sys: 1min 57s, total: 2min 1s\n",
      "Wall time: 2min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add a dropout this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'pin_memory': True,\n",
    "    'device': device,\n",
    "    'num_workers': 12,\n",
    "    'logger': comet_logger,\n",
    "    'max_epochs': 30,\n",
    "    'lr': 1e-3,\n",
    "    'num_warmup_steps': 2000,\n",
    "    'dropout': 0.2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EarlyStopping mode set to min for monitoring avg_val_loss.\n"
     ]
    }
   ],
   "source": [
    "model = Model(X_train, y_train, X_val, y_val, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (net): Net(\n",
       "    (fc1): Linear(in_features=768, out_features=128, bias=True)\n",
       "    (fc2): Linear(in_features=128, out_features=12, bias=True)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "    (loss_func): CrossEntropyLoss()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trditionally checking metrics before learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4239/4239 [00:04<00:00, 1035.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.073     0.019     0.030      9893\n",
      "           1      0.094     0.109     0.101     12961\n",
      "           2      0.095     0.078     0.086     12949\n",
      "           3      0.060     0.006     0.011      9801\n",
      "           4      0.077     0.334     0.125     10344\n",
      "           5      0.073     0.016     0.026     10708\n",
      "           6      0.090     0.001     0.001     12412\n",
      "           7      0.080     0.306     0.126     10757\n",
      "           8      0.065     0.001     0.001      9963\n",
      "           9      0.115     0.001     0.001     11370\n",
      "          10      0.097     0.002     0.005     12453\n",
      "          11      0.091     0.131     0.107     12022\n",
      "\n",
      "    accuracy                          0.083    135633\n",
      "   macro avg      0.084     0.083     0.052    135633\n",
      "weighted avg      0.085     0.083     0.053    135633\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict_eval(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type | Params \n",
      "-------------------------------\n",
      "0 | net  | Net  | 100.0 K\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  70%|██████▉   | 11868/16955 [00:53<00:22, 223.48it/s, loss=2.465, v_num=e839]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  70%|███████   | 11880/16955 [00:54<00:23, 218.26it/s, loss=2.465, v_num=e839]\n",
      "Epoch 0:  71%|███████   | 11978/16955 [00:54<00:22, 219.65it/s, loss=2.465, v_num=e839]\n",
      "Epoch 0:  71%|███████   | 12076/16955 [00:54<00:22, 220.97it/s, loss=2.465, v_num=e839]\n",
      "Epoch 0:  72%|███████▏  | 12174/16955 [00:54<00:21, 222.30it/s, loss=2.465, v_num=e839]\n",
      "Epoch 0:  72%|███████▏  | 12272/16955 [00:54<00:20, 223.62it/s, loss=2.465, v_num=e839]\n",
      "Validating:   8%|▊         | 407/5087 [00:01<16:46,  4.65it/s]\u001b[A\n",
      "Epoch 0:  73%|███████▎  | 12370/16955 [00:54<00:20, 224.93it/s, loss=2.465, v_num=e839]\n",
      "Epoch 0:  74%|███████▎  | 12468/16955 [00:55<00:19, 226.25it/s, loss=2.465, v_num=e839]\n",
      "Epoch 0:  74%|███████▍  | 12566/16955 [00:55<00:19, 227.56it/s, loss=2.465, v_num=e839]\n",
      "Epoch 0:  75%|███████▍  | 12664/16955 [00:55<00:18, 228.85it/s, loss=2.465, v_num=e839]\n",
      "Epoch 0:  75%|███████▌  | 12762/16955 [00:55<00:18, 230.15it/s, loss=2.465, v_num=e839]\n",
      "Epoch 0:  76%|███████▌  | 12860/16955 [00:55<00:17, 231.46it/s, loss=2.465, v_num=e839]\n",
      "Epoch 0:  76%|███████▋  | 12958/16955 [00:55<00:17, 232.75it/s, loss=2.465, v_num=e839]\n",
      "Epoch 0:  77%|███████▋  | 13056/16955 [00:55<00:16, 234.03it/s, loss=2.465, v_num=e839]\n",
      "Validating:  23%|██▎       | 1189/5087 [00:02<00:38, 102.11it/s]\u001b[A\n",
      "Epoch 0:  78%|███████▊  | 13154/16955 [00:55<00:16, 235.29it/s, loss=2.465, v_num=e839]\n",
      "Epoch 0:  78%|███████▊  | 13252/16955 [00:56<00:15, 236.56it/s, loss=2.465, v_num=e839]\n",
      "Epoch 0:  79%|███████▊  | 13350/16955 [00:56<00:15, 237.82it/s, loss=2.465, v_num=e839]\n",
      "Epoch 0:  79%|███████▉  | 13448/16955 [00:56<00:14, 239.09it/s, loss=2.465, v_num=e839]\n",
      "Epoch 0:  80%|███████▉  | 13546/16955 [00:56<00:14, 240.35it/s, loss=2.465, v_num=e839]\n",
      "Epoch 0:  80%|████████  | 13644/16955 [00:56<00:13, 241.60it/s, loss=2.465, v_num=e839]\n",
      "Epoch 0:  81%|████████  | 13742/16955 [00:56<00:13, 242.85it/s, loss=2.465, v_num=e839]\n",
      "Epoch 0:  82%|████████▏ | 13840/16955 [00:56<00:12, 244.10it/s, loss=2.465, v_num=e839]\n",
      "Validating:  39%|███▉      | 1973/5087 [00:03<00:04, 666.32it/s]\u001b[A\n",
      "Epoch 0:  82%|████████▏ | 13938/16955 [00:56<00:12, 245.33it/s, loss=2.465, v_num=e839]\n",
      "Epoch 0:  83%|████████▎ | 14036/16955 [00:56<00:11, 246.56it/s, loss=2.465, v_num=e839]\n",
      "Epoch 0:  83%|████████▎ | 14134/16955 [00:57<00:11, 247.79it/s, loss=2.465, v_num=e839]\n",
      "Epoch 0:  84%|████████▍ | 14232/16955 [00:57<00:10, 248.96it/s, loss=2.465, v_num=e839]\n",
      "Epoch 0:  85%|████████▍ | 14330/16955 [00:57<00:10, 250.18it/s, loss=2.465, v_num=e839]\n",
      "Epoch 0:  85%|████████▌ | 14428/16955 [00:57<00:10, 251.39it/s, loss=2.465, v_num=e839]\n",
      "Epoch 0:  86%|████████▌ | 14526/16955 [00:57<00:09, 252.61it/s, loss=2.465, v_num=e839]\n",
      "Epoch 0:  86%|████████▋ | 14624/16955 [00:57<00:09, 253.82it/s, loss=2.465, v_num=e839]\n",
      "Validating:  54%|█████▍    | 2757/5087 [00:04<00:02, 855.60it/s]\u001b[A\n",
      "Epoch 0:  87%|████████▋ | 14722/16955 [00:57<00:08, 255.02it/s, loss=2.465, v_num=e839]\n",
      "Epoch 0:  87%|████████▋ | 14820/16955 [00:57<00:08, 256.21it/s, loss=2.465, v_num=e839]\n",
      "Epoch 0:  88%|████████▊ | 14918/16955 [00:57<00:07, 257.40it/s, loss=2.465, v_num=e839]\n",
      "Epoch 0:  89%|████████▊ | 15016/16955 [00:58<00:07, 258.58it/s, loss=2.465, v_num=e839]\n",
      "Epoch 0:  89%|████████▉ | 15114/16955 [00:58<00:07, 259.74it/s, loss=2.465, v_num=e839]\n",
      "Epoch 0:  90%|████████▉ | 15212/16955 [00:58<00:06, 260.91it/s, loss=2.465, v_num=e839]\n",
      "Epoch 0:  90%|█████████ | 15310/16955 [00:58<00:06, 262.08it/s, loss=2.465, v_num=e839]\n",
      "Validating:  68%|██████▊   | 3452/5087 [00:05<00:01, 854.33it/s]\u001b[A\n",
      "Epoch 0:  91%|█████████ | 15408/16955 [00:58<00:05, 263.23it/s, loss=2.465, v_num=e839]\n",
      "Epoch 0:  91%|█████████▏| 15506/16955 [00:58<00:05, 264.40it/s, loss=2.465, v_num=e839]\n",
      "Epoch 0:  92%|█████████▏| 15604/16955 [00:58<00:05, 265.56it/s, loss=2.465, v_num=e839]\n",
      "Epoch 0:  93%|█████████▎| 15702/16955 [00:58<00:04, 266.71it/s, loss=2.465, v_num=e839]\n",
      "Epoch 0:  93%|█████████▎| 15800/16955 [00:58<00:04, 267.84it/s, loss=2.465, v_num=e839]\n",
      "Epoch 0:  94%|█████████▍| 15898/16955 [00:59<00:03, 268.97it/s, loss=2.465, v_num=e839]\n",
      "Epoch 0:  94%|█████████▍| 15996/16955 [00:59<00:03, 270.10it/s, loss=2.465, v_num=e839]\n",
      "Epoch 0:  95%|█████████▍| 16094/16955 [00:59<00:03, 271.19it/s, loss=2.465, v_num=e839]\n",
      "Validating:  83%|████████▎ | 4230/5087 [00:06<00:01, 823.49it/s]\u001b[A\n",
      "Epoch 0:  95%|█████████▌| 16192/16955 [00:59<00:02, 272.26it/s, loss=2.465, v_num=e839]\n",
      "Epoch 0:  96%|█████████▌| 16290/16955 [00:59<00:02, 273.36it/s, loss=2.465, v_num=e839]\n",
      "Epoch 0:  97%|█████████▋| 16388/16955 [00:59<00:02, 274.45it/s, loss=2.465, v_num=e839]\n",
      "Epoch 0:  97%|█████████▋| 16486/16955 [00:59<00:01, 275.55it/s, loss=2.465, v_num=e839]\n",
      "Epoch 0:  98%|█████████▊| 16584/16955 [00:59<00:01, 276.64it/s, loss=2.465, v_num=e839]\n",
      "Epoch 0:  98%|█████████▊| 16682/16955 [01:00<00:00, 277.74it/s, loss=2.465, v_num=e839]\n",
      "Validating:  95%|█████████▍| 4814/5087 [00:06<00:00, 829.69it/s]\u001b[A\n",
      "Epoch 0:  99%|█████████▉| 16780/16955 [01:00<00:00, 278.83it/s, loss=2.465, v_num=e839]\n",
      "Epoch 0: 100%|█████████▉| 16878/16955 [01:00<00:00, 279.91it/s, loss=2.465, v_num=e839]\n",
      "Validating: 100%|█████████▉| 5069/5087 [00:07<00:00, 838.26it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: avg_val_loss reached 2.46381 (best 2.46381), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v3.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 16955/16955 [01:00<00:00, 279.68it/s, loss=2.465, v_num=e839]\n",
      "Epoch 1:  70%|██████▉   | 11868/16955 [00:53<00:22, 223.05it/s, loss=2.457, v_num=e839]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 1/5087 [00:01<1:58:12,  1.39s/it]\u001b[A\n",
      "Epoch 1:  71%|███████   | 11956/16955 [00:54<00:22, 218.48it/s, loss=2.457, v_num=e839]\n",
      "Epoch 1:  71%|███████   | 12054/16955 [00:54<00:22, 219.79it/s, loss=2.457, v_num=e839]\n",
      "Epoch 1:  72%|███████▏  | 12152/16955 [00:54<00:21, 221.10it/s, loss=2.457, v_num=e839]\n",
      "Epoch 1:  72%|███████▏  | 12250/16955 [00:55<00:21, 222.40it/s, loss=2.457, v_num=e839]\n",
      "Epoch 1:  73%|███████▎  | 12348/16955 [00:55<00:20, 223.70it/s, loss=2.457, v_num=e839]\n",
      "Validating:  10%|▉         | 486/5087 [00:01<12:39,  6.06it/s]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 12446/16955 [00:55<00:20, 224.96it/s, loss=2.457, v_num=e839]\n",
      "Epoch 1:  74%|███████▍  | 12544/16955 [00:55<00:19, 226.24it/s, loss=2.457, v_num=e839]\n",
      "Epoch 1:  75%|███████▍  | 12642/16955 [00:55<00:18, 227.54it/s, loss=2.457, v_num=e839]\n",
      "Epoch 1:  75%|███████▌  | 12740/16955 [00:55<00:18, 228.80it/s, loss=2.457, v_num=e839]\n",
      "Epoch 1:  76%|███████▌  | 12838/16955 [00:55<00:17, 230.05it/s, loss=2.457, v_num=e839]\n",
      "Validating:  19%|█▉        | 976/5087 [00:02<01:24, 48.72it/s]\u001b[A\n",
      "Epoch 1:  76%|███████▋  | 12936/16955 [00:55<00:17, 231.27it/s, loss=2.457, v_num=e839]\n",
      "Epoch 1:  77%|███████▋  | 13034/16955 [00:56<00:16, 232.52it/s, loss=2.457, v_num=e839]\n",
      "Epoch 1:  77%|███████▋  | 13132/16955 [00:56<00:16, 233.76it/s, loss=2.457, v_num=e839]\n",
      "Epoch 1:  78%|███████▊  | 13230/16955 [00:56<00:15, 235.01it/s, loss=2.457, v_num=e839]\n",
      "Epoch 1:  79%|███████▊  | 13328/16955 [00:56<00:15, 236.26it/s, loss=2.457, v_num=e839]\n",
      "Validating:  29%|██▉       | 1467/5087 [00:03<00:12, 286.03it/s]\u001b[A\n",
      "Epoch 1:  79%|███████▉  | 13426/16955 [00:56<00:14, 237.47it/s, loss=2.457, v_num=e839]\n",
      "Epoch 1:  80%|███████▉  | 13524/16955 [00:56<00:14, 238.62it/s, loss=2.457, v_num=e839]\n",
      "Epoch 1:  80%|████████  | 13622/16955 [00:56<00:13, 239.85it/s, loss=2.457, v_num=e839]\n",
      "Epoch 1:  81%|████████  | 13720/16955 [00:56<00:13, 241.05it/s, loss=2.457, v_num=e839]\n",
      "Epoch 1:  81%|████████▏ | 13818/16955 [00:57<00:12, 242.23it/s, loss=2.457, v_num=e839]\n",
      "Validating:  38%|███▊      | 1950/5087 [00:03<00:04, 647.59it/s]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 13916/16955 [00:57<00:12, 243.42it/s, loss=2.457, v_num=e839]\n",
      "Epoch 1:  83%|████████▎ | 14014/16955 [00:57<00:12, 244.62it/s, loss=2.457, v_num=e839]\n",
      "Epoch 1:  83%|████████▎ | 14112/16955 [00:57<00:11, 245.80it/s, loss=2.457, v_num=e839]\n",
      "Epoch 1:  84%|████████▍ | 14210/16955 [00:57<00:11, 246.95it/s, loss=2.457, v_num=e839]\n",
      "Validating:  46%|████▋     | 2353/5087 [00:04<00:03, 750.85it/s]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 14308/16955 [00:57<00:10, 248.10it/s, loss=2.457, v_num=e839]\n",
      "Epoch 1:  85%|████████▍ | 14406/16955 [00:57<00:10, 249.28it/s, loss=2.457, v_num=e839]\n",
      "Epoch 1:  86%|████████▌ | 14504/16955 [00:57<00:09, 250.47it/s, loss=2.457, v_num=e839]\n",
      "Epoch 1:  86%|████████▌ | 14602/16955 [00:58<00:09, 251.64it/s, loss=2.457, v_num=e839]\n",
      "Epoch 1:  87%|████████▋ | 14700/16955 [00:58<00:08, 252.79it/s, loss=2.457, v_num=e839]\n",
      "Validating:  56%|█████▌    | 2844/5087 [00:04<00:02, 797.49it/s]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 14798/16955 [00:58<00:08, 253.94it/s, loss=2.457, v_num=e839]\n",
      "Epoch 1:  88%|████████▊ | 14896/16955 [00:58<00:08, 255.13it/s, loss=2.457, v_num=e839]\n",
      "Epoch 1:  88%|████████▊ | 14994/16955 [00:58<00:07, 256.28it/s, loss=2.457, v_num=e839]\n",
      "Epoch 1:  89%|████████▉ | 15092/16955 [00:58<00:07, 257.44it/s, loss=2.457, v_num=e839]\n",
      "Epoch 1:  90%|████████▉ | 15190/16955 [00:58<00:06, 258.60it/s, loss=2.457, v_num=e839]\n",
      "Epoch 1:  90%|█████████ | 15288/16955 [00:58<00:06, 259.74it/s, loss=2.457, v_num=e839]\n",
      "Validating:  67%|██████▋   | 3432/5087 [00:05<00:02, 818.17it/s]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 15386/16955 [00:58<00:06, 260.85it/s, loss=2.457, v_num=e839]\n",
      "Epoch 1:  91%|█████████▏| 15484/16955 [00:59<00:05, 261.98it/s, loss=2.457, v_num=e839]\n",
      "Epoch 1:  92%|█████████▏| 15582/16955 [00:59<00:05, 263.09it/s, loss=2.457, v_num=e839]\n",
      "Epoch 1:  92%|█████████▏| 15680/16955 [00:59<00:04, 264.20it/s, loss=2.457, v_num=e839]\n",
      "Epoch 1:  93%|█████████▎| 15778/16955 [00:59<00:04, 265.30it/s, loss=2.457, v_num=e839]\n",
      "Epoch 1:  94%|█████████▎| 15876/16955 [00:59<00:04, 266.42it/s, loss=2.457, v_num=e839]\n",
      "Validating:  79%|███████▉  | 4008/5087 [00:06<00:01, 804.87it/s]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 15974/16955 [00:59<00:03, 267.51it/s, loss=2.457, v_num=e839]\n",
      "Epoch 1:  95%|█████████▍| 16072/16955 [00:59<00:03, 268.61it/s, loss=2.457, v_num=e839]\n",
      "Epoch 1:  95%|█████████▌| 16170/16955 [00:59<00:02, 269.73it/s, loss=2.457, v_num=e839]\n",
      "Epoch 1:  96%|█████████▌| 16268/16955 [01:00<00:02, 270.81it/s, loss=2.457, v_num=e839]\n",
      "Epoch 1:  97%|█████████▋| 16366/16955 [01:00<00:02, 271.92it/s, loss=2.457, v_num=e839]\n",
      "Validating:  89%|████████▊ | 4510/5087 [00:06<00:00, 822.10it/s]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 16464/16955 [01:00<00:01, 273.01it/s, loss=2.457, v_num=e839]\n",
      "Epoch 1:  98%|█████████▊| 16562/16955 [01:00<00:01, 274.11it/s, loss=2.457, v_num=e839]\n",
      "Epoch 1:  98%|█████████▊| 16660/16955 [01:00<00:01, 275.18it/s, loss=2.457, v_num=e839]\n",
      "Epoch 1:  99%|█████████▉| 16758/16955 [01:00<00:00, 276.24it/s, loss=2.457, v_num=e839]\n",
      "Epoch 1:  99%|█████████▉| 16856/16955 [01:00<00:00, 277.33it/s, loss=2.457, v_num=e839]\n",
      "Epoch 1: 100%|█████████▉| 16954/16955 [01:00<00:00, 278.39it/s, loss=2.457, v_num=e839]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: avg_val_loss reached 2.45950 (best 2.45950), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v5.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 16955/16955 [01:01<00:00, 277.22it/s, loss=2.457, v_num=e839]\n",
      "Epoch 2:  70%|██████▉   | 11868/16955 [00:52<00:22, 225.61it/s, loss=2.454, v_num=e839]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 1/5087 [00:01<1:42:45,  1.21s/it]\u001b[A\n",
      "Epoch 2:  71%|███████   | 11956/16955 [00:53<00:22, 221.58it/s, loss=2.454, v_num=e839]\n",
      "Epoch 2:  71%|███████   | 12054/16955 [00:54<00:21, 222.87it/s, loss=2.454, v_num=e839]\n",
      "Epoch 2:  72%|███████▏  | 12152/16955 [00:54<00:21, 224.21it/s, loss=2.454, v_num=e839]\n",
      "Epoch 2:  72%|███████▏  | 12250/16955 [00:54<00:20, 225.53it/s, loss=2.454, v_num=e839]\n",
      "Validating:   8%|▊         | 385/5087 [00:01<16:02,  4.88it/s]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 12348/16955 [00:54<00:20, 226.83it/s, loss=2.454, v_num=e839]\n",
      "Epoch 2:  73%|███████▎  | 12446/16955 [00:54<00:19, 228.15it/s, loss=2.454, v_num=e839]\n",
      "Epoch 2:  74%|███████▍  | 12544/16955 [00:54<00:19, 229.46it/s, loss=2.454, v_num=e839]\n",
      "Epoch 2:  75%|███████▍  | 12642/16955 [00:54<00:18, 230.76it/s, loss=2.454, v_num=e839]\n",
      "Epoch 2:  75%|███████▌  | 12740/16955 [00:54<00:18, 232.05it/s, loss=2.454, v_num=e839]\n",
      "Epoch 2:  76%|███████▌  | 12838/16955 [00:55<00:17, 233.35it/s, loss=2.454, v_num=e839]\n",
      "Validating:  19%|█▉        | 976/5087 [00:02<01:13, 55.70it/s]\u001b[A\n",
      "Epoch 2:  76%|███████▋  | 12936/16955 [00:55<00:17, 234.62it/s, loss=2.454, v_num=e839]\n",
      "Epoch 2:  77%|███████▋  | 13034/16955 [00:55<00:16, 235.87it/s, loss=2.454, v_num=e839]\n",
      "Epoch 2:  77%|███████▋  | 13132/16955 [00:55<00:16, 237.11it/s, loss=2.454, v_num=e839]\n",
      "Epoch 2:  78%|███████▊  | 13230/16955 [00:55<00:15, 238.37it/s, loss=2.454, v_num=e839]\n",
      "Epoch 2:  79%|███████▊  | 13328/16955 [00:55<00:15, 239.63it/s, loss=2.454, v_num=e839]\n",
      "Epoch 2:  79%|███████▉  | 13426/16955 [00:55<00:14, 240.85it/s, loss=2.454, v_num=e839]\n",
      "Validating:  31%|███       | 1558/5087 [00:03<00:09, 379.91it/s]\u001b[A\n",
      "Epoch 2:  80%|███████▉  | 13524/16955 [00:55<00:14, 242.00it/s, loss=2.454, v_num=e839]\n",
      "Epoch 2:  80%|████████  | 13622/16955 [00:56<00:13, 243.24it/s, loss=2.454, v_num=e839]\n",
      "Epoch 2:  81%|████████  | 13720/16955 [00:56<00:13, 244.48it/s, loss=2.454, v_num=e839]\n",
      "Epoch 2:  81%|████████▏ | 13818/16955 [00:56<00:12, 245.66it/s, loss=2.454, v_num=e839]\n",
      "Validating:  39%|███▊      | 1966/5087 [00:03<00:04, 659.65it/s]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 13916/16955 [00:56<00:12, 246.83it/s, loss=2.454, v_num=e839]\n",
      "Epoch 2:  83%|████████▎ | 14014/16955 [00:56<00:11, 248.01it/s, loss=2.454, v_num=e839]\n",
      "Epoch 2:  83%|████████▎ | 14112/16955 [00:56<00:11, 249.23it/s, loss=2.454, v_num=e839]\n",
      "Epoch 2:  84%|████████▍ | 14210/16955 [00:56<00:10, 250.41it/s, loss=2.454, v_num=e839]\n",
      "Epoch 2:  84%|████████▍ | 14308/16955 [00:56<00:10, 251.60it/s, loss=2.454, v_num=e839]\n",
      "Validating:  48%|████▊     | 2450/5087 [00:04<00:03, 781.55it/s]\u001b[A\n",
      "Epoch 2:  85%|████████▍ | 14406/16955 [00:56<00:10, 252.76it/s, loss=2.454, v_num=e839]\n",
      "Epoch 2:  86%|████████▌ | 14504/16955 [00:57<00:09, 253.93it/s, loss=2.454, v_num=e839]\n",
      "Epoch 2:  86%|████████▌ | 14602/16955 [00:57<00:09, 255.09it/s, loss=2.454, v_num=e839]\n",
      "Epoch 2:  87%|████████▋ | 14700/16955 [00:57<00:08, 256.24it/s, loss=2.454, v_num=e839]\n",
      "Epoch 2:  87%|████████▋ | 14798/16955 [00:57<00:08, 257.42it/s, loss=2.454, v_num=e839]\n",
      "Validating:  58%|█████▊    | 2935/5087 [00:04<00:02, 801.43it/s]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 14896/16955 [00:57<00:07, 258.59it/s, loss=2.454, v_num=e839]\n",
      "Epoch 2:  88%|████████▊ | 14994/16955 [00:57<00:07, 259.76it/s, loss=2.454, v_num=e839]\n",
      "Epoch 2:  89%|████████▉ | 15092/16955 [00:57<00:07, 260.93it/s, loss=2.454, v_num=e839]\n",
      "Epoch 2:  90%|████████▉ | 15190/16955 [00:57<00:06, 262.09it/s, loss=2.454, v_num=e839]\n",
      "Epoch 2:  90%|█████████ | 15288/16955 [00:58<00:06, 263.25it/s, loss=2.454, v_num=e839]\n",
      "Epoch 2:  91%|█████████ | 15386/16955 [00:58<00:05, 264.41it/s, loss=2.454, v_num=e839]\n",
      "Validating:  69%|██████▉   | 3527/5087 [00:05<00:01, 832.01it/s]\u001b[A\n",
      "Epoch 2:  91%|█████████▏| 15484/16955 [00:58<00:05, 265.55it/s, loss=2.454, v_num=e839]\n",
      "Epoch 2:  92%|█████████▏| 15582/16955 [00:58<00:05, 266.70it/s, loss=2.454, v_num=e839]\n",
      "Epoch 2:  92%|█████████▏| 15680/16955 [00:58<00:04, 267.83it/s, loss=2.454, v_num=e839]\n",
      "Epoch 2:  93%|█████████▎| 15778/16955 [00:58<00:04, 268.97it/s, loss=2.454, v_num=e839]\n",
      "Epoch 2:  94%|█████████▎| 15876/16955 [00:58<00:03, 270.10it/s, loss=2.454, v_num=e839]\n",
      "Epoch 2:  94%|█████████▍| 15974/16955 [00:58<00:03, 271.21it/s, loss=2.454, v_num=e839]\n",
      "Epoch 2:  95%|█████████▍| 16072/16955 [00:59<00:03, 272.34it/s, loss=2.454, v_num=e839]\n",
      "Validating:  83%|████████▎ | 4204/5087 [00:06<00:01, 832.54it/s]\u001b[A\n",
      "Epoch 2:  95%|█████████▌| 16170/16955 [00:59<00:02, 273.38it/s, loss=2.454, v_num=e839]\n",
      "Epoch 2:  96%|█████████▌| 16268/16955 [00:59<00:02, 274.47it/s, loss=2.454, v_num=e839]\n",
      "Epoch 2:  97%|█████████▋| 16366/16955 [00:59<00:02, 275.58it/s, loss=2.454, v_num=e839]\n",
      "Epoch 2:  97%|█████████▋| 16464/16955 [00:59<00:01, 276.65it/s, loss=2.454, v_num=e839]\n",
      "Epoch 2:  98%|█████████▊| 16562/16955 [00:59<00:01, 277.73it/s, loss=2.454, v_num=e839]\n",
      "Validating:  92%|█████████▏| 4695/5087 [00:07<00:00, 795.40it/s]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 16660/16955 [00:59<00:01, 278.79it/s, loss=2.454, v_num=e839]\n",
      "Epoch 2:  99%|█████████▉| 16758/16955 [00:59<00:00, 279.85it/s, loss=2.454, v_num=e839]\n",
      "Epoch 2:  99%|█████████▉| 16856/16955 [01:00<00:00, 280.89it/s, loss=2.454, v_num=e839]\n",
      "Epoch 2: 100%|█████████▉| 16954/16955 [01:00<00:00, 281.94it/s, loss=2.454, v_num=e839]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: avg_val_loss reached 2.45532 (best 2.45532), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v3.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 16955/16955 [01:00<00:00, 280.85it/s, loss=2.454, v_num=e839]\n",
      "Epoch 3:  70%|██████▉   | 11868/16955 [00:52<00:22, 224.48it/s, loss=2.452, v_num=e839]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 1/5087 [00:01<2:01:35,  1.43s/it]\u001b[A\n",
      "Epoch 3:  71%|███████   | 11956/16955 [00:54<00:22, 219.62it/s, loss=2.452, v_num=e839]\n",
      "Epoch 3:  71%|███████   | 12054/16955 [00:54<00:22, 220.92it/s, loss=2.452, v_num=e839]\n",
      "Epoch 3:  72%|███████▏  | 12152/16955 [00:54<00:21, 222.24it/s, loss=2.452, v_num=e839]\n",
      "Epoch 3:  72%|███████▏  | 12250/16955 [00:54<00:21, 223.54it/s, loss=2.452, v_num=e839]\n",
      "Validating:   8%|▊         | 388/5087 [00:01<18:57,  4.13it/s]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 12348/16955 [00:54<00:20, 224.84it/s, loss=2.452, v_num=e839]\n",
      "Epoch 3:  73%|███████▎  | 12446/16955 [00:55<00:19, 226.12it/s, loss=2.452, v_num=e839]\n",
      "Epoch 3:  74%|███████▍  | 12544/16955 [00:55<00:19, 227.40it/s, loss=2.452, v_num=e839]\n",
      "Epoch 3:  75%|███████▍  | 12642/16955 [00:55<00:18, 228.69it/s, loss=2.452, v_num=e839]\n",
      "Epoch 3:  75%|███████▌  | 12740/16955 [00:55<00:18, 229.95it/s, loss=2.452, v_num=e839]\n",
      "Validating:  17%|█▋        | 880/5087 [00:02<02:04, 33.80it/s]\u001b[A\n",
      "Epoch 3:  76%|███████▌  | 12838/16955 [00:55<00:17, 231.20it/s, loss=2.452, v_num=e839]\n",
      "Epoch 3:  76%|███████▋  | 12936/16955 [00:55<00:17, 232.45it/s, loss=2.452, v_num=e839]\n",
      "Epoch 3:  77%|███████▋  | 13034/16955 [00:55<00:16, 233.71it/s, loss=2.452, v_num=e839]\n",
      "Epoch 3:  77%|███████▋  | 13132/16955 [00:55<00:16, 234.96it/s, loss=2.452, v_num=e839]\n",
      "Epoch 3:  78%|███████▊  | 13230/16955 [00:56<00:15, 236.21it/s, loss=2.452, v_num=e839]\n",
      "Validating:  27%|██▋       | 1373/5087 [00:03<00:16, 219.32it/s]\u001b[A\n",
      "Epoch 3:  79%|███████▊  | 13328/16955 [00:56<00:15, 237.43it/s, loss=2.452, v_num=e839]\n",
      "Epoch 3:  79%|███████▉  | 13426/16955 [00:56<00:14, 238.65it/s, loss=2.452, v_num=e839]\n",
      "Epoch 3:  80%|███████▉  | 13524/16955 [00:56<00:14, 239.85it/s, loss=2.452, v_num=e839]\n",
      "Epoch 3:  80%|████████  | 13622/16955 [00:56<00:13, 241.10it/s, loss=2.452, v_num=e839]\n",
      "Epoch 3:  81%|████████  | 13720/16955 [00:56<00:13, 242.36it/s, loss=2.452, v_num=e839]\n",
      "Epoch 3:  81%|████████▏ | 13818/16955 [00:56<00:12, 243.59it/s, loss=2.452, v_num=e839]\n",
      "Validating:  39%|███▊      | 1960/5087 [00:03<00:04, 679.74it/s]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 13916/16955 [00:56<00:12, 244.81it/s, loss=2.452, v_num=e839]\n",
      "Epoch 3:  83%|████████▎ | 14014/16955 [00:56<00:11, 246.01it/s, loss=2.452, v_num=e839]\n",
      "Epoch 3:  83%|████████▎ | 14112/16955 [00:57<00:11, 247.20it/s, loss=2.452, v_num=e839]\n",
      "Epoch 3:  84%|████████▍ | 14210/16955 [00:57<00:11, 248.40it/s, loss=2.452, v_num=e839]\n",
      "Epoch 3:  84%|████████▍ | 14308/16955 [00:57<00:10, 249.59it/s, loss=2.452, v_num=e839]\n",
      "Epoch 3:  85%|████████▍ | 14406/16955 [00:57<00:10, 250.76it/s, loss=2.452, v_num=e839]\n",
      "Validating:  50%|█████     | 2544/5087 [00:04<00:03, 792.56it/s]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 14504/16955 [00:57<00:09, 251.91it/s, loss=2.452, v_num=e839]\n",
      "Epoch 3:  86%|████████▌ | 14602/16955 [00:57<00:09, 253.09it/s, loss=2.452, v_num=e839]\n",
      "Epoch 3:  87%|████████▋ | 14700/16955 [00:57<00:08, 254.26it/s, loss=2.452, v_num=e839]\n",
      "Epoch 3:  87%|████████▋ | 14798/16955 [00:57<00:08, 255.43it/s, loss=2.452, v_num=e839]\n",
      "Epoch 3:  88%|████████▊ | 14896/16955 [00:58<00:08, 256.58it/s, loss=2.452, v_num=e839]\n",
      "Validating:  60%|█████▉    | 3039/5087 [00:05<00:02, 803.85it/s]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 14994/16955 [00:58<00:07, 257.72it/s, loss=2.452, v_num=e839]\n",
      "Epoch 3:  89%|████████▉ | 15092/16955 [00:58<00:07, 258.86it/s, loss=2.452, v_num=e839]\n",
      "Epoch 3:  90%|████████▉ | 15190/16955 [00:58<00:06, 260.03it/s, loss=2.452, v_num=e839]\n",
      "Epoch 3:  90%|█████████ | 15288/16955 [00:58<00:06, 261.16it/s, loss=2.452, v_num=e839]\n",
      "Epoch 3:  91%|█████████ | 15386/16955 [00:58<00:05, 262.31it/s, loss=2.452, v_num=e839]\n",
      "Epoch 3:  91%|█████████▏| 15484/16955 [00:58<00:05, 262.89it/s, loss=2.452, v_num=e839]\n",
      "Validating:  71%|███████   | 3617/5087 [00:06<00:02, 596.59it/s]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 15582/16955 [00:59<00:05, 264.02it/s, loss=2.452, v_num=e839]\n",
      "Epoch 3:  92%|█████████▏| 15680/16955 [00:59<00:04, 265.16it/s, loss=2.452, v_num=e839]\n",
      "Epoch 3:  93%|█████████▎| 15778/16955 [00:59<00:04, 266.28it/s, loss=2.452, v_num=e839]\n",
      "Epoch 3:  94%|█████████▎| 15876/16955 [00:59<00:04, 267.40it/s, loss=2.452, v_num=e839]\n",
      "Epoch 3:  94%|█████████▍| 15974/16955 [00:59<00:03, 268.51it/s, loss=2.452, v_num=e839]\n",
      "Validating:  81%|████████  | 4118/5087 [00:06<00:01, 783.23it/s]\u001b[A\n",
      "Epoch 3:  95%|█████████▍| 16072/16955 [00:59<00:03, 269.59it/s, loss=2.452, v_num=e839]\n",
      "Epoch 3:  95%|█████████▌| 16170/16955 [00:59<00:02, 270.67it/s, loss=2.452, v_num=e839]\n",
      "Epoch 3:  96%|█████████▌| 16268/16955 [00:59<00:02, 271.78it/s, loss=2.452, v_num=e839]\n",
      "Epoch 3:  97%|█████████▋| 16366/16955 [00:59<00:02, 272.87it/s, loss=2.452, v_num=e839]\n",
      "Epoch 3:  97%|█████████▋| 16464/16955 [01:00<00:01, 273.96it/s, loss=2.452, v_num=e839]\n",
      "Validating:  91%|█████████ | 4612/5087 [00:07<00:00, 802.67it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 16562/16955 [01:00<00:01, 275.00it/s, loss=2.452, v_num=e839]\n",
      "Epoch 3:  98%|█████████▊| 16660/16955 [01:00<00:01, 276.06it/s, loss=2.452, v_num=e839]\n",
      "Epoch 3:  99%|█████████▉| 16758/16955 [01:00<00:00, 277.16it/s, loss=2.452, v_num=e839]\n",
      "Epoch 3:  99%|█████████▉| 16856/16955 [01:00<00:00, 278.23it/s, loss=2.452, v_num=e839]\n",
      "Epoch 3: 100%|█████████▉| 16954/16955 [01:00<00:00, 279.30it/s, loss=2.452, v_num=e839]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: avg_val_loss reached 2.45404 (best 2.45404), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v5.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 16955/16955 [01:00<00:00, 278.22it/s, loss=2.452, v_num=e839]\n",
      "Epoch 4:  70%|██████▉   | 11868/16955 [00:52<00:22, 225.20it/s, loss=2.460, v_num=e839]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 1/5087 [00:01<1:43:38,  1.22s/it]\u001b[A\n",
      "Epoch 4:  71%|███████   | 11956/16955 [00:54<00:22, 221.19it/s, loss=2.460, v_num=e839]\n",
      "Epoch 4:  71%|███████   | 12054/16955 [00:54<00:22, 222.52it/s, loss=2.460, v_num=e839]\n",
      "Epoch 4:  72%|███████▏  | 12152/16955 [00:54<00:21, 223.83it/s, loss=2.460, v_num=e839]\n",
      "Epoch 4:  72%|███████▏  | 12250/16955 [00:54<00:20, 225.17it/s, loss=2.460, v_num=e839]\n",
      "Epoch 4:  73%|███████▎  | 12348/16955 [00:54<00:20, 226.50it/s, loss=2.460, v_num=e839]\n",
      "Validating:  10%|▉         | 489/5087 [00:01<11:06,  6.90it/s]\u001b[A\n",
      "Epoch 4:  73%|███████▎  | 12446/16955 [00:54<00:19, 227.78it/s, loss=2.460, v_num=e839]\n",
      "Epoch 4:  74%|███████▍  | 12544/16955 [00:54<00:19, 229.08it/s, loss=2.460, v_num=e839]\n",
      "Epoch 4:  75%|███████▍  | 12642/16955 [00:54<00:18, 230.38it/s, loss=2.460, v_num=e839]\n",
      "Epoch 4:  75%|███████▌  | 12740/16955 [00:54<00:18, 231.66it/s, loss=2.460, v_num=e839]\n",
      "Epoch 4:  76%|███████▌  | 12838/16955 [00:55<00:17, 232.94it/s, loss=2.460, v_num=e839]\n",
      "Epoch 4:  76%|███████▋  | 12936/16955 [00:55<00:17, 234.20it/s, loss=2.460, v_num=e839]\n",
      "Validating:  21%|██        | 1070/5087 [00:02<00:52, 76.58it/s]\u001b[A\n",
      "Epoch 4:  77%|███████▋  | 13034/16955 [00:55<00:16, 235.42it/s, loss=2.460, v_num=e839]\n",
      "Epoch 4:  77%|███████▋  | 13132/16955 [00:55<00:16, 236.67it/s, loss=2.460, v_num=e839]\n",
      "Epoch 4:  78%|███████▊  | 13230/16955 [00:55<00:15, 237.90it/s, loss=2.460, v_num=e839]\n",
      "Epoch 4:  79%|███████▊  | 13328/16955 [00:55<00:15, 239.15it/s, loss=2.460, v_num=e839]\n",
      "Validating:  29%|██▉       | 1472/5087 [00:03<00:11, 308.53it/s]\u001b[A\n",
      "Epoch 4:  79%|███████▉  | 13426/16955 [00:55<00:14, 240.34it/s, loss=2.460, v_num=e839]\n",
      "Epoch 4:  80%|███████▉  | 13524/16955 [00:55<00:14, 241.58it/s, loss=2.460, v_num=e839]\n",
      "Epoch 4:  80%|████████  | 13622/16955 [00:56<00:13, 242.84it/s, loss=2.460, v_num=e839]\n",
      "Epoch 4:  81%|████████  | 13720/16955 [00:56<00:13, 244.08it/s, loss=2.460, v_num=e839]\n",
      "Epoch 4:  81%|████████▏ | 13818/16955 [00:56<00:12, 245.31it/s, loss=2.460, v_num=e839]\n",
      "Epoch 4:  82%|████████▏ | 13916/16955 [00:56<00:12, 246.48it/s, loss=2.460, v_num=e839]\n",
      "Validating:  40%|████      | 2054/5087 [00:03<00:04, 703.48it/s]\u001b[A\n",
      "Epoch 4:  83%|████████▎ | 14014/16955 [00:56<00:11, 247.66it/s, loss=2.460, v_num=e839]\n",
      "Epoch 4:  83%|████████▎ | 14112/16955 [00:56<00:11, 248.89it/s, loss=2.460, v_num=e839]\n",
      "Epoch 4:  84%|████████▍ | 14210/16955 [00:56<00:10, 250.10it/s, loss=2.460, v_num=e839]\n",
      "Epoch 4:  84%|████████▍ | 14308/16955 [00:56<00:10, 251.31it/s, loss=2.460, v_num=e839]\n",
      "Epoch 4:  85%|████████▍ | 14406/16955 [00:57<00:10, 252.48it/s, loss=2.460, v_num=e839]\n",
      "Validating:  50%|█████     | 2553/5087 [00:04<00:03, 799.69it/s]\u001b[A\n",
      "Epoch 4:  86%|████████▌ | 14504/16955 [00:57<00:09, 253.63it/s, loss=2.460, v_num=e839]\n",
      "Epoch 4:  86%|████████▌ | 14602/16955 [00:57<00:09, 254.79it/s, loss=2.460, v_num=e839]\n",
      "Epoch 4:  87%|████████▋ | 14700/16955 [00:57<00:08, 255.99it/s, loss=2.460, v_num=e839]\n",
      "Epoch 4:  87%|████████▋ | 14798/16955 [00:57<00:08, 257.19it/s, loss=2.460, v_num=e839]\n",
      "Epoch 4:  88%|████████▊ | 14896/16955 [00:57<00:07, 258.37it/s, loss=2.460, v_num=e839]\n",
      "Epoch 4:  88%|████████▊ | 14994/16955 [00:57<00:07, 259.56it/s, loss=2.460, v_num=e839]\n",
      "Epoch 4:  89%|████████▉ | 15092/16955 [00:57<00:07, 260.73it/s, loss=2.460, v_num=e839]\n",
      "Validating:  63%|██████▎   | 3226/5087 [00:05<00:02, 838.33it/s]\u001b[A\n",
      "Epoch 4:  90%|████████▉ | 15190/16955 [00:57<00:06, 261.90it/s, loss=2.460, v_num=e839]\n",
      "Epoch 4:  90%|█████████ | 15288/16955 [00:58<00:06, 263.05it/s, loss=2.460, v_num=e839]\n",
      "Epoch 4:  91%|█████████ | 15386/16955 [00:58<00:05, 264.18it/s, loss=2.460, v_num=e839]\n",
      "Epoch 4:  91%|█████████▏| 15484/16955 [00:58<00:05, 265.32it/s, loss=2.460, v_num=e839]\n",
      "Epoch 4:  92%|█████████▏| 15582/16955 [00:58<00:05, 266.44it/s, loss=2.460, v_num=e839]\n",
      "Epoch 4:  92%|█████████▏| 15680/16955 [00:58<00:04, 267.57it/s, loss=2.460, v_num=e839]\n",
      "Validating:  75%|███████▌  | 3820/5087 [00:05<00:01, 818.96it/s]\u001b[A\n",
      "Epoch 4:  93%|█████████▎| 15778/16955 [00:58<00:04, 268.70it/s, loss=2.460, v_num=e839]\n",
      "Epoch 4:  94%|█████████▎| 15876/16955 [00:58<00:03, 269.82it/s, loss=2.460, v_num=e839]\n",
      "Epoch 4:  94%|█████████▍| 15974/16955 [00:58<00:03, 270.95it/s, loss=2.460, v_num=e839]\n",
      "Epoch 4:  95%|█████████▍| 16072/16955 [00:59<00:03, 272.08it/s, loss=2.460, v_num=e839]\n",
      "Epoch 4:  95%|█████████▌| 16170/16955 [00:59<00:02, 273.22it/s, loss=2.460, v_num=e839]\n",
      "Epoch 4:  96%|█████████▌| 16268/16955 [00:59<00:02, 274.34it/s, loss=2.460, v_num=e839]\n",
      "Epoch 4:  97%|█████████▋| 16366/16955 [00:59<00:02, 275.46it/s, loss=2.460, v_num=e839]\n",
      "Validating:  89%|████████▊ | 4503/5087 [00:06<00:00, 846.90it/s]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 16464/16955 [00:59<00:01, 276.57it/s, loss=2.460, v_num=e839]\n",
      "Epoch 4:  98%|█████████▊| 16562/16955 [00:59<00:01, 277.67it/s, loss=2.460, v_num=e839]\n",
      "Epoch 4:  98%|█████████▊| 16660/16955 [00:59<00:01, 278.78it/s, loss=2.460, v_num=e839]\n",
      "Epoch 4:  99%|█████████▉| 16758/16955 [00:59<00:00, 279.87it/s, loss=2.460, v_num=e839]\n",
      "Epoch 4:  99%|█████████▉| 16856/16955 [00:59<00:00, 280.95it/s, loss=2.460, v_num=e839]\n",
      "Epoch 4: 100%|█████████▉| 16954/16955 [01:00<00:00, 282.05it/s, loss=2.460, v_num=e839]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: avg_val_loss reached 2.45359 (best 2.45359), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v3.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 16955/16955 [01:00<00:00, 280.94it/s, loss=2.460, v_num=e839]\n",
      "Epoch 5:  70%|██████▉   | 11868/16955 [00:52<00:22, 224.55it/s, loss=2.451, v_num=e839]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 1/5087 [00:01<2:02:34,  1.45s/it]\u001b[A\n",
      "Epoch 5:  71%|███████   | 11956/16955 [00:54<00:22, 219.62it/s, loss=2.451, v_num=e839]\n",
      "Epoch 5:  71%|███████   | 12054/16955 [00:54<00:22, 220.90it/s, loss=2.451, v_num=e839]\n",
      "Epoch 5:  72%|███████▏  | 12152/16955 [00:54<00:21, 222.17it/s, loss=2.451, v_num=e839]\n",
      "Validating:   6%|▌         | 287/5087 [00:01<27:51,  2.87it/s]\u001b[A\n",
      "Epoch 5:  72%|███████▏  | 12250/16955 [00:54<00:21, 223.43it/s, loss=2.451, v_num=e839]\n",
      "Epoch 5:  73%|███████▎  | 12348/16955 [00:54<00:20, 224.74it/s, loss=2.451, v_num=e839]\n",
      "Epoch 5:  73%|███████▎  | 12446/16955 [00:55<00:19, 226.04it/s, loss=2.451, v_num=e839]\n",
      "Epoch 5:  74%|███████▍  | 12544/16955 [00:55<00:19, 227.34it/s, loss=2.451, v_num=e839]\n",
      "Epoch 5:  75%|███████▍  | 12642/16955 [00:55<00:18, 228.65it/s, loss=2.451, v_num=e839]\n",
      "Validating:  15%|█▌        | 787/5087 [00:02<03:00, 23.80it/s]\u001b[A\n",
      "Epoch 5:  75%|███████▌  | 12740/16955 [00:55<00:18, 229.90it/s, loss=2.451, v_num=e839]\n",
      "Epoch 5:  76%|███████▌  | 12838/16955 [00:55<00:17, 231.16it/s, loss=2.451, v_num=e839]\n",
      "Epoch 5:  76%|███████▋  | 12936/16955 [00:55<00:17, 232.42it/s, loss=2.451, v_num=e839]\n",
      "Epoch 5:  77%|███████▋  | 13034/16955 [00:55<00:16, 233.66it/s, loss=2.451, v_num=e839]\n",
      "Epoch 5:  77%|███████▋  | 13132/16955 [00:55<00:16, 234.89it/s, loss=2.451, v_num=e839]\n",
      "Epoch 5:  78%|███████▊  | 13230/16955 [00:56<00:15, 236.17it/s, loss=2.451, v_num=e839]\n",
      "Validating:  27%|██▋       | 1363/5087 [00:03<00:17, 218.31it/s]\u001b[A\n",
      "Epoch 5:  79%|███████▊  | 13328/16955 [00:56<00:15, 237.41it/s, loss=2.451, v_num=e839]\n",
      "Epoch 5:  79%|███████▉  | 13426/16955 [00:56<00:14, 238.63it/s, loss=2.451, v_num=e839]\n",
      "Epoch 5:  80%|███████▉  | 13524/16955 [00:56<00:14, 239.85it/s, loss=2.451, v_num=e839]\n",
      "Epoch 5:  80%|████████  | 13622/16955 [00:56<00:13, 241.06it/s, loss=2.451, v_num=e839]\n",
      "Epoch 5:  81%|████████  | 13720/16955 [00:56<00:13, 242.28it/s, loss=2.451, v_num=e839]\n",
      "Validating:  36%|███▋      | 1855/5087 [00:03<00:05, 607.78it/s]\u001b[A\n",
      "Epoch 5:  81%|████████▏ | 13818/16955 [00:56<00:12, 243.46it/s, loss=2.451, v_num=e839]\n",
      "Epoch 5:  82%|████████▏ | 13916/16955 [00:56<00:12, 244.67it/s, loss=2.451, v_num=e839]\n",
      "Epoch 5:  83%|████████▎ | 14014/16955 [00:56<00:11, 245.88it/s, loss=2.451, v_num=e839]\n",
      "Epoch 5:  83%|████████▎ | 14112/16955 [00:57<00:11, 247.07it/s, loss=2.451, v_num=e839]\n",
      "Epoch 5:  84%|████████▍ | 14210/16955 [00:57<00:11, 248.28it/s, loss=2.451, v_num=e839]\n",
      "Validating:  46%|████▌     | 2348/5087 [00:04<00:03, 788.39it/s]\u001b[A\n",
      "Epoch 5:  84%|████████▍ | 14308/16955 [00:57<00:10, 249.48it/s, loss=2.451, v_num=e839]\n",
      "Epoch 5:  85%|████████▍ | 14406/16955 [00:57<00:10, 250.66it/s, loss=2.451, v_num=e839]\n",
      "Epoch 5:  86%|████████▌ | 14504/16955 [00:57<00:09, 251.85it/s, loss=2.451, v_num=e839]\n",
      "Epoch 5:  86%|████████▌ | 14602/16955 [00:57<00:09, 253.02it/s, loss=2.451, v_num=e839]\n",
      "Epoch 5:  87%|████████▋ | 14700/16955 [00:57<00:08, 254.18it/s, loss=2.451, v_num=e839]\n",
      "Epoch 5:  87%|████████▋ | 14798/16955 [00:57<00:08, 255.34it/s, loss=2.451, v_num=e839]\n",
      "Validating:  58%|█████▊    | 2936/5087 [00:05<00:02, 807.02it/s]\u001b[A\n",
      "Epoch 5:  88%|████████▊ | 14896/16955 [00:58<00:08, 256.49it/s, loss=2.451, v_num=e839]\n",
      "Epoch 5:  88%|████████▊ | 14994/16955 [00:58<00:07, 257.63it/s, loss=2.451, v_num=e839]\n",
      "Epoch 5:  89%|████████▉ | 15092/16955 [00:58<00:07, 258.77it/s, loss=2.451, v_num=e839]\n",
      "Epoch 5:  90%|████████▉ | 15190/16955 [00:58<00:06, 259.93it/s, loss=2.451, v_num=e839]\n",
      "Epoch 5:  90%|█████████ | 15288/16955 [00:58<00:06, 261.10it/s, loss=2.451, v_num=e839]\n",
      "Epoch 5:  91%|█████████ | 15386/16955 [00:58<00:05, 262.25it/s, loss=2.451, v_num=e839]\n",
      "Validating:  69%|██████▉   | 3520/5087 [00:05<00:01, 830.11it/s]\u001b[A\n",
      "Epoch 5:  91%|█████████▏| 15484/16955 [00:58<00:05, 263.35it/s, loss=2.451, v_num=e839]\n",
      "Epoch 5:  92%|█████████▏| 15582/16955 [00:58<00:05, 264.50it/s, loss=2.451, v_num=e839]\n",
      "Epoch 5:  92%|█████████▏| 15680/16955 [00:59<00:04, 265.60it/s, loss=2.451, v_num=e839]\n",
      "Epoch 5:  93%|█████████▎| 15778/16955 [00:59<00:04, 266.74it/s, loss=2.451, v_num=e839]\n",
      "Epoch 5:  94%|█████████▎| 15876/16955 [00:59<00:04, 267.87it/s, loss=2.451, v_num=e839]\n",
      "Epoch 5:  94%|█████████▍| 15974/16955 [00:59<00:03, 269.00it/s, loss=2.451, v_num=e839]\n",
      "Validating:  81%|████████  | 4110/5087 [00:06<00:01, 833.83it/s]\u001b[A\n",
      "Epoch 5:  95%|█████████▍| 16072/16955 [00:59<00:03, 270.09it/s, loss=2.451, v_num=e839]\n",
      "Epoch 5:  95%|█████████▌| 16170/16955 [00:59<00:02, 271.17it/s, loss=2.451, v_num=e839]\n",
      "Epoch 5:  96%|█████████▌| 16268/16955 [00:59<00:02, 272.29it/s, loss=2.451, v_num=e839]\n",
      "Epoch 5:  97%|█████████▋| 16366/16955 [00:59<00:02, 273.39it/s, loss=2.451, v_num=e839]\n",
      "Epoch 5:  97%|█████████▋| 16464/16955 [00:59<00:01, 274.46it/s, loss=2.451, v_num=e839]\n",
      "Epoch 5:  98%|█████████▊| 16562/16955 [01:00<00:01, 275.55it/s, loss=2.451, v_num=e839]\n",
      "Validating:  92%|█████████▏| 4694/5087 [00:07<00:00, 812.59it/s]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 16660/16955 [01:00<00:01, 276.60it/s, loss=2.451, v_num=e839]\n",
      "Epoch 5:  99%|█████████▉| 16758/16955 [01:00<00:00, 277.68it/s, loss=2.451, v_num=e839]\n",
      "Epoch 5:  99%|█████████▉| 16856/16955 [01:00<00:00, 278.76it/s, loss=2.451, v_num=e839]\n",
      "Epoch 5: 100%|█████████▉| 16954/16955 [01:00<00:00, 279.86it/s, loss=2.451, v_num=e839]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: avg_val_loss reached 2.45291 (best 2.45291), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v5.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 16955/16955 [01:00<00:00, 278.66it/s, loss=2.451, v_num=e839]\n",
      "Epoch 6:  70%|██████▉   | 11868/16955 [00:53<00:22, 223.10it/s, loss=2.451, v_num=e839]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 1/5087 [00:01<1:43:48,  1.22s/it]\u001b[A\n",
      "Epoch 6:  71%|███████   | 11956/16955 [00:54<00:22, 219.20it/s, loss=2.451, v_num=e839]\n",
      "Epoch 6:  71%|███████   | 12054/16955 [00:54<00:22, 220.50it/s, loss=2.451, v_num=e839]\n",
      "Epoch 6:  72%|███████▏  | 12152/16955 [00:54<00:21, 221.82it/s, loss=2.451, v_num=e839]\n",
      "Epoch 6:  72%|███████▏  | 12250/16955 [00:54<00:21, 223.11it/s, loss=2.451, v_num=e839]\n",
      "Epoch 6:  73%|███████▎  | 12348/16955 [00:55<00:20, 224.41it/s, loss=2.451, v_num=e839]\n",
      "Validating:   9%|▉         | 480/5087 [00:01<11:08,  6.89it/s]\u001b[A\n",
      "Epoch 6:  73%|███████▎  | 12446/16955 [00:55<00:19, 225.69it/s, loss=2.451, v_num=e839]\n",
      "Epoch 6:  74%|███████▍  | 12544/16955 [00:55<00:19, 226.98it/s, loss=2.451, v_num=e839]\n",
      "Epoch 6:  75%|███████▍  | 12642/16955 [00:55<00:18, 228.24it/s, loss=2.451, v_num=e839]\n",
      "Epoch 6:  75%|███████▌  | 12740/16955 [00:55<00:18, 229.51it/s, loss=2.451, v_num=e839]\n",
      "Validating:  17%|█▋        | 887/5087 [00:02<01:46, 39.31it/s]\u001b[A\n",
      "Epoch 6:  76%|███████▌  | 12838/16955 [00:55<00:17, 230.76it/s, loss=2.451, v_num=e839]\n",
      "Epoch 6:  76%|███████▋  | 12936/16955 [00:55<00:17, 232.04it/s, loss=2.451, v_num=e839]\n",
      "Epoch 6:  77%|███████▋  | 13034/16955 [00:55<00:16, 233.32it/s, loss=2.451, v_num=e839]\n",
      "Epoch 6:  77%|███████▋  | 13132/16955 [00:55<00:16, 234.59it/s, loss=2.451, v_num=e839]\n",
      "Epoch 6:  78%|███████▊  | 13230/16955 [00:56<00:15, 235.80it/s, loss=2.451, v_num=e839]\n",
      "Epoch 6:  79%|███████▊  | 13328/16955 [00:56<00:15, 237.02it/s, loss=2.451, v_num=e839]\n",
      "Validating:  29%|██▉       | 1473/5087 [00:03<00:11, 308.24it/s]\u001b[A\n",
      "Epoch 6:  79%|███████▉  | 13426/16955 [00:56<00:14, 238.23it/s, loss=2.451, v_num=e839]\n",
      "Epoch 6:  80%|███████▉  | 13524/16955 [00:56<00:14, 239.47it/s, loss=2.451, v_num=e839]\n",
      "Epoch 6:  80%|████████  | 13622/16955 [00:56<00:13, 240.70it/s, loss=2.451, v_num=e839]\n",
      "Epoch 6:  81%|████████  | 13720/16955 [00:56<00:13, 241.90it/s, loss=2.451, v_num=e839]\n",
      "Epoch 6:  81%|████████▏ | 13818/16955 [00:56<00:12, 243.10it/s, loss=2.451, v_num=e839]\n",
      "Validating:  39%|███▊      | 1963/5087 [00:03<00:04, 670.29it/s]\u001b[A\n",
      "Epoch 6:  82%|████████▏ | 13916/16955 [00:56<00:12, 244.28it/s, loss=2.451, v_num=e839]\n",
      "Epoch 6:  83%|████████▎ | 14014/16955 [00:57<00:11, 245.49it/s, loss=2.451, v_num=e839]\n",
      "Epoch 6:  83%|████████▎ | 14112/16955 [00:57<00:11, 246.72it/s, loss=2.451, v_num=e839]\n",
      "Epoch 6:  84%|████████▍ | 14210/16955 [00:57<00:11, 247.91it/s, loss=2.451, v_num=e839]\n",
      "Epoch 6:  84%|████████▍ | 14308/16955 [00:57<00:10, 249.08it/s, loss=2.451, v_num=e839]\n",
      "Epoch 6:  85%|████████▍ | 14406/16955 [00:57<00:10, 250.28it/s, loss=2.451, v_num=e839]\n",
      "Validating:  50%|█████     | 2547/5087 [00:04<00:03, 803.00it/s]\u001b[A\n",
      "Epoch 6:  86%|████████▌ | 14504/16955 [00:57<00:09, 251.46it/s, loss=2.451, v_num=e839]\n",
      "Epoch 6:  86%|████████▌ | 14602/16955 [00:57<00:09, 252.61it/s, loss=2.451, v_num=e839]\n",
      "Epoch 6:  87%|████████▋ | 14700/16955 [00:57<00:08, 253.74it/s, loss=2.451, v_num=e839]\n",
      "Epoch 6:  87%|████████▋ | 14798/16955 [00:58<00:08, 254.91it/s, loss=2.451, v_num=e839]\n",
      "Epoch 6:  88%|████████▊ | 14896/16955 [00:58<00:08, 256.08it/s, loss=2.451, v_num=e839]\n",
      "Epoch 6:  88%|████████▊ | 14994/16955 [00:58<00:07, 257.24it/s, loss=2.451, v_num=e839]\n",
      "Validating:  61%|██████▏   | 3128/5087 [00:05<00:02, 808.78it/s]\u001b[A\n",
      "Epoch 6:  89%|████████▉ | 15092/16955 [00:58<00:07, 258.40it/s, loss=2.451, v_num=e839]\n",
      "Epoch 6:  90%|████████▉ | 15190/16955 [00:58<00:06, 259.56it/s, loss=2.451, v_num=e839]\n",
      "Epoch 6:  90%|█████████ | 15288/16955 [00:58<00:06, 260.70it/s, loss=2.451, v_num=e839]\n",
      "Epoch 6:  91%|█████████ | 15386/16955 [00:58<00:05, 261.84it/s, loss=2.451, v_num=e839]\n",
      "Epoch 6:  91%|█████████▏| 15484/16955 [00:58<00:05, 262.99it/s, loss=2.451, v_num=e839]\n",
      "Epoch 6:  92%|█████████▏| 15582/16955 [00:58<00:05, 264.14it/s, loss=2.451, v_num=e839]\n",
      "Validating:  73%|███████▎  | 3719/5087 [00:05<00:01, 834.01it/s]\u001b[A\n",
      "Epoch 6:  92%|█████████▏| 15680/16955 [00:59<00:04, 265.24it/s, loss=2.451, v_num=e839]\n",
      "Epoch 6:  93%|█████████▎| 15778/16955 [00:59<00:04, 266.35it/s, loss=2.451, v_num=e839]\n",
      "Epoch 6:  94%|█████████▎| 15876/16955 [00:59<00:04, 267.49it/s, loss=2.451, v_num=e839]\n",
      "Epoch 6:  94%|█████████▍| 15974/16955 [00:59<00:03, 268.60it/s, loss=2.451, v_num=e839]\n",
      "Epoch 6:  95%|█████████▍| 16072/16955 [00:59<00:03, 269.72it/s, loss=2.451, v_num=e839]\n",
      "Epoch 6:  95%|█████████▌| 16170/16955 [00:59<00:02, 270.82it/s, loss=2.451, v_num=e839]\n",
      "Validating:  85%|████████▍ | 4305/5087 [00:06<00:00, 824.67it/s]\u001b[A\n",
      "Epoch 6:  96%|█████████▌| 16268/16955 [00:59<00:02, 271.90it/s, loss=2.451, v_num=e839]\n",
      "Epoch 6:  97%|█████████▋| 16366/16955 [00:59<00:02, 272.97it/s, loss=2.451, v_num=e839]\n",
      "Epoch 6:  97%|█████████▋| 16464/16955 [01:00<00:01, 274.03it/s, loss=2.451, v_num=e839]\n",
      "Epoch 6:  98%|█████████▊| 16562/16955 [01:00<00:01, 275.13it/s, loss=2.451, v_num=e839]\n",
      "Epoch 6:  98%|█████████▊| 16660/16955 [01:00<00:01, 276.21it/s, loss=2.451, v_num=e839]\n",
      "Epoch 6:  99%|█████████▉| 16758/16955 [01:00<00:00, 277.31it/s, loss=2.451, v_num=e839]\n",
      "Validating:  96%|█████████▌| 4890/5087 [00:07<00:00, 826.83it/s]\u001b[A\n",
      "Epoch 6:  99%|█████████▉| 16856/16955 [01:00<00:00, 278.37it/s, loss=2.451, v_num=e839]\n",
      "Epoch 6: 100%|█████████▉| 16954/16955 [01:00<00:00, 279.44it/s, loss=2.451, v_num=e839]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: avg_val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 16955/16955 [01:00<00:00, 278.36it/s, loss=2.451, v_num=e839]\n",
      "Epoch 7:  70%|██████▉   | 11868/16955 [00:53<00:22, 222.93it/s, loss=2.438, v_num=e839]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 1/5087 [00:01<2:00:31,  1.42s/it]\u001b[A\n",
      "Epoch 7:  71%|███████   | 11956/16955 [00:54<00:22, 218.24it/s, loss=2.438, v_num=e839]\n",
      "Epoch 7:  71%|███████   | 12054/16955 [00:54<00:22, 219.57it/s, loss=2.438, v_num=e839]\n",
      "Epoch 7:  72%|███████▏  | 12152/16955 [00:55<00:21, 220.89it/s, loss=2.438, v_num=e839]\n",
      "Epoch 7:  72%|███████▏  | 12250/16955 [00:55<00:21, 222.19it/s, loss=2.438, v_num=e839]\n",
      "Epoch 7:  73%|███████▎  | 12348/16955 [00:55<00:20, 223.50it/s, loss=2.438, v_num=e839]\n",
      "Validating:  10%|▉         | 494/5087 [00:02<12:53,  5.94it/s]\u001b[A\n",
      "Epoch 7:  73%|███████▎  | 12446/16955 [00:55<00:20, 224.78it/s, loss=2.438, v_num=e839]\n",
      "Epoch 7:  74%|███████▍  | 12544/16955 [00:55<00:19, 226.02it/s, loss=2.438, v_num=e839]\n",
      "Epoch 7:  75%|███████▍  | 12642/16955 [00:55<00:18, 227.30it/s, loss=2.438, v_num=e839]\n",
      "Epoch 7:  75%|███████▌  | 12740/16955 [00:55<00:18, 228.57it/s, loss=2.438, v_num=e839]\n",
      "Epoch 7:  76%|███████▌  | 12838/16955 [00:55<00:17, 229.84it/s, loss=2.438, v_num=e839]\n",
      "Validating:  19%|█▉        | 981/5087 [00:02<01:25, 47.86it/s]\u001b[A\n",
      "Epoch 7:  76%|███████▋  | 12936/16955 [00:55<00:17, 231.10it/s, loss=2.438, v_num=e839]\n",
      "Epoch 7:  77%|███████▋  | 13034/16955 [00:56<00:16, 232.36it/s, loss=2.438, v_num=e839]\n",
      "Epoch 7:  77%|███████▋  | 13132/16955 [00:56<00:16, 233.62it/s, loss=2.438, v_num=e839]\n",
      "Epoch 7:  78%|███████▊  | 13230/16955 [00:56<00:15, 234.87it/s, loss=2.438, v_num=e839]\n",
      "Epoch 7:  79%|███████▊  | 13328/16955 [00:56<00:15, 236.10it/s, loss=2.438, v_num=e839]\n",
      "Epoch 7:  79%|███████▉  | 13426/16955 [00:56<00:14, 237.31it/s, loss=2.438, v_num=e839]\n",
      "Validating:  31%|███       | 1564/5087 [00:03<00:10, 349.30it/s]\u001b[A\n",
      "Epoch 7:  80%|███████▉  | 13524/16955 [00:56<00:14, 238.49it/s, loss=2.438, v_num=e839]\n",
      "Epoch 7:  80%|████████  | 13622/16955 [00:56<00:13, 239.70it/s, loss=2.438, v_num=e839]\n",
      "Epoch 7:  81%|████████  | 13720/16955 [00:56<00:13, 240.92it/s, loss=2.438, v_num=e839]\n",
      "Epoch 7:  81%|████████▏ | 13818/16955 [00:57<00:12, 242.13it/s, loss=2.438, v_num=e839]\n",
      "Epoch 7:  82%|████████▏ | 13916/16955 [00:57<00:12, 243.35it/s, loss=2.438, v_num=e839]\n",
      "Validating:  40%|████      | 2055/5087 [00:03<00:04, 705.06it/s]\u001b[A\n",
      "Epoch 7:  83%|████████▎ | 14014/16955 [00:57<00:12, 244.54it/s, loss=2.438, v_num=e839]\n",
      "Epoch 7:  83%|████████▎ | 14112/16955 [00:57<00:11, 245.75it/s, loss=2.438, v_num=e839]\n",
      "Epoch 7:  84%|████████▍ | 14210/16955 [00:57<00:11, 246.95it/s, loss=2.438, v_num=e839]\n",
      "Epoch 7:  84%|████████▍ | 14308/16955 [00:57<00:10, 248.12it/s, loss=2.438, v_num=e839]\n",
      "Epoch 7:  85%|████████▍ | 14406/16955 [00:57<00:10, 249.28it/s, loss=2.438, v_num=e839]\n",
      "Validating:  50%|█████     | 2552/5087 [00:04<00:03, 782.29it/s]\u001b[A\n",
      "Epoch 7:  86%|████████▌ | 14504/16955 [00:57<00:09, 250.44it/s, loss=2.438, v_num=e839]\n",
      "Epoch 7:  86%|████████▌ | 14602/16955 [00:58<00:09, 251.61it/s, loss=2.438, v_num=e839]\n",
      "Epoch 7:  87%|████████▋ | 14700/16955 [00:58<00:08, 252.75it/s, loss=2.438, v_num=e839]\n",
      "Epoch 7:  87%|████████▋ | 14798/16955 [00:58<00:08, 253.89it/s, loss=2.438, v_num=e839]\n",
      "Epoch 7:  88%|████████▊ | 14896/16955 [00:58<00:08, 255.05it/s, loss=2.438, v_num=e839]\n",
      "Validating:  60%|█████▉    | 3044/5087 [00:05<00:02, 799.38it/s]\u001b[A\n",
      "Epoch 7:  88%|████████▊ | 14994/16955 [00:58<00:07, 256.14it/s, loss=2.438, v_num=e839]\n",
      "Epoch 7:  89%|████████▉ | 15092/16955 [00:58<00:07, 257.25it/s, loss=2.438, v_num=e839]\n",
      "Epoch 7:  90%|████████▉ | 15190/16955 [00:58<00:06, 258.40it/s, loss=2.438, v_num=e839]\n",
      "Epoch 7:  90%|█████████ | 15288/16955 [00:58<00:06, 259.52it/s, loss=2.438, v_num=e839]\n",
      "Epoch 7:  91%|█████████ | 15386/16955 [00:59<00:06, 260.67it/s, loss=2.438, v_num=e839]\n",
      "Validating:  69%|██████▉   | 3533/5087 [00:05<00:01, 800.55it/s]\u001b[A\n",
      "Epoch 7:  91%|█████████▏| 15484/16955 [00:59<00:05, 261.77it/s, loss=2.438, v_num=e839]\n",
      "Epoch 7:  92%|█████████▏| 15582/16955 [00:59<00:05, 262.91it/s, loss=2.438, v_num=e839]\n",
      "Epoch 7:  92%|█████████▏| 15680/16955 [00:59<00:04, 264.03it/s, loss=2.438, v_num=e839]\n",
      "Epoch 7:  93%|█████████▎| 15778/16955 [00:59<00:04, 265.13it/s, loss=2.438, v_num=e839]\n",
      "Epoch 7:  94%|█████████▎| 15876/16955 [00:59<00:04, 266.23it/s, loss=2.438, v_num=e839]\n",
      "Epoch 7:  94%|█████████▍| 15974/16955 [00:59<00:03, 267.30it/s, loss=2.438, v_num=e839]\n",
      "Validating:  81%|████████  | 4106/5087 [00:06<00:01, 792.96it/s]\u001b[A\n",
      "Epoch 7:  95%|█████████▍| 16072/16955 [00:59<00:03, 268.39it/s, loss=2.438, v_num=e839]\n",
      "Epoch 7:  95%|█████████▌| 16170/16955 [00:59<00:02, 269.51it/s, loss=2.438, v_num=e839]\n",
      "Epoch 7:  96%|█████████▌| 16268/16955 [01:00<00:02, 270.61it/s, loss=2.438, v_num=e839]\n",
      "Epoch 7:  97%|█████████▋| 16366/16955 [01:00<00:02, 271.71it/s, loss=2.438, v_num=e839]\n",
      "Epoch 7:  97%|█████████▋| 16464/16955 [01:00<00:01, 272.79it/s, loss=2.438, v_num=e839]\n",
      "Validating:  91%|█████████ | 4607/5087 [00:07<00:00, 810.78it/s]\u001b[A\n",
      "Epoch 7:  98%|█████████▊| 16562/16955 [01:00<00:01, 273.84it/s, loss=2.438, v_num=e839]\n",
      "Epoch 7:  98%|█████████▊| 16660/16955 [01:00<00:01, 274.91it/s, loss=2.438, v_num=e839]\n",
      "Epoch 7:  99%|█████████▉| 16758/16955 [01:00<00:00, 275.98it/s, loss=2.438, v_num=e839]\n",
      "Epoch 7:  99%|█████████▉| 16856/16955 [01:00<00:00, 277.03it/s, loss=2.438, v_num=e839]\n",
      "Epoch 7: 100%|█████████▉| 16954/16955 [01:00<00:00, 278.11it/s, loss=2.438, v_num=e839]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: avg_val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 16955/16955 [01:01<00:00, 276.98it/s, loss=2.438, v_num=e839]\n",
      "Epoch 8:  70%|██████▉   | 11868/16955 [00:53<00:23, 220.27it/s, loss=2.445, v_num=e839]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 1/5087 [00:01<1:55:49,  1.37s/it]\u001b[A\n",
      "Epoch 8:  71%|███████   | 11956/16955 [00:55<00:23, 216.01it/s, loss=2.445, v_num=e839]\n",
      "Epoch 8:  71%|███████   | 12054/16955 [00:55<00:22, 217.27it/s, loss=2.445, v_num=e839]\n",
      "Epoch 8:  72%|███████▏  | 12152/16955 [00:55<00:21, 218.59it/s, loss=2.445, v_num=e839]\n",
      "Epoch 8:  72%|███████▏  | 12250/16955 [00:55<00:21, 219.89it/s, loss=2.445, v_num=e839]\n",
      "Epoch 8:  73%|███████▎  | 12348/16955 [00:55<00:20, 221.17it/s, loss=2.445, v_num=e839]\n",
      "Validating:  10%|▉         | 495/5087 [00:01<12:23,  6.18it/s]\u001b[A\n",
      "Epoch 8:  73%|███████▎  | 12446/16955 [00:55<00:20, 222.41it/s, loss=2.445, v_num=e839]\n",
      "Epoch 8:  74%|███████▍  | 12544/16955 [00:56<00:19, 223.68it/s, loss=2.445, v_num=e839]\n",
      "Epoch 8:  75%|███████▍  | 12642/16955 [00:56<00:19, 224.95it/s, loss=2.445, v_num=e839]\n",
      "Epoch 8:  75%|███████▌  | 12740/16955 [00:56<00:18, 226.21it/s, loss=2.445, v_num=e839]\n",
      "Epoch 8:  76%|███████▌  | 12838/16955 [00:56<00:18, 227.44it/s, loss=2.445, v_num=e839]\n",
      "Validating:  19%|█▉        | 976/5087 [00:02<01:22, 49.61it/s]\u001b[A\n",
      "Epoch 8:  76%|███████▋  | 12936/16955 [00:56<00:17, 228.65it/s, loss=2.445, v_num=e839]\n",
      "Epoch 8:  77%|███████▋  | 13034/16955 [00:56<00:17, 229.91it/s, loss=2.445, v_num=e839]\n",
      "Epoch 8:  77%|███████▋  | 13132/16955 [00:56<00:16, 231.16it/s, loss=2.445, v_num=e839]\n",
      "Epoch 8:  78%|███████▊  | 13230/16955 [00:56<00:16, 232.41it/s, loss=2.445, v_num=e839]\n",
      "Epoch 8:  79%|███████▊  | 13328/16955 [00:57<00:15, 233.65it/s, loss=2.445, v_num=e839]\n",
      "Validating:  29%|██▉       | 1474/5087 [00:03<00:12, 291.20it/s]\u001b[A\n",
      "Epoch 8:  79%|███████▉  | 13426/16955 [00:57<00:15, 234.87it/s, loss=2.445, v_num=e839]\n",
      "Epoch 8:  80%|███████▉  | 13524/16955 [00:57<00:14, 236.09it/s, loss=2.445, v_num=e839]\n",
      "Epoch 8:  80%|████████  | 13622/16955 [00:57<00:14, 237.31it/s, loss=2.445, v_num=e839]\n",
      "Epoch 8:  81%|████████  | 13720/16955 [00:57<00:13, 238.50it/s, loss=2.445, v_num=e839]\n",
      "Epoch 8:  81%|████████▏ | 13818/16955 [00:57<00:13, 239.68it/s, loss=2.445, v_num=e839]\n",
      "Epoch 8:  82%|████████▏ | 13916/16955 [00:57<00:12, 240.86it/s, loss=2.445, v_num=e839]\n",
      "Validating:  40%|████      | 2049/5087 [00:03<00:04, 689.99it/s]\u001b[A\n",
      "Epoch 8:  83%|████████▎ | 14014/16955 [00:57<00:12, 242.06it/s, loss=2.445, v_num=e839]\n",
      "Epoch 8:  83%|████████▎ | 14112/16955 [00:58<00:11, 243.26it/s, loss=2.445, v_num=e839]\n",
      "Epoch 8:  84%|████████▍ | 14210/16955 [00:58<00:11, 244.46it/s, loss=2.445, v_num=e839]\n",
      "Epoch 8:  84%|████████▍ | 14308/16955 [00:58<00:10, 245.65it/s, loss=2.445, v_num=e839]\n",
      "Epoch 8:  85%|████████▍ | 14406/16955 [00:58<00:10, 246.82it/s, loss=2.445, v_num=e839]\n",
      "Epoch 8:  86%|████████▌ | 14504/16955 [00:58<00:09, 247.98it/s, loss=2.445, v_num=e839]\n",
      "Validating:  52%|█████▏    | 2639/5087 [00:04<00:03, 803.35it/s]\u001b[A\n",
      "Epoch 8:  86%|████████▌ | 14602/16955 [00:58<00:09, 249.17it/s, loss=2.445, v_num=e839]\n",
      "Epoch 8:  87%|████████▋ | 14700/16955 [00:58<00:09, 250.36it/s, loss=2.445, v_num=e839]\n",
      "Epoch 8:  87%|████████▋ | 14798/16955 [00:58<00:08, 251.53it/s, loss=2.445, v_num=e839]\n",
      "Epoch 8:  88%|████████▊ | 14896/16955 [00:58<00:08, 252.68it/s, loss=2.445, v_num=e839]\n",
      "Epoch 8:  88%|████████▊ | 14994/16955 [00:59<00:07, 253.82it/s, loss=2.445, v_num=e839]\n",
      "Epoch 8:  89%|████████▉ | 15092/16955 [00:59<00:07, 254.99it/s, loss=2.445, v_num=e839]\n",
      "Epoch 8:  90%|████████▉ | 15190/16955 [00:59<00:06, 256.14it/s, loss=2.445, v_num=e839]\n",
      "Validating:  65%|██████▌   | 3325/5087 [00:05<00:02, 832.12it/s]\u001b[A\n",
      "Epoch 8:  90%|█████████ | 15288/16955 [00:59<00:06, 257.25it/s, loss=2.445, v_num=e839]\n",
      "Epoch 8:  91%|█████████ | 15386/16955 [00:59<00:06, 258.37it/s, loss=2.445, v_num=e839]\n",
      "Epoch 8:  91%|█████████▏| 15484/16955 [00:59<00:05, 259.50it/s, loss=2.445, v_num=e839]\n",
      "Epoch 8:  92%|█████████▏| 15582/16955 [00:59<00:05, 260.59it/s, loss=2.445, v_num=e839]\n",
      "Epoch 8:  92%|█████████▏| 15680/16955 [00:59<00:04, 261.66it/s, loss=2.445, v_num=e839]\n",
      "Validating:  75%|███████▌  | 3818/5087 [00:06<00:01, 779.96it/s]\u001b[A\n",
      "Epoch 8:  93%|█████████▎| 15778/16955 [01:00<00:04, 262.72it/s, loss=2.445, v_num=e839]\n",
      "Epoch 8:  94%|█████████▎| 15876/16955 [01:00<00:04, 263.80it/s, loss=2.445, v_num=e839]\n",
      "Epoch 8:  94%|█████████▍| 15974/16955 [01:00<00:03, 264.87it/s, loss=2.445, v_num=e839]\n",
      "Epoch 8:  95%|█████████▍| 16072/16955 [01:00<00:03, 265.97it/s, loss=2.445, v_num=e839]\n",
      "Validating:  83%|████████▎ | 4216/5087 [00:06<00:01, 789.04it/s]\u001b[A\n",
      "Epoch 8:  95%|█████████▌| 16170/16955 [01:00<00:02, 267.05it/s, loss=2.445, v_num=e839]\n",
      "Epoch 8:  96%|█████████▌| 16268/16955 [01:00<00:02, 268.11it/s, loss=2.445, v_num=e839]\n",
      "Epoch 8:  97%|█████████▋| 16366/16955 [01:00<00:02, 269.19it/s, loss=2.445, v_num=e839]\n",
      "Epoch 8:  97%|█████████▋| 16464/16955 [01:00<00:01, 270.29it/s, loss=2.445, v_num=e839]\n",
      "Epoch 8:  98%|█████████▊| 16562/16955 [01:01<00:01, 271.38it/s, loss=2.445, v_num=e839]\n",
      "Epoch 8:  98%|█████████▊| 16660/16955 [01:01<00:01, 272.43it/s, loss=2.445, v_num=e839]\n",
      "Validating:  94%|█████████▍| 4793/5087 [00:07<00:00, 806.21it/s]\u001b[A\n",
      "Epoch 8:  99%|█████████▉| 16758/16955 [01:01<00:00, 273.47it/s, loss=2.445, v_num=e839]\n",
      "Epoch 8:  99%|█████████▉| 16856/16955 [01:01<00:00, 274.50it/s, loss=2.445, v_num=e839]\n",
      "Epoch 8: 100%|█████████▉| 16954/16955 [01:01<00:00, 275.53it/s, loss=2.445, v_num=e839]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: avg_val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 16955/16955 [01:01<00:00, 274.38it/s, loss=2.445, v_num=e839]\n",
      "Epoch 8: 100%|██████████| 16955/16955 [01:02<00:00, 271.29it/s, loss=2.445, v_num=e839]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: ----------------------------------\n",
      "COMET INFO: Comet.ml OfflineExperiment Summary\n",
      "COMET INFO: ----------------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : [OfflineExperiment will get URL after upload]\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     avg_train_loss [9] : (2.438805341720581, 2.472425937652588)\n",
      "COMET INFO:     avg_val_loss [9]   : (2.4529061317443848, 2.4638121128082275)\n",
      "COMET INFO:   Others:\n",
      "COMET INFO:     offline_experiment : True\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     device           : cuda\n",
      "COMET INFO:     dropout          : 0.2\n",
      "COMET INFO:     logger           : <pytorch_lightning.loggers.comet.CometLogger object at 0x7f30824ecad0>\n",
      "COMET INFO:     lr               : 0.001\n",
      "COMET INFO:     max_epochs       : 30\n",
      "COMET INFO:     num_warmup_steps : 2000\n",
      "COMET INFO:     num_workers      : 12\n",
      "COMET INFO:     pin_memory       : True\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     code                     : 1 (4 KB)\n",
      "COMET INFO:     environment details      : 1\n",
      "COMET INFO:     filename                 : 1\n",
      "COMET INFO:     git metadata             : 1\n",
      "COMET INFO:     git-patch (uncompressed) : 1 (439 bytes)\n",
      "COMET INFO:     installed packages       : 1\n",
      "COMET INFO:     notebook                 : 1\n",
      "COMET INFO:     os packages              : 1\n",
      "COMET INFO: ----------------------------------\n",
      "COMET INFO: Starting saving the offline archive\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: To upload this offline experiment, run:\n",
      "    comet upload logs/0e9416ac8e894f2e920277f7793ce839.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9min 15s, sys: 1min 35s, total: 10min 50s\n",
      "Wall time: 9min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EarlyStopping mode set to min for monitoring avg_val_loss.\n",
      "INFO:lightning:EarlyStopping mode set to min for monitoring avg_val_loss.\n"
     ]
    }
   ],
   "source": [
    "sign_model = Model.load_from_checkpoint(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, hparams=hparams,\\\n",
    "                                   checkpoint_path=\"./checkpoints/model-outputs-v5.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (net): Net(\n",
       "    (fc1): Linear(in_features=768, out_features=128, bias=True)\n",
       "    (fc2): Linear(in_features=128, out_features=12, bias=True)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "    (loss_func): CrossEntropyLoss()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sign_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4239/4239 [00:04<00:00, 1057.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.178     0.060     0.090      9893\n",
      "           1      0.197     0.098     0.131     12961\n",
      "           2      0.258     0.077     0.118     12949\n",
      "           3      0.391     0.001     0.002      9801\n",
      "           4      0.416     0.014     0.027     10344\n",
      "           5      0.344     0.024     0.045     10708\n",
      "           6      0.094     0.817     0.168     12412\n",
      "           7      0.270     0.032     0.058     10757\n",
      "           8      0.119     0.093     0.104      9963\n",
      "           9      0.237     0.019     0.036     11370\n",
      "          10      0.140     0.015     0.028     12453\n",
      "          11      0.168     0.022     0.040     12022\n",
      "\n",
      "    accuracy                          0.113    135633\n",
      "   macro avg      0.234     0.106     0.071    135633\n",
      "weighted avg      0.230     0.113     0.073    135633\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = sign_model.predict_eval(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics are higher now, but still, the model is weak. To be fair, the task sounds a bit impossible, considering that it's hard to find any patterns which are specific for zodiac signs, especially in texts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's turn for age prediction model. Classes are not balanced, we'll try to deal with it. Repeating again prepararion routine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_class2idx = {k: v for v, k in enumerate(sorted(df2['age'].unique()))}\n",
    "age_idx2class = {v: k for k, v in age_class2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{13: 0,\n",
       " 14: 1,\n",
       " 15: 2,\n",
       " 16: 3,\n",
       " 17: 4,\n",
       " 23: 5,\n",
       " 24: 6,\n",
       " 25: 7,\n",
       " 26: 8,\n",
       " 27: 9,\n",
       " 33: 10,\n",
       " 34: 11,\n",
       " 35: 12,\n",
       " 36: 13,\n",
       " 37: 14,\n",
       " 38: 15,\n",
       " 39: 16,\n",
       " 40: 17,\n",
       " 41: 18,\n",
       " 42: 19,\n",
       " 43: 20,\n",
       " 44: 21,\n",
       " 45: 22,\n",
       " 46: 23,\n",
       " 47: 24,\n",
       " 48: 25}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_class2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['age'] = df2['age'].map(age_class2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2['vectors'].values\n",
    "y = df2['age'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=17)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.3, stratify=y_trainval, random_state=43)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As classes are highly disbalanced we want artificially increase number of times NN sees rare classes. So I provide weights for training instances to activate `WeightedRandomSampler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_distribution(y_label):\n",
    "    return dict(df2[y_label].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_list = torch.tensor(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_count = [i for i in get_class_distribution('age').values()]\n",
    "class_weights = 1./torch.tensor(class_count, dtype=torch.float) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights_all = class_weights[target_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.6968e-05, 2.3787e-04, 7.6728e-05,  ..., 1.3801e-05, 1.2532e-05,\n",
       "        2.1786e-05])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'fast_dev_run': True,\n",
    "    'pin_memory': True,\n",
    "    'device': device,\n",
    "    'num_workers': 12,\n",
    "    'shuffle': False,\n",
    "    'batch_size': 32,\n",
    "    'logger': comet_logger,\n",
    "    'weights': class_weights_all\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EarlyStopping mode set to min for monitoring avg_val_loss.\n"
     ]
    }
   ],
   "source": [
    "model = Model(X_train, y_train, X_val, y_val, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Running in fast_dev_run mode: will run a full train, val and test loop using a single batch\n",
      "\n",
      "  | Name | Type | Params\n",
      "------------------------------\n",
      "0 | net  | Net  | 101 K \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 2/2 [00:03<00:00,  1.88s/it, loss=3.299, v_num=a4ff]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating: 100%|██████████| 1/1 [00:01<00:00,  1.31s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: avg_val_loss reached 3.23989 (best 3.23989), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v3.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 2/2 [00:05<00:00,  2.75s/it, loss=3.299, v_num=a4ff]\n",
      "Epoch 0: 100%|██████████| 2/2 [00:05<00:00,  2.87s/it, loss=3.299, v_num=a4ff]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Starting saving the offline archive\n",
      "COMET INFO: To upload this offline experiment, run:\n",
      "    comet upload logs/04e9cc18d1d64f59b707d639a7c2a4ff.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 4.09 s, sys: 2.94 s, total: 7.03 s\n",
      "Wall time: 7.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'pin_memory': True,\n",
    "    'device': device,\n",
    "    'num_workers': 12,\n",
    "    'logger': comet_logger,\n",
    "    'max_epochs': 30,\n",
    "    'lr': 1e-3,\n",
    "    'num_warmup_steps': 2000,\n",
    "    'dropout': 0.2,\n",
    "    'weights': class_weights_all\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EarlyStopping mode set to min for monitoring avg_val_loss.\n"
     ]
    }
   ],
   "source": [
    "model = Model(X_train, y_train, X_val, y_val, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (net): Net(\n",
       "    (fc1): Linear(in_features=768, out_features=128, bias=True)\n",
       "    (fc2): Linear(in_features=128, out_features=26, bias=True)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "    (loss_func): CrossEntropyLoss()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4239/4239 [00:04<00:00, 1023.47it/s]\n",
      "/home/payonear/Cases_recruit/netguru-case/netguru-env/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000      2607\n",
      "           1      0.033     0.013     0.019      5456\n",
      "           2      0.066     0.029     0.041      8314\n",
      "           3      0.057     0.000     0.000     14492\n",
      "           4      0.125     0.000     0.000     16107\n",
      "           5      0.123     0.003     0.006     14493\n",
      "           6      0.125     0.001     0.001     15959\n",
      "           7      0.094     0.037     0.053     13348\n",
      "           8      0.000     0.000     0.000     11014\n",
      "           9      0.084     0.005     0.009      9180\n",
      "          10      0.024     0.001     0.001      3498\n",
      "          11      0.051     0.010     0.017      4258\n",
      "          12      0.038     0.020     0.026      3481\n",
      "          13      0.000     0.000     0.000      2835\n",
      "          14      0.014     0.269     0.026      1853\n",
      "          15      0.009     0.012     0.011      1484\n",
      "          16      0.006     0.011     0.008      1092\n",
      "          17      0.006     0.039     0.010      1001\n",
      "          18      0.000     0.000     0.000       741\n",
      "          19      0.004     0.029     0.006       580\n",
      "          20      0.005     0.025     0.009       841\n",
      "          21      0.003     0.516     0.007       407\n",
      "          22      0.006     0.022     0.009       894\n",
      "          23      0.000     0.000     0.000       546\n",
      "          24      0.000     0.000     0.000       439\n",
      "          25      0.000     0.000     0.000       713\n",
      "\n",
      "    accuracy                          0.014    135633\n",
      "   macro avg      0.034     0.040     0.010    135633\n",
      "weighted avg      0.073     0.014     0.012    135633\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict_eval(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type | Params\n",
      "------------------------------\n",
      "0 | net  | Net  | 101 K \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  70%|██████▉   | 11868/16955 [00:54<00:23, 219.07it/s, loss=2.785, v_num=946a]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  70%|███████   | 11885/16955 [00:55<00:23, 212.87it/s, loss=2.785, v_num=946a]\n",
      "Epoch 0:  71%|███████   | 11978/16955 [00:55<00:23, 214.15it/s, loss=2.785, v_num=946a]\n",
      "Epoch 0:  71%|███████   | 12071/16955 [00:56<00:22, 215.40it/s, loss=2.785, v_num=946a]\n",
      "Epoch 0:  72%|███████▏  | 12164/16955 [00:56<00:22, 216.64it/s, loss=2.785, v_num=946a]\n",
      "Epoch 0:  72%|███████▏  | 12257/16955 [00:56<00:21, 217.88it/s, loss=2.785, v_num=946a]\n",
      "Epoch 0:  73%|███████▎  | 12350/16955 [00:56<00:21, 219.11it/s, loss=2.785, v_num=946a]\n",
      "Epoch 0:  73%|███████▎  | 12443/16955 [00:56<00:20, 220.34it/s, loss=2.785, v_num=946a]\n",
      "Validating:  11%|█▏        | 579/5087 [00:02<09:58,  7.54it/s]\u001b[A\n",
      "Epoch 0:  74%|███████▍  | 12536/16955 [00:56<00:19, 221.55it/s, loss=2.785, v_num=946a]\n",
      "Epoch 0:  74%|███████▍  | 12629/16955 [00:56<00:19, 222.77it/s, loss=2.785, v_num=946a]\n",
      "Epoch 0:  75%|███████▌  | 12722/16955 [00:56<00:18, 223.97it/s, loss=2.785, v_num=946a]\n",
      "Epoch 0:  76%|███████▌  | 12815/16955 [00:56<00:18, 225.18it/s, loss=2.785, v_num=946a]\n",
      "Epoch 0:  76%|███████▌  | 12908/16955 [00:57<00:17, 226.38it/s, loss=2.785, v_num=946a]\n",
      "Epoch 0:  77%|███████▋  | 13001/16955 [00:57<00:17, 227.58it/s, loss=2.785, v_num=946a]\n",
      "Epoch 0:  77%|███████▋  | 13094/16955 [00:57<00:16, 228.78it/s, loss=2.785, v_num=946a]\n",
      "Epoch 0:  78%|███████▊  | 13187/16955 [00:57<00:16, 229.97it/s, loss=2.785, v_num=946a]\n",
      "Epoch 0:  78%|███████▊  | 13280/16955 [00:57<00:15, 231.13it/s, loss=2.785, v_num=946a]\n",
      "Epoch 0:  79%|███████▉  | 13373/16955 [00:57<00:15, 232.31it/s, loss=2.785, v_num=946a]\n",
      "Epoch 0:  79%|███████▉  | 13466/16955 [00:57<00:14, 233.46it/s, loss=2.785, v_num=946a]\n",
      "Epoch 0:  80%|███████▉  | 13559/16955 [00:57<00:14, 234.61it/s, loss=2.785, v_num=946a]\n",
      "Epoch 0:  81%|████████  | 13652/16955 [00:57<00:14, 235.78it/s, loss=2.785, v_num=946a]\n",
      "Validating:  35%|███▌      | 1784/5087 [00:03<00:06, 479.24it/s]\u001b[A\n",
      "Epoch 0:  81%|████████  | 13745/16955 [00:58<00:13, 236.92it/s, loss=2.785, v_num=946a]\n",
      "Epoch 0:  82%|████████▏ | 13838/16955 [00:58<00:13, 238.06it/s, loss=2.785, v_num=946a]\n",
      "Epoch 0:  82%|████████▏ | 13931/16955 [00:58<00:12, 239.18it/s, loss=2.785, v_num=946a]\n",
      "Epoch 0:  83%|████████▎ | 14024/16955 [00:58<00:12, 240.33it/s, loss=2.785, v_num=946a]\n",
      "Epoch 0:  83%|████████▎ | 14117/16955 [00:58<00:11, 241.45it/s, loss=2.785, v_num=946a]\n",
      "Epoch 0:  84%|████████▍ | 14210/16955 [00:58<00:11, 242.56it/s, loss=2.785, v_num=946a]\n",
      "Epoch 0:  84%|████████▍ | 14303/16955 [00:58<00:10, 243.67it/s, loss=2.785, v_num=946a]\n",
      "Epoch 0:  85%|████████▍ | 14396/16955 [00:58<00:10, 244.79it/s, loss=2.785, v_num=946a]\n",
      "Epoch 0:  85%|████████▌ | 14489/16955 [00:58<00:10, 245.91it/s, loss=2.785, v_num=946a]\n",
      "Validating:  52%|█████▏    | 2624/5087 [00:04<00:03, 805.19it/s]\u001b[A\n",
      "Epoch 0:  86%|████████▌ | 14582/16955 [00:59<00:09, 247.00it/s, loss=2.785, v_num=946a]\n",
      "Epoch 0:  87%|████████▋ | 14675/16955 [00:59<00:09, 248.10it/s, loss=2.785, v_num=946a]\n",
      "Epoch 0:  87%|████████▋ | 14768/16955 [00:59<00:08, 249.16it/s, loss=2.785, v_num=946a]\n",
      "Epoch 0:  88%|████████▊ | 14861/16955 [00:59<00:08, 250.22it/s, loss=2.785, v_num=946a]\n",
      "Epoch 0:  88%|████████▊ | 14954/16955 [00:59<00:07, 251.27it/s, loss=2.785, v_num=946a]\n",
      "Epoch 0:  89%|████████▊ | 15047/16955 [00:59<00:07, 252.35it/s, loss=2.785, v_num=946a]\n",
      "Epoch 0:  89%|████████▉ | 15140/16955 [00:59<00:07, 253.41it/s, loss=2.785, v_num=946a]\n",
      "Validating:  64%|██████▍   | 3275/5087 [00:05<00:02, 788.62it/s]\u001b[A\n",
      "Epoch 0:  90%|████████▉ | 15233/16955 [00:59<00:06, 254.47it/s, loss=2.785, v_num=946a]\n",
      "Epoch 0:  90%|█████████ | 15326/16955 [00:59<00:06, 255.52it/s, loss=2.785, v_num=946a]\n",
      "Epoch 0:  91%|█████████ | 15419/16955 [01:00<00:05, 256.56it/s, loss=2.785, v_num=946a]\n",
      "Epoch 0:  91%|█████████▏| 15512/16955 [01:00<00:05, 257.59it/s, loss=2.785, v_num=946a]\n",
      "Epoch 0:  92%|█████████▏| 15605/16955 [01:00<00:05, 258.67it/s, loss=2.785, v_num=946a]\n",
      "Epoch 0:  93%|█████████▎| 15698/16955 [01:00<00:04, 259.74it/s, loss=2.785, v_num=946a]\n",
      "Epoch 0:  93%|█████████▎| 15791/16955 [01:00<00:04, 260.80it/s, loss=2.785, v_num=946a]\n",
      "Epoch 0:  94%|█████████▎| 15884/16955 [01:00<00:04, 261.89it/s, loss=2.785, v_num=946a]\n",
      "Validating:  79%|███████▉  | 4023/5087 [00:06<00:01, 839.94it/s]\u001b[A\n",
      "Epoch 0:  94%|█████████▍| 15977/16955 [01:00<00:03, 262.89it/s, loss=2.785, v_num=946a]\n",
      "Epoch 0:  95%|█████████▍| 16070/16955 [01:00<00:03, 263.94it/s, loss=2.785, v_num=946a]\n",
      "Epoch 0:  95%|█████████▌| 16163/16955 [01:00<00:02, 264.98it/s, loss=2.785, v_num=946a]\n",
      "Epoch 0:  96%|█████████▌| 16256/16955 [01:01<00:02, 266.03it/s, loss=2.785, v_num=946a]\n",
      "Epoch 0:  96%|█████████▋| 16349/16955 [01:01<00:02, 267.10it/s, loss=2.785, v_num=946a]\n",
      "Epoch 0:  97%|█████████▋| 16444/16955 [01:01<00:01, 268.20it/s, loss=2.785, v_num=946a]\n",
      "Epoch 0:  98%|█████████▊| 16539/16955 [01:01<00:01, 269.25it/s, loss=2.785, v_num=946a]\n",
      "Epoch 0:  98%|█████████▊| 16634/16955 [01:01<00:01, 270.31it/s, loss=2.785, v_num=946a]\n",
      "Epoch 0:  99%|█████████▊| 16729/16955 [01:01<00:00, 271.31it/s, loss=2.785, v_num=946a]\n",
      "Epoch 0:  99%|█████████▉| 16824/16955 [01:01<00:00, 272.33it/s, loss=2.785, v_num=946a]\n",
      "Epoch 0: 100%|█████████▉| 16919/16955 [01:01<00:00, 273.33it/s, loss=2.785, v_num=946a]\n",
      "Validating:  99%|█████████▉| 5055/5087 [00:07<00:00, 802.49it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: avg_val_loss reached 2.96739 (best 2.96739), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v7.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 16955/16955 [01:02<00:00, 272.60it/s, loss=2.785, v_num=946a]\n",
      "Epoch 1:  70%|██████▉   | 11868/16955 [00:53<00:22, 221.55it/s, loss=2.521, v_num=946a]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1:  70%|███████   | 11875/16955 [00:55<00:23, 215.53it/s, loss=2.521, v_num=946a]\n",
      "Epoch 1:  71%|███████   | 11970/16955 [00:55<00:22, 216.78it/s, loss=2.521, v_num=946a]\n",
      "Epoch 1:  71%|███████   | 12065/16955 [00:55<00:22, 218.03it/s, loss=2.521, v_num=946a]\n",
      "Epoch 1:  72%|███████▏  | 12160/16955 [00:55<00:21, 219.29it/s, loss=2.521, v_num=946a]\n",
      "Validating:   6%|▌         | 301/5087 [00:01<28:39,  2.78it/s]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 12255/16955 [00:55<00:21, 220.51it/s, loss=2.521, v_num=946a]\n",
      "Epoch 1:  73%|███████▎  | 12350/16955 [00:55<00:20, 221.75it/s, loss=2.521, v_num=946a]\n",
      "Epoch 1:  73%|███████▎  | 12445/16955 [00:55<00:20, 222.99it/s, loss=2.521, v_num=946a]\n",
      "Epoch 1:  74%|███████▍  | 12540/16955 [00:55<00:19, 224.21it/s, loss=2.521, v_num=946a]\n",
      "Epoch 1:  75%|███████▍  | 12635/16955 [00:56<00:19, 225.43it/s, loss=2.521, v_num=946a]\n",
      "Epoch 1:  75%|███████▌  | 12730/16955 [00:56<00:18, 226.66it/s, loss=2.521, v_num=946a]\n",
      "Validating:  17%|█▋        | 865/5087 [00:02<02:09, 32.55it/s]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 12825/16955 [00:56<00:18, 227.87it/s, loss=2.521, v_num=946a]\n",
      "Epoch 1:  76%|███████▌  | 12920/16955 [00:56<00:17, 229.11it/s, loss=2.521, v_num=946a]\n",
      "Epoch 1:  77%|███████▋  | 13015/16955 [00:56<00:17, 230.33it/s, loss=2.521, v_num=946a]\n",
      "Epoch 1:  77%|███████▋  | 13110/16955 [00:56<00:16, 231.54it/s, loss=2.521, v_num=946a]\n",
      "Epoch 1:  78%|███████▊  | 13205/16955 [00:56<00:16, 232.72it/s, loss=2.521, v_num=946a]\n",
      "Epoch 1:  78%|███████▊  | 13300/16955 [00:56<00:15, 233.91it/s, loss=2.521, v_num=946a]\n",
      "Epoch 1:  79%|███████▉  | 13395/16955 [00:56<00:15, 235.11it/s, loss=2.521, v_num=946a]\n",
      "Validating:  30%|███       | 1533/5087 [00:03<00:10, 342.58it/s]\u001b[A\n",
      "Epoch 1:  80%|███████▉  | 13490/16955 [00:57<00:14, 236.27it/s, loss=2.521, v_num=946a]\n",
      "Epoch 1:  80%|████████  | 13585/16955 [00:57<00:14, 237.46it/s, loss=2.521, v_num=946a]\n",
      "Epoch 1:  81%|████████  | 13680/16955 [00:57<00:13, 238.66it/s, loss=2.521, v_num=946a]\n",
      "Epoch 1:  81%|████████  | 13775/16955 [00:57<00:13, 239.84it/s, loss=2.521, v_num=946a]\n",
      "Epoch 1:  82%|████████▏ | 13870/16955 [00:57<00:12, 241.00it/s, loss=2.521, v_num=946a]\n",
      "Epoch 1:  82%|████████▏ | 13965/16955 [00:57<00:12, 242.15it/s, loss=2.521, v_num=946a]\n",
      "Epoch 1:  83%|████████▎ | 14060/16955 [00:57<00:11, 243.34it/s, loss=2.521, v_num=946a]\n",
      "Epoch 1:  83%|████████▎ | 14155/16955 [00:57<00:11, 244.53it/s, loss=2.521, v_num=946a]\n",
      "Epoch 1:  84%|████████▍ | 14250/16955 [00:57<00:11, 245.70it/s, loss=2.521, v_num=946a]\n",
      "Validating:  47%|████▋     | 2382/5087 [00:04<00:03, 814.81it/s]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 14345/16955 [00:58<00:10, 246.82it/s, loss=2.521, v_num=946a]\n",
      "Epoch 1:  85%|████████▌ | 14440/16955 [00:58<00:10, 247.94it/s, loss=2.521, v_num=946a]\n",
      "Epoch 1:  86%|████████▌ | 14535/16955 [00:58<00:09, 249.05it/s, loss=2.521, v_num=946a]\n",
      "Epoch 1:  86%|████████▋ | 14630/16955 [00:58<00:09, 250.17it/s, loss=2.521, v_num=946a]\n",
      "Epoch 1:  87%|████████▋ | 14725/16955 [00:58<00:08, 251.29it/s, loss=2.521, v_num=946a]\n",
      "Epoch 1:  87%|████████▋ | 14820/16955 [00:58<00:08, 252.41it/s, loss=2.521, v_num=946a]\n",
      "Validating:  58%|█████▊    | 2961/5087 [00:05<00:02, 803.94it/s]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 14915/16955 [00:58<00:08, 253.47it/s, loss=2.521, v_num=946a]\n",
      "Epoch 1:  89%|████████▊ | 15010/16955 [00:58<00:07, 254.56it/s, loss=2.521, v_num=946a]\n",
      "Epoch 1:  89%|████████▉ | 15105/16955 [00:59<00:07, 255.69it/s, loss=2.521, v_num=946a]\n",
      "Epoch 1:  90%|████████▉ | 15200/16955 [00:59<00:06, 256.80it/s, loss=2.521, v_num=946a]\n",
      "Epoch 1:  90%|█████████ | 15295/16955 [00:59<00:06, 257.90it/s, loss=2.521, v_num=946a]\n",
      "Epoch 1:  91%|█████████ | 15390/16955 [00:59<00:06, 259.01it/s, loss=2.521, v_num=946a]\n",
      "Epoch 1:  91%|█████████▏| 15485/16955 [00:59<00:05, 260.11it/s, loss=2.521, v_num=946a]\n",
      "Validating:  71%|███████   | 3622/5087 [00:05<00:01, 825.49it/s]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 15580/16955 [00:59<00:05, 261.20it/s, loss=2.521, v_num=946a]\n",
      "Epoch 1:  92%|█████████▏| 15675/16955 [00:59<00:04, 262.28it/s, loss=2.521, v_num=946a]\n",
      "Epoch 1:  93%|█████████▎| 15770/16955 [00:59<00:04, 263.36it/s, loss=2.521, v_num=946a]\n",
      "Epoch 1:  94%|█████████▎| 15865/16955 [01:00<00:04, 264.40it/s, loss=2.521, v_num=946a]\n",
      "Epoch 1:  94%|█████████▍| 15960/16955 [01:00<00:03, 265.46it/s, loss=2.521, v_num=946a]\n",
      "Epoch 1:  95%|█████████▍| 16055/16955 [01:00<00:03, 266.55it/s, loss=2.521, v_num=946a]\n",
      "Epoch 1:  95%|█████████▌| 16150/16955 [01:00<00:03, 267.60it/s, loss=2.521, v_num=946a]\n",
      "Epoch 1:  96%|█████████▌| 16245/16955 [01:00<00:02, 268.68it/s, loss=2.521, v_num=946a]\n",
      "Validating:  86%|████████▌ | 4378/5087 [00:06<00:00, 823.55it/s]\u001b[A\n",
      "Epoch 1:  96%|█████████▋| 16340/16955 [01:00<00:02, 269.75it/s, loss=2.521, v_num=946a]\n",
      "Epoch 1:  97%|█████████▋| 16435/16955 [01:00<00:01, 270.80it/s, loss=2.521, v_num=946a]\n",
      "Epoch 1:  97%|█████████▋| 16530/16955 [01:00<00:01, 271.86it/s, loss=2.521, v_num=946a]\n",
      "Epoch 1:  98%|█████████▊| 16625/16955 [01:00<00:01, 272.86it/s, loss=2.521, v_num=946a]\n",
      "Epoch 1:  99%|█████████▊| 16720/16955 [01:01<00:00, 273.89it/s, loss=2.521, v_num=946a]\n",
      "Epoch 1:  99%|█████████▉| 16815/16955 [01:01<00:00, 274.95it/s, loss=2.521, v_num=946a]\n",
      "Epoch 1: 100%|█████████▉| 16910/16955 [01:01<00:00, 275.99it/s, loss=2.521, v_num=946a]\n",
      "Validating:  99%|█████████▉| 5055/5087 [00:07<00:00, 831.17it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: avg_val_loss reached 2.87084 (best 2.87084), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v8.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 16955/16955 [01:01<00:00, 275.13it/s, loss=2.521, v_num=946a]\n",
      "Epoch 2:  70%|██████▉   | 11868/16955 [00:54<00:23, 218.24it/s, loss=2.538, v_num=946a]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2:  70%|███████   | 11875/16955 [00:55<00:23, 212.87it/s, loss=2.538, v_num=946a]\n",
      "Epoch 2:  71%|███████   | 11970/16955 [00:55<00:23, 214.14it/s, loss=2.538, v_num=946a]\n",
      "Epoch 2:  71%|███████   | 12065/16955 [00:56<00:22, 215.40it/s, loss=2.538, v_num=946a]\n",
      "Epoch 2:  72%|███████▏  | 12160/16955 [00:56<00:22, 216.67it/s, loss=2.538, v_num=946a]\n",
      "Epoch 2:  72%|███████▏  | 12255/16955 [00:56<00:21, 217.92it/s, loss=2.538, v_num=946a]\n",
      "Epoch 2:  73%|███████▎  | 12350/16955 [00:56<00:21, 219.17it/s, loss=2.538, v_num=946a]\n",
      "Validating:  10%|▉         | 489/5087 [00:01<12:27,  6.15it/s]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 12445/16955 [00:56<00:20, 220.38it/s, loss=2.538, v_num=946a]\n",
      "Epoch 2:  74%|███████▍  | 12540/16955 [00:56<00:19, 221.60it/s, loss=2.538, v_num=946a]\n",
      "Epoch 2:  75%|███████▍  | 12635/16955 [00:56<00:19, 222.81it/s, loss=2.538, v_num=946a]\n",
      "Epoch 2:  75%|███████▌  | 12730/16955 [00:56<00:18, 224.02it/s, loss=2.538, v_num=946a]\n",
      "Epoch 2:  76%|███████▌  | 12825/16955 [00:56<00:18, 225.22it/s, loss=2.538, v_num=946a]\n",
      "Validating:  19%|█▉        | 972/5087 [00:02<01:23, 49.40it/s]\u001b[A\n",
      "Epoch 2:  76%|███████▌  | 12920/16955 [00:57<00:17, 226.38it/s, loss=2.538, v_num=946a]\n",
      "Epoch 2:  77%|███████▋  | 13015/16955 [00:57<00:17, 227.57it/s, loss=2.538, v_num=946a]\n",
      "Epoch 2:  77%|███████▋  | 13110/16955 [00:57<00:16, 228.75it/s, loss=2.538, v_num=946a]\n",
      "Epoch 2:  78%|███████▊  | 13205/16955 [00:57<00:16, 229.95it/s, loss=2.538, v_num=946a]\n",
      "Epoch 2:  78%|███████▊  | 13300/16955 [00:57<00:15, 231.15it/s, loss=2.538, v_num=946a]\n",
      "Epoch 2:  79%|███████▉  | 13395/16955 [00:57<00:15, 232.34it/s, loss=2.538, v_num=946a]\n",
      "Epoch 2:  80%|███████▉  | 13490/16955 [00:57<00:14, 233.55it/s, loss=2.538, v_num=946a]\n",
      "Epoch 2:  80%|████████  | 13585/16955 [00:57<00:14, 234.71it/s, loss=2.538, v_num=946a]\n",
      "Validating:  34%|███▍      | 1717/5087 [00:03<00:06, 504.61it/s]\u001b[A\n",
      "Epoch 2:  81%|████████  | 13680/16955 [00:57<00:13, 235.88it/s, loss=2.538, v_num=946a]\n",
      "Epoch 2:  81%|████████  | 13775/16955 [00:58<00:13, 237.02it/s, loss=2.538, v_num=946a]\n",
      "Epoch 2:  82%|████████▏ | 13870/16955 [00:58<00:12, 238.16it/s, loss=2.538, v_num=946a]\n",
      "Epoch 2:  82%|████████▏ | 13965/16955 [00:58<00:12, 239.31it/s, loss=2.538, v_num=946a]\n",
      "Epoch 2:  83%|████████▎ | 14060/16955 [00:58<00:12, 240.46it/s, loss=2.538, v_num=946a]\n",
      "Epoch 2:  83%|████████▎ | 14155/16955 [00:58<00:11, 241.62it/s, loss=2.538, v_num=946a]\n",
      "Epoch 2:  84%|████████▍ | 14250/16955 [00:58<00:11, 242.77it/s, loss=2.538, v_num=946a]\n",
      "Validating:  47%|████▋     | 2383/5087 [00:04<00:03, 795.24it/s]\u001b[A\n",
      "Epoch 2:  85%|████████▍ | 14345/16955 [00:58<00:10, 243.88it/s, loss=2.538, v_num=946a]\n",
      "Epoch 2:  85%|████████▌ | 14440/16955 [00:58<00:10, 244.99it/s, loss=2.538, v_num=946a]\n",
      "Epoch 2:  86%|████████▌ | 14535/16955 [00:59<00:09, 246.12it/s, loss=2.538, v_num=946a]\n",
      "Epoch 2:  86%|████████▋ | 14630/16955 [00:59<00:09, 247.22it/s, loss=2.538, v_num=946a]\n",
      "Epoch 2:  87%|████████▋ | 14725/16955 [00:59<00:08, 248.32it/s, loss=2.538, v_num=946a]\n",
      "Epoch 2:  87%|████████▋ | 14820/16955 [00:59<00:08, 249.44it/s, loss=2.538, v_num=946a]\n",
      "Validating:  58%|█████▊    | 2953/5087 [00:05<00:02, 798.18it/s]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 14915/16955 [00:59<00:08, 250.54it/s, loss=2.538, v_num=946a]\n",
      "Epoch 2:  89%|████████▊ | 15010/16955 [00:59<00:07, 251.67it/s, loss=2.538, v_num=946a]\n",
      "Epoch 2:  89%|████████▉ | 15105/16955 [00:59<00:07, 252.78it/s, loss=2.538, v_num=946a]\n",
      "Epoch 2:  90%|████████▉ | 15200/16955 [00:59<00:06, 253.89it/s, loss=2.538, v_num=946a]\n",
      "Epoch 2:  90%|█████████ | 15295/16955 [00:59<00:06, 254.98it/s, loss=2.538, v_num=946a]\n",
      "Epoch 2:  91%|█████████ | 15390/16955 [01:00<00:06, 256.07it/s, loss=2.538, v_num=946a]\n",
      "Epoch 2:  91%|█████████▏| 15485/16955 [01:00<00:05, 257.16it/s, loss=2.538, v_num=946a]\n",
      "Validating:  71%|███████   | 3623/5087 [00:05<00:01, 820.23it/s]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 15580/16955 [01:00<00:05, 258.25it/s, loss=2.538, v_num=946a]\n",
      "Epoch 2:  92%|█████████▏| 15675/16955 [01:00<00:04, 259.33it/s, loss=2.538, v_num=946a]\n",
      "Epoch 2:  93%|█████████▎| 15770/16955 [01:00<00:04, 260.41it/s, loss=2.538, v_num=946a]\n",
      "Epoch 2:  94%|█████████▎| 15865/16955 [01:00<00:04, 261.51it/s, loss=2.538, v_num=946a]\n",
      "Epoch 2:  94%|█████████▍| 15960/16955 [01:00<00:03, 262.57it/s, loss=2.538, v_num=946a]\n",
      "Epoch 2:  95%|█████████▍| 16055/16955 [01:00<00:03, 263.63it/s, loss=2.538, v_num=946a]\n",
      "Epoch 2:  95%|█████████▌| 16150/16955 [01:01<00:03, 264.71it/s, loss=2.538, v_num=946a]\n",
      "Epoch 2:  96%|█████████▌| 16245/16955 [01:01<00:02, 265.78it/s, loss=2.538, v_num=946a]\n",
      "Validating:  86%|████████▌ | 4385/5087 [00:06<00:00, 835.24it/s]\u001b[A\n",
      "Epoch 2:  96%|█████████▋| 16340/16955 [01:01<00:02, 266.82it/s, loss=2.538, v_num=946a]\n",
      "Epoch 2:  97%|█████████▋| 16435/16955 [01:01<00:01, 267.88it/s, loss=2.538, v_num=946a]\n",
      "Epoch 2:  97%|█████████▋| 16530/16955 [01:01<00:01, 268.93it/s, loss=2.538, v_num=946a]\n",
      "Epoch 2:  98%|█████████▊| 16625/16955 [01:01<00:01, 269.94it/s, loss=2.538, v_num=946a]\n",
      "Epoch 2:  99%|█████████▊| 16720/16955 [01:01<00:00, 270.97it/s, loss=2.538, v_num=946a]\n",
      "Epoch 2:  99%|█████████▉| 16815/16955 [01:01<00:00, 272.00it/s, loss=2.538, v_num=946a]\n",
      "Epoch 2: 100%|█████████▉| 16910/16955 [01:01<00:00, 273.04it/s, loss=2.538, v_num=946a]\n",
      "Validating: 100%|█████████▉| 5062/5087 [00:07<00:00, 826.78it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: avg_val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 16955/16955 [01:02<00:00, 272.40it/s, loss=2.538, v_num=946a]\n",
      "Epoch 3:  70%|██████▉   | 11868/16955 [00:54<00:23, 217.15it/s, loss=2.579, v_num=946a]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 3:  70%|███████   | 11875/16955 [00:56<00:23, 211.93it/s, loss=2.579, v_num=946a]\n",
      "Epoch 3:  71%|███████   | 11970/16955 [00:56<00:23, 213.12it/s, loss=2.579, v_num=946a]\n",
      "Epoch 3:  71%|███████   | 12065/16955 [00:56<00:22, 214.37it/s, loss=2.579, v_num=946a]\n",
      "Epoch 3:  72%|███████▏  | 12160/16955 [00:56<00:22, 215.62it/s, loss=2.579, v_num=946a]\n",
      "Epoch 3:  72%|███████▏  | 12255/16955 [00:56<00:21, 216.86it/s, loss=2.579, v_num=946a]\n",
      "Epoch 3:  73%|███████▎  | 12350/16955 [00:56<00:21, 218.13it/s, loss=2.579, v_num=946a]\n",
      "Validating:  10%|▉         | 486/5087 [00:01<12:24,  6.18it/s]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 12445/16955 [00:56<00:20, 219.32it/s, loss=2.579, v_num=946a]\n",
      "Epoch 3:  74%|███████▍  | 12540/16955 [00:56<00:20, 220.53it/s, loss=2.579, v_num=946a]\n",
      "Epoch 3:  75%|███████▍  | 12635/16955 [00:56<00:19, 221.75it/s, loss=2.579, v_num=946a]\n",
      "Epoch 3:  75%|███████▌  | 12730/16955 [00:57<00:18, 222.93it/s, loss=2.579, v_num=946a]\n",
      "Epoch 3:  76%|███████▌  | 12825/16955 [00:57<00:18, 224.13it/s, loss=2.579, v_num=946a]\n",
      "Validating:  19%|█▉        | 967/5087 [00:02<01:23, 49.58it/s]\u001b[A\n",
      "Epoch 3:  76%|███████▌  | 12920/16955 [00:57<00:17, 225.32it/s, loss=2.579, v_num=946a]\n",
      "Epoch 3:  77%|███████▋  | 13015/16955 [00:57<00:17, 226.49it/s, loss=2.579, v_num=946a]\n",
      "Epoch 3:  77%|███████▋  | 13110/16955 [00:57<00:16, 227.66it/s, loss=2.579, v_num=946a]\n",
      "Epoch 3:  78%|███████▊  | 13205/16955 [00:57<00:16, 228.82it/s, loss=2.579, v_num=946a]\n",
      "Epoch 3:  78%|███████▊  | 13300/16955 [00:57<00:15, 229.99it/s, loss=2.579, v_num=946a]\n",
      "Epoch 3:  79%|███████▉  | 13395/16955 [00:57<00:15, 231.18it/s, loss=2.579, v_num=946a]\n",
      "Validating:  30%|███       | 1533/5087 [00:03<00:09, 356.41it/s]\u001b[A\n",
      "Epoch 3:  80%|███████▉  | 13490/16955 [00:58<00:14, 232.34it/s, loss=2.579, v_num=946a]\n",
      "Epoch 3:  80%|████████  | 13585/16955 [00:58<00:14, 233.49it/s, loss=2.579, v_num=946a]\n",
      "Epoch 3:  81%|████████  | 13680/16955 [00:58<00:13, 234.68it/s, loss=2.579, v_num=946a]\n",
      "Epoch 3:  81%|████████  | 13775/16955 [00:58<00:13, 235.85it/s, loss=2.579, v_num=946a]\n",
      "Epoch 3:  82%|████████▏ | 13870/16955 [00:58<00:13, 237.01it/s, loss=2.579, v_num=946a]\n",
      "Epoch 3:  82%|████████▏ | 13965/16955 [00:58<00:12, 238.17it/s, loss=2.579, v_num=946a]\n",
      "Epoch 3:  83%|████████▎ | 14060/16955 [00:58<00:12, 239.32it/s, loss=2.579, v_num=946a]\n",
      "Epoch 3:  83%|████████▎ | 14155/16955 [00:58<00:11, 240.51it/s, loss=2.579, v_num=946a]\n",
      "Validating:  45%|████▌     | 2292/5087 [00:04<00:03, 802.89it/s]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 14250/16955 [00:58<00:11, 241.65it/s, loss=2.579, v_num=946a]\n",
      "Epoch 3:  85%|████████▍ | 14345/16955 [00:59<00:10, 242.80it/s, loss=2.579, v_num=946a]\n",
      "Epoch 3:  85%|████████▌ | 14440/16955 [00:59<00:10, 243.95it/s, loss=2.579, v_num=946a]\n",
      "Epoch 3:  86%|████████▌ | 14535/16955 [00:59<00:09, 245.06it/s, loss=2.579, v_num=946a]\n",
      "Epoch 3:  86%|████████▋ | 14630/16955 [00:59<00:09, 246.18it/s, loss=2.579, v_num=946a]\n",
      "Epoch 3:  87%|████████▋ | 14725/16955 [00:59<00:09, 247.28it/s, loss=2.579, v_num=946a]\n",
      "Epoch 3:  87%|████████▋ | 14820/16955 [00:59<00:08, 248.39it/s, loss=2.579, v_num=946a]\n",
      "Epoch 3:  88%|████████▊ | 14915/16955 [00:59<00:08, 249.48it/s, loss=2.579, v_num=946a]\n",
      "Validating:  60%|█████▉    | 3050/5087 [00:05<00:02, 801.96it/s]\u001b[A\n",
      "Epoch 3:  89%|████████▊ | 15010/16955 [00:59<00:07, 250.58it/s, loss=2.579, v_num=946a]\n",
      "Epoch 3:  89%|████████▉ | 15105/16955 [01:00<00:07, 251.69it/s, loss=2.579, v_num=946a]\n",
      "Epoch 3:  90%|████████▉ | 15200/16955 [01:00<00:06, 252.78it/s, loss=2.579, v_num=946a]\n",
      "Epoch 3:  90%|█████████ | 15295/16955 [01:00<00:06, 253.83it/s, loss=2.579, v_num=946a]\n",
      "Epoch 3:  91%|█████████ | 15390/16955 [01:00<00:06, 254.95it/s, loss=2.579, v_num=946a]\n",
      "Epoch 3:  91%|█████████▏| 15485/16955 [01:00<00:05, 256.07it/s, loss=2.579, v_num=946a]\n",
      "Epoch 3:  92%|█████████▏| 15580/16955 [01:00<00:05, 257.15it/s, loss=2.579, v_num=946a]\n",
      "Epoch 3:  92%|█████████▏| 15675/16955 [01:00<00:04, 258.24it/s, loss=2.579, v_num=946a]\n",
      "Validating:  75%|███████▍  | 3813/5087 [00:06<00:01, 838.30it/s]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 15770/16955 [01:00<00:04, 259.31it/s, loss=2.579, v_num=946a]\n",
      "Epoch 3:  94%|█████████▎| 15865/16955 [01:00<00:04, 260.38it/s, loss=2.579, v_num=946a]\n",
      "Epoch 3:  94%|█████████▍| 15960/16955 [01:01<00:03, 261.46it/s, loss=2.579, v_num=946a]\n",
      "Epoch 3:  95%|█████████▍| 16055/16955 [01:01<00:03, 262.53it/s, loss=2.579, v_num=946a]\n",
      "Epoch 3:  95%|█████████▌| 16150/16955 [01:01<00:03, 263.62it/s, loss=2.579, v_num=946a]\n",
      "Epoch 3:  96%|█████████▌| 16245/16955 [01:01<00:02, 264.67it/s, loss=2.579, v_num=946a]\n",
      "Epoch 3:  96%|█████████▋| 16340/16955 [01:01<00:02, 265.72it/s, loss=2.579, v_num=946a]\n",
      "Epoch 3:  97%|█████████▋| 16435/16955 [01:01<00:01, 266.78it/s, loss=2.579, v_num=946a]\n",
      "Epoch 3:  97%|█████████▋| 16530/16955 [01:01<00:01, 267.85it/s, loss=2.579, v_num=946a]\n",
      "Validating:  92%|█████████▏| 4671/5087 [00:07<00:00, 847.03it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 16625/16955 [01:01<00:01, 268.89it/s, loss=2.579, v_num=946a]\n",
      "Epoch 3:  99%|█████████▊| 16720/16955 [01:01<00:00, 269.93it/s, loss=2.579, v_num=946a]\n",
      "Epoch 3:  99%|█████████▉| 16815/16955 [01:02<00:00, 270.97it/s, loss=2.579, v_num=946a]\n",
      "Epoch 3: 100%|█████████▉| 16910/16955 [01:02<00:00, 272.02it/s, loss=2.579, v_num=946a]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: avg_val_loss reached 2.84829 (best 2.84829), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v7.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 16955/16955 [01:02<00:00, 271.36it/s, loss=2.579, v_num=946a]\n",
      "Epoch 4:  70%|██████▉   | 11868/16955 [00:54<00:23, 216.43it/s, loss=2.469, v_num=946a]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 4:  70%|███████   | 11875/16955 [00:56<00:24, 210.71it/s, loss=2.469, v_num=946a]\n",
      "Epoch 4:  71%|███████   | 11970/16955 [00:56<00:23, 211.93it/s, loss=2.469, v_num=946a]\n",
      "Epoch 4:  71%|███████   | 12065/16955 [00:56<00:22, 213.16it/s, loss=2.469, v_num=946a]\n",
      "Epoch 4:  72%|███████▏  | 12160/16955 [00:56<00:22, 214.41it/s, loss=2.469, v_num=946a]\n",
      "Epoch 4:  72%|███████▏  | 12255/16955 [00:56<00:21, 215.67it/s, loss=2.469, v_num=946a]\n",
      "Epoch 4:  73%|███████▎  | 12350/16955 [00:56<00:21, 216.87it/s, loss=2.469, v_num=946a]\n",
      "Validating:  10%|▉         | 485/5087 [00:02<13:42,  5.59it/s]\u001b[A\n",
      "Epoch 4:  73%|███████▎  | 12445/16955 [00:57<00:20, 218.07it/s, loss=2.469, v_num=946a]\n",
      "Epoch 4:  74%|███████▍  | 12540/16955 [00:57<00:20, 219.28it/s, loss=2.469, v_num=946a]\n",
      "Epoch 4:  75%|███████▍  | 12635/16955 [00:57<00:19, 220.50it/s, loss=2.469, v_num=946a]\n",
      "Epoch 4:  75%|███████▌  | 12730/16955 [00:57<00:19, 221.72it/s, loss=2.469, v_num=946a]\n",
      "Epoch 4:  76%|███████▌  | 12825/16955 [00:57<00:18, 222.93it/s, loss=2.469, v_num=946a]\n",
      "Epoch 4:  76%|███████▌  | 12920/16955 [00:57<00:18, 224.14it/s, loss=2.469, v_num=946a]\n",
      "Epoch 4:  77%|███████▋  | 13015/16955 [00:57<00:17, 225.36it/s, loss=2.469, v_num=946a]\n",
      "Validating:  23%|██▎       | 1150/5087 [00:02<00:44, 87.50it/s]\u001b[A\n",
      "Epoch 4:  77%|███████▋  | 13110/16955 [00:57<00:16, 226.55it/s, loss=2.469, v_num=946a]\n",
      "Epoch 4:  78%|███████▊  | 13205/16955 [00:57<00:16, 227.75it/s, loss=2.469, v_num=946a]\n",
      "Epoch 4:  78%|███████▊  | 13300/16955 [00:58<00:15, 228.94it/s, loss=2.469, v_num=946a]\n",
      "Epoch 4:  79%|███████▉  | 13395/16955 [00:58<00:15, 230.13it/s, loss=2.469, v_num=946a]\n",
      "Epoch 4:  80%|███████▉  | 13490/16955 [00:58<00:14, 231.31it/s, loss=2.469, v_num=946a]\n",
      "Epoch 4:  80%|████████  | 13585/16955 [00:58<00:14, 232.49it/s, loss=2.469, v_num=946a]\n",
      "Epoch 4:  81%|████████  | 13680/16955 [00:58<00:14, 233.66it/s, loss=2.469, v_num=946a]\n",
      "Epoch 4:  81%|████████  | 13775/16955 [00:58<00:13, 234.80it/s, loss=2.469, v_num=946a]\n",
      "Validating:  38%|███▊      | 1911/5087 [00:03<00:05, 611.14it/s]\u001b[A\n",
      "Epoch 4:  82%|████████▏ | 13870/16955 [00:58<00:13, 235.92it/s, loss=2.469, v_num=946a]\n",
      "Epoch 4:  82%|████████▏ | 13965/16955 [00:58<00:12, 237.08it/s, loss=2.469, v_num=946a]\n",
      "Epoch 4:  83%|████████▎ | 14060/16955 [00:59<00:12, 238.22it/s, loss=2.469, v_num=946a]\n",
      "Epoch 4:  83%|████████▎ | 14155/16955 [00:59<00:11, 239.37it/s, loss=2.469, v_num=946a]\n",
      "Epoch 4:  84%|████████▍ | 14250/16955 [00:59<00:11, 240.50it/s, loss=2.469, v_num=946a]\n",
      "Epoch 4:  85%|████████▍ | 14345/16955 [00:59<00:10, 241.62it/s, loss=2.469, v_num=946a]\n",
      "Epoch 4:  85%|████████▌ | 14440/16955 [00:59<00:10, 242.74it/s, loss=2.469, v_num=946a]\n",
      "Validating:  51%|█████     | 2572/5087 [00:04<00:03, 796.31it/s]\u001b[A\n",
      "Epoch 4:  86%|████████▌ | 14535/16955 [00:59<00:09, 243.84it/s, loss=2.469, v_num=946a]\n",
      "Epoch 4:  86%|████████▋ | 14630/16955 [00:59<00:09, 244.97it/s, loss=2.469, v_num=946a]\n",
      "Epoch 4:  87%|████████▋ | 14725/16955 [00:59<00:09, 246.10it/s, loss=2.469, v_num=946a]\n",
      "Epoch 4:  87%|████████▋ | 14820/16955 [00:59<00:08, 247.21it/s, loss=2.469, v_num=946a]\n",
      "Epoch 4:  88%|████████▊ | 14915/16955 [01:00<00:08, 248.32it/s, loss=2.469, v_num=946a]\n",
      "Epoch 4:  89%|████████▊ | 15010/16955 [01:00<00:07, 249.44it/s, loss=2.469, v_num=946a]\n",
      "Epoch 4:  89%|████████▉ | 15105/16955 [01:00<00:07, 250.53it/s, loss=2.469, v_num=946a]\n",
      "Validating:  64%|██████▍   | 3247/5087 [00:05<00:02, 821.11it/s]\u001b[A\n",
      "Epoch 4:  90%|████████▉ | 15200/16955 [01:00<00:06, 251.58it/s, loss=2.469, v_num=946a]\n",
      "Epoch 4:  90%|█████████ | 15295/16955 [01:00<00:06, 252.67it/s, loss=2.469, v_num=946a]\n",
      "Epoch 4:  91%|█████████ | 15390/16955 [01:00<00:06, 253.74it/s, loss=2.469, v_num=946a]\n",
      "Epoch 4:  91%|█████████▏| 15485/16955 [01:00<00:05, 254.83it/s, loss=2.469, v_num=946a]\n",
      "Epoch 4:  92%|█████████▏| 15580/16955 [01:00<00:05, 255.88it/s, loss=2.469, v_num=946a]\n",
      "Epoch 4:  92%|█████████▏| 15675/16955 [01:01<00:04, 256.96it/s, loss=2.469, v_num=946a]\n",
      "Epoch 4:  93%|█████████▎| 15770/16955 [01:01<00:04, 258.03it/s, loss=2.469, v_num=946a]\n",
      "Validating:  77%|███████▋  | 3907/5087 [00:06<00:01, 809.11it/s]\u001b[A\n",
      "Epoch 4:  94%|█████████▎| 15865/16955 [01:01<00:04, 259.07it/s, loss=2.469, v_num=946a]\n",
      "Epoch 4:  94%|█████████▍| 15960/16955 [01:01<00:03, 260.11it/s, loss=2.469, v_num=946a]\n",
      "Epoch 4:  95%|█████████▍| 16055/16955 [01:01<00:03, 261.16it/s, loss=2.469, v_num=946a]\n",
      "Epoch 4:  95%|█████████▌| 16150/16955 [01:01<00:03, 262.20it/s, loss=2.469, v_num=946a]\n",
      "Epoch 4:  96%|█████████▌| 16245/16955 [01:01<00:02, 263.21it/s, loss=2.469, v_num=946a]\n",
      "Epoch 4:  96%|█████████▋| 16340/16955 [01:01<00:02, 264.23it/s, loss=2.469, v_num=946a]\n",
      "Validating:  88%|████████▊ | 4477/5087 [00:07<00:00, 785.38it/s]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 16435/16955 [01:01<00:01, 265.24it/s, loss=2.469, v_num=946a]\n",
      "Epoch 4:  97%|█████████▋| 16530/16955 [01:02<00:01, 266.27it/s, loss=2.469, v_num=946a]\n",
      "Epoch 4:  98%|█████████▊| 16625/16955 [01:02<00:01, 267.30it/s, loss=2.469, v_num=946a]\n",
      "Epoch 4:  99%|█████████▊| 16720/16955 [01:02<00:00, 268.34it/s, loss=2.469, v_num=946a]\n",
      "Epoch 4:  99%|█████████▉| 16815/16955 [01:02<00:00, 269.36it/s, loss=2.469, v_num=946a]\n",
      "Epoch 4: 100%|█████████▉| 16910/16955 [01:02<00:00, 270.37it/s, loss=2.469, v_num=946a]\n",
      "Validating:  99%|█████████▉| 5052/5087 [00:07<00:00, 807.14it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: avg_val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 16955/16955 [01:02<00:00, 269.56it/s, loss=2.469, v_num=946a]\n",
      "Epoch 5:  70%|██████▉   | 11868/16955 [00:54<00:23, 217.58it/s, loss=2.429, v_num=946a]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 5:  70%|███████   | 11875/16955 [00:56<00:23, 212.01it/s, loss=2.429, v_num=946a]\n",
      "Epoch 5:  71%|███████   | 11970/16955 [00:56<00:23, 213.18it/s, loss=2.429, v_num=946a]\n",
      "Epoch 5:  71%|███████   | 12065/16955 [00:56<00:22, 214.42it/s, loss=2.429, v_num=946a]\n",
      "Epoch 5:  72%|███████▏  | 12160/16955 [00:56<00:22, 215.65it/s, loss=2.429, v_num=946a]\n",
      "Validating:   6%|▌         | 302/5087 [00:01<27:52,  2.86it/s]\u001b[A\n",
      "Epoch 5:  72%|███████▏  | 12255/16955 [00:56<00:21, 216.86it/s, loss=2.429, v_num=946a]\n",
      "Epoch 5:  73%|███████▎  | 12350/16955 [00:56<00:21, 218.10it/s, loss=2.429, v_num=946a]\n",
      "Epoch 5:  73%|███████▎  | 12445/16955 [00:56<00:20, 219.30it/s, loss=2.429, v_num=946a]\n",
      "Epoch 5:  74%|███████▍  | 12540/16955 [00:56<00:20, 220.51it/s, loss=2.429, v_num=946a]\n",
      "Epoch 5:  75%|███████▍  | 12635/16955 [00:56<00:19, 221.74it/s, loss=2.429, v_num=946a]\n",
      "Epoch 5:  75%|███████▌  | 12730/16955 [00:57<00:18, 222.97it/s, loss=2.429, v_num=946a]\n",
      "Validating:  17%|█▋        | 867/5087 [00:02<02:08, 32.84it/s]\u001b[A\n",
      "Epoch 5:  76%|███████▌  | 12825/16955 [00:57<00:18, 223.60it/s, loss=2.429, v_num=946a]\n",
      "Epoch 5:  76%|███████▌  | 12920/16955 [00:57<00:17, 224.80it/s, loss=2.429, v_num=946a]\n",
      "Epoch 5:  77%|███████▋  | 13015/16955 [00:57<00:17, 226.01it/s, loss=2.429, v_num=946a]\n",
      "Epoch 5:  77%|███████▋  | 13110/16955 [00:57<00:16, 227.21it/s, loss=2.429, v_num=946a]\n",
      "Epoch 5:  78%|███████▊  | 13205/16955 [00:57<00:16, 228.37it/s, loss=2.429, v_num=946a]\n",
      "Epoch 5:  78%|███████▊  | 13300/16955 [00:57<00:15, 229.55it/s, loss=2.429, v_num=946a]\n",
      "Validating:  28%|██▊       | 1438/5087 [00:03<00:13, 273.67it/s]\u001b[A\n",
      "Epoch 5:  79%|███████▉  | 13395/16955 [00:58<00:15, 230.68it/s, loss=2.429, v_num=946a]\n",
      "Epoch 5:  80%|███████▉  | 13490/16955 [00:58<00:14, 231.82it/s, loss=2.429, v_num=946a]\n",
      "Epoch 5:  80%|████████  | 13585/16955 [00:58<00:14, 232.98it/s, loss=2.429, v_num=946a]\n",
      "Epoch 5:  81%|████████  | 13680/16955 [00:58<00:13, 234.13it/s, loss=2.429, v_num=946a]\n",
      "Epoch 5:  81%|████████  | 13775/16955 [00:58<00:13, 235.28it/s, loss=2.429, v_num=946a]\n",
      "Validating:  38%|███▊      | 1918/5087 [00:04<00:04, 648.12it/s]\u001b[A\n",
      "Epoch 5:  82%|████████▏ | 13870/16955 [00:58<00:13, 236.42it/s, loss=2.429, v_num=946a]\n",
      "Epoch 5:  82%|████████▏ | 13965/16955 [00:58<00:12, 237.57it/s, loss=2.429, v_num=946a]\n",
      "Epoch 5:  83%|████████▎ | 14060/16955 [00:58<00:12, 238.70it/s, loss=2.429, v_num=946a]\n",
      "Epoch 5:  83%|████████▎ | 14155/16955 [00:59<00:11, 239.82it/s, loss=2.429, v_num=946a]\n",
      "Epoch 5:  84%|████████▍ | 14250/16955 [00:59<00:11, 240.95it/s, loss=2.429, v_num=946a]\n",
      "Epoch 5:  85%|████████▍ | 14345/16955 [00:59<00:10, 242.08it/s, loss=2.429, v_num=946a]\n",
      "Epoch 5:  85%|████████▌ | 14440/16955 [00:59<00:10, 243.22it/s, loss=2.429, v_num=946a]\n",
      "Epoch 5:  86%|████████▌ | 14535/16955 [00:59<00:09, 244.37it/s, loss=2.429, v_num=946a]\n",
      "Validating:  52%|█████▏    | 2667/5087 [00:04<00:02, 824.99it/s]\u001b[A\n",
      "Epoch 5:  86%|████████▋ | 14630/16955 [00:59<00:09, 245.51it/s, loss=2.429, v_num=946a]\n",
      "Epoch 5:  87%|████████▋ | 14725/16955 [00:59<00:09, 246.63it/s, loss=2.429, v_num=946a]\n",
      "Epoch 5:  87%|████████▋ | 14820/16955 [00:59<00:08, 247.71it/s, loss=2.429, v_num=946a]\n",
      "Epoch 5:  88%|████████▊ | 14915/16955 [00:59<00:08, 248.80it/s, loss=2.429, v_num=946a]\n",
      "Epoch 5:  89%|████████▊ | 15010/16955 [01:00<00:07, 249.90it/s, loss=2.429, v_num=946a]\n",
      "Epoch 5:  89%|████████▉ | 15105/16955 [01:00<00:07, 250.99it/s, loss=2.429, v_num=946a]\n",
      "Epoch 5:  90%|████████▉ | 15200/16955 [01:00<00:06, 252.05it/s, loss=2.429, v_num=946a]\n",
      "Validating:  66%|██████▌   | 3333/5087 [00:05<00:02, 791.72it/s]\u001b[A\n",
      "Epoch 5:  90%|█████████ | 15295/16955 [01:00<00:06, 253.11it/s, loss=2.429, v_num=946a]\n",
      "Epoch 5:  91%|█████████ | 15390/16955 [01:00<00:06, 254.20it/s, loss=2.429, v_num=946a]\n",
      "Epoch 5:  91%|█████████▏| 15485/16955 [01:00<00:05, 255.27it/s, loss=2.429, v_num=946a]\n",
      "Epoch 5:  92%|█████████▏| 15580/16955 [01:00<00:05, 256.32it/s, loss=2.429, v_num=946a]\n",
      "Epoch 5:  92%|█████████▏| 15675/16955 [01:00<00:04, 257.39it/s, loss=2.429, v_num=946a]\n",
      "Epoch 5:  93%|█████████▎| 15770/16955 [01:01<00:04, 258.46it/s, loss=2.429, v_num=946a]\n",
      "Validating:  77%|███████▋  | 3907/5087 [00:06<00:01, 808.39it/s]\u001b[A\n",
      "Epoch 5:  94%|█████████▎| 15865/16955 [01:01<00:04, 259.52it/s, loss=2.429, v_num=946a]\n",
      "Epoch 5:  94%|█████████▍| 15960/16955 [01:01<00:03, 260.54it/s, loss=2.429, v_num=946a]\n",
      "Epoch 5:  95%|█████████▍| 16055/16955 [01:01<00:03, 261.59it/s, loss=2.429, v_num=946a]\n",
      "Epoch 5:  95%|█████████▌| 16150/16955 [01:01<00:03, 262.60it/s, loss=2.429, v_num=946a]\n",
      "Epoch 5:  96%|█████████▌| 16245/16955 [01:01<00:02, 263.63it/s, loss=2.429, v_num=946a]\n",
      "Epoch 5:  96%|█████████▋| 16340/16955 [01:01<00:02, 264.68it/s, loss=2.429, v_num=946a]\n",
      "Validating:  88%|████████▊ | 4478/5087 [00:07<00:00, 796.01it/s]\u001b[A\n",
      "Epoch 5:  97%|█████████▋| 16435/16955 [01:01<00:01, 265.68it/s, loss=2.429, v_num=946a]\n",
      "Epoch 5:  97%|█████████▋| 16530/16955 [01:01<00:01, 266.72it/s, loss=2.429, v_num=946a]\n",
      "Epoch 5:  98%|█████████▊| 16625/16955 [01:02<00:01, 267.77it/s, loss=2.429, v_num=946a]\n",
      "Epoch 5:  99%|█████████▊| 16720/16955 [01:02<00:00, 268.83it/s, loss=2.429, v_num=946a]\n",
      "Epoch 5:  99%|█████████▉| 16815/16955 [01:02<00:00, 269.85it/s, loss=2.429, v_num=946a]\n",
      "Epoch 5: 100%|█████████▉| 16910/16955 [01:02<00:00, 270.88it/s, loss=2.429, v_num=946a]\n",
      "Validating:  99%|█████████▉| 5061/5087 [00:07<00:00, 831.14it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: avg_val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 16955/16955 [01:02<00:00, 270.30it/s, loss=2.429, v_num=946a]\n",
      "Epoch 6:  70%|██████▉   | 11868/16955 [00:54<00:23, 218.91it/s, loss=2.394, v_num=946a]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 6:  70%|███████   | 11875/16955 [00:55<00:23, 213.81it/s, loss=2.394, v_num=946a]\n",
      "Epoch 6:  71%|███████   | 11970/16955 [00:55<00:23, 214.97it/s, loss=2.394, v_num=946a]\n",
      "Epoch 6:  71%|███████   | 12065/16955 [00:55<00:22, 216.24it/s, loss=2.394, v_num=946a]\n",
      "Epoch 6:  72%|███████▏  | 12160/16955 [00:55<00:22, 217.48it/s, loss=2.394, v_num=946a]\n",
      "Validating:   6%|▌         | 308/5087 [00:01<25:15,  3.15it/s]\u001b[A\n",
      "Epoch 6:  72%|███████▏  | 12255/16955 [00:56<00:21, 218.68it/s, loss=2.394, v_num=946a]\n",
      "Epoch 6:  73%|███████▎  | 12350/16955 [00:56<00:20, 219.93it/s, loss=2.394, v_num=946a]\n",
      "Epoch 6:  73%|███████▎  | 12445/16955 [00:56<00:20, 221.17it/s, loss=2.394, v_num=946a]\n",
      "Epoch 6:  74%|███████▍  | 12540/16955 [00:56<00:19, 222.42it/s, loss=2.394, v_num=946a]\n",
      "Epoch 6:  75%|███████▍  | 12635/16955 [00:56<00:19, 223.65it/s, loss=2.394, v_num=946a]\n",
      "Epoch 6:  75%|███████▌  | 12730/16955 [00:56<00:18, 224.85it/s, loss=2.394, v_num=946a]\n",
      "Epoch 6:  76%|███████▌  | 12825/16955 [00:56<00:18, 226.05it/s, loss=2.394, v_num=946a]\n",
      "Epoch 6:  76%|███████▌  | 12920/16955 [00:56<00:17, 227.29it/s, loss=2.394, v_num=946a]\n",
      "Validating:  21%|██        | 1052/5087 [00:02<00:56, 71.61it/s]\u001b[A\n",
      "Epoch 6:  77%|███████▋  | 13015/16955 [00:56<00:17, 228.45it/s, loss=2.394, v_num=946a]\n",
      "Epoch 6:  77%|███████▋  | 13110/16955 [00:57<00:16, 229.63it/s, loss=2.394, v_num=946a]\n",
      "Epoch 6:  78%|███████▊  | 13205/16955 [00:57<00:16, 230.78it/s, loss=2.394, v_num=946a]\n",
      "Epoch 6:  78%|███████▊  | 13300/16955 [00:57<00:15, 231.97it/s, loss=2.394, v_num=946a]\n",
      "Epoch 6:  79%|███████▉  | 13395/16955 [00:57<00:15, 233.17it/s, loss=2.394, v_num=946a]\n",
      "Epoch 6:  80%|███████▉  | 13490/16955 [00:57<00:14, 234.34it/s, loss=2.394, v_num=946a]\n",
      "Validating:  32%|███▏      | 1622/5087 [00:03<00:07, 436.42it/s]\u001b[A\n",
      "Epoch 6:  80%|████████  | 13585/16955 [00:57<00:14, 235.50it/s, loss=2.394, v_num=946a]\n",
      "Epoch 6:  81%|████████  | 13680/16955 [00:57<00:13, 236.64it/s, loss=2.394, v_num=946a]\n",
      "Epoch 6:  81%|████████  | 13775/16955 [00:57<00:13, 237.79it/s, loss=2.394, v_num=946a]\n",
      "Epoch 6:  82%|████████▏ | 13870/16955 [00:58<00:12, 238.96it/s, loss=2.394, v_num=946a]\n",
      "Epoch 6:  82%|████████▏ | 13965/16955 [00:58<00:12, 240.09it/s, loss=2.394, v_num=946a]\n",
      "Validating:  41%|████▏     | 2109/5087 [00:03<00:04, 718.02it/s]\u001b[A\n",
      "Epoch 6:  83%|████████▎ | 14060/16955 [00:58<00:12, 241.22it/s, loss=2.394, v_num=946a]\n",
      "Epoch 6:  83%|████████▎ | 14155/16955 [00:58<00:11, 242.33it/s, loss=2.394, v_num=946a]\n",
      "Epoch 6:  84%|████████▍ | 14250/16955 [00:58<00:11, 243.47it/s, loss=2.394, v_num=946a]\n",
      "Epoch 6:  85%|████████▍ | 14345/16955 [00:58<00:10, 244.61it/s, loss=2.394, v_num=946a]\n",
      "Epoch 6:  85%|████████▌ | 14440/16955 [00:58<00:10, 245.73it/s, loss=2.394, v_num=946a]\n",
      "Epoch 6:  86%|████████▌ | 14535/16955 [00:58<00:09, 246.82it/s, loss=2.394, v_num=946a]\n",
      "Validating:  53%|█████▎    | 2676/5087 [00:04<00:03, 768.82it/s]\u001b[A\n",
      "Epoch 6:  86%|████████▋ | 14630/16955 [00:59<00:09, 247.91it/s, loss=2.394, v_num=946a]\n",
      "Epoch 6:  87%|████████▋ | 14725/16955 [00:59<00:08, 249.02it/s, loss=2.394, v_num=946a]\n",
      "Epoch 6:  87%|████████▋ | 14820/16955 [00:59<00:08, 250.14it/s, loss=2.394, v_num=946a]\n",
      "Epoch 6:  88%|████████▊ | 14915/16955 [00:59<00:08, 251.26it/s, loss=2.394, v_num=946a]\n",
      "Epoch 6:  89%|████████▊ | 15010/16955 [00:59<00:07, 252.36it/s, loss=2.394, v_num=946a]\n",
      "Epoch 6:  89%|████████▉ | 15105/16955 [00:59<00:07, 253.45it/s, loss=2.394, v_num=946a]\n",
      "Epoch 6:  90%|████████▉ | 15200/16955 [00:59<00:06, 254.57it/s, loss=2.394, v_num=946a]\n",
      "Validating:  66%|██████▌   | 3337/5087 [00:05<00:02, 816.15it/s]\u001b[A\n",
      "Epoch 6:  90%|█████████ | 15295/16955 [00:59<00:06, 255.68it/s, loss=2.394, v_num=946a]\n",
      "Epoch 6:  91%|█████████ | 15390/16955 [00:59<00:06, 256.77it/s, loss=2.394, v_num=946a]\n",
      "Epoch 6:  91%|█████████▏| 15485/16955 [01:00<00:05, 257.84it/s, loss=2.394, v_num=946a]\n",
      "Epoch 6:  92%|█████████▏| 15580/16955 [01:00<00:05, 258.92it/s, loss=2.394, v_num=946a]\n",
      "Epoch 6:  92%|█████████▏| 15675/16955 [01:00<00:04, 260.00it/s, loss=2.394, v_num=946a]\n",
      "Epoch 6:  93%|█████████▎| 15770/16955 [01:00<00:04, 261.09it/s, loss=2.394, v_num=946a]\n",
      "Epoch 6:  94%|█████████▎| 15865/16955 [01:00<00:04, 262.17it/s, loss=2.394, v_num=946a]\n",
      "Epoch 6:  94%|█████████▍| 15960/16955 [01:00<00:03, 263.23it/s, loss=2.394, v_num=946a]\n",
      "Validating:  81%|████████  | 4098/5087 [00:06<00:01, 820.90it/s]\u001b[A\n",
      "Epoch 6:  95%|█████████▍| 16055/16955 [01:00<00:03, 264.29it/s, loss=2.394, v_num=946a]\n",
      "Epoch 6:  95%|█████████▌| 16150/16955 [01:00<00:03, 265.31it/s, loss=2.394, v_num=946a]\n",
      "Epoch 6:  96%|█████████▌| 16245/16955 [01:00<00:02, 266.34it/s, loss=2.394, v_num=946a]\n",
      "Epoch 6:  96%|█████████▋| 16340/16955 [01:01<00:02, 267.39it/s, loss=2.394, v_num=946a]\n",
      "Epoch 6:  97%|█████████▋| 16435/16955 [01:01<00:01, 268.45it/s, loss=2.394, v_num=946a]\n",
      "Epoch 6:  97%|█████████▋| 16530/16955 [01:01<00:01, 269.50it/s, loss=2.394, v_num=946a]\n",
      "Epoch 6:  98%|█████████▊| 16625/16955 [01:01<00:01, 270.51it/s, loss=2.394, v_num=946a]\n",
      "Validating:  94%|█████████▎| 4765/5087 [00:07<00:00, 804.00it/s]\u001b[A\n",
      "Epoch 6:  99%|█████████▊| 16720/16955 [01:01<00:00, 271.52it/s, loss=2.394, v_num=946a]\n",
      "Epoch 6:  99%|█████████▉| 16815/16955 [01:01<00:00, 272.54it/s, loss=2.394, v_num=946a]\n",
      "Epoch 6: 100%|█████████▉| 16910/16955 [01:01<00:00, 273.55it/s, loss=2.394, v_num=946a]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: avg_val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 16955/16955 [01:02<00:00, 272.92it/s, loss=2.394, v_num=946a]\n",
      "Epoch 6: 100%|██████████| 16955/16955 [01:02<00:00, 269.88it/s, loss=2.394, v_num=946a]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Starting saving the offline archive\n",
      "COMET INFO: To upload this offline experiment, run:\n",
      "    comet upload logs/2708165c013247eb966a30532e4d946a.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 24s, sys: 1min 15s, total: 8min 40s\n",
      "Wall time: 7min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EarlyStopping mode set to min for monitoring avg_val_loss.\n",
      "INFO:lightning:EarlyStopping mode set to min for monitoring avg_val_loss.\n"
     ]
    }
   ],
   "source": [
    "age_model = Model.load_from_checkpoint(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, hparams=hparams, \\\n",
    "                                   checkpoint_path=\"./checkpoints/model-outputs-v7.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (net): Net(\n",
       "    (fc1): Linear(in_features=768, out_features=128, bias=True)\n",
       "    (fc2): Linear(in_features=128, out_features=26, bias=True)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "    (loss_func): CrossEntropyLoss()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4239/4239 [00:04<00:00, 1021.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.076     0.194     0.109      2607\n",
      "           1      0.125     0.383     0.189      5456\n",
      "           2      0.128     0.051     0.073      8314\n",
      "           3      0.178     0.079     0.109     14492\n",
      "           4      0.227     0.190     0.207     16107\n",
      "           5      0.166     0.053     0.080     14493\n",
      "           6      0.172     0.075     0.105     15959\n",
      "           7      0.141     0.075     0.098     13348\n",
      "           8      0.183     0.006     0.012     11014\n",
      "           9      0.104     0.028     0.045      9180\n",
      "          10      0.061     0.040     0.049      3498\n",
      "          11      0.241     0.167     0.198      4258\n",
      "          12      0.075     0.065     0.069      3481\n",
      "          13      0.057     0.051     0.054      2835\n",
      "          14      0.070     0.138     0.093      1853\n",
      "          15      0.034     0.143     0.054      1484\n",
      "          16      0.022     0.179     0.039      1092\n",
      "          17      0.101     0.300     0.151      1001\n",
      "          18      0.020     0.209     0.036       741\n",
      "          19      0.041     0.271     0.072       580\n",
      "          20      0.048     0.209     0.078       841\n",
      "          21      0.018     0.211     0.034       407\n",
      "          22      0.037     0.159     0.061       894\n",
      "          23      0.041     0.258     0.070       546\n",
      "          24      0.036     0.319     0.065       439\n",
      "          25      0.068     0.370     0.115       713\n",
      "\n",
      "    accuracy                          0.103    135633\n",
      "   macro avg      0.095     0.162     0.087    135633\n",
      "weighted avg      0.150     0.103     0.101    135633\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = age_model.predict_eval(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Averaged weighted F-1 Score equals 10.3% which is considerably better than for random model, still not satisfactory. But again, predicting text author's age is extremely complex task. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we remember, numerous records have not specified the topic. We probably not interested in predicting unknown industry. So I remove records with no topic specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_df = df2[df2.topic != 'indUnk'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(428278, 10)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again classes mapping and samples split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_class2idx = {k: v for v, k in enumerate(sorted(topic_df['topic'].unique()))}\n",
    "topic_idx2class = {v: k for k, v in topic_class2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accounting': 0,\n",
       " 'Advertising': 1,\n",
       " 'Agriculture': 2,\n",
       " 'Architecture': 3,\n",
       " 'Arts': 4,\n",
       " 'Automotive': 5,\n",
       " 'Banking': 6,\n",
       " 'Biotech': 7,\n",
       " 'BusinessServices': 8,\n",
       " 'Chemicals': 9,\n",
       " 'Communications-Media': 10,\n",
       " 'Construction': 11,\n",
       " 'Consulting': 12,\n",
       " 'Education': 13,\n",
       " 'Engineering': 14,\n",
       " 'Environment': 15,\n",
       " 'Fashion': 16,\n",
       " 'Government': 17,\n",
       " 'HumanResources': 18,\n",
       " 'Internet': 19,\n",
       " 'InvestmentBanking': 20,\n",
       " 'Law': 21,\n",
       " 'LawEnforcement-Security': 22,\n",
       " 'Manufacturing': 23,\n",
       " 'Maritime': 24,\n",
       " 'Marketing': 25,\n",
       " 'Military': 26,\n",
       " 'Museums-Libraries': 27,\n",
       " 'Non-Profit': 28,\n",
       " 'Publishing': 29,\n",
       " 'RealEstate': 30,\n",
       " 'Religion': 31,\n",
       " 'Science': 32,\n",
       " 'Sports-Recreation': 33,\n",
       " 'Student': 34,\n",
       " 'Technology': 35,\n",
       " 'Telecommunications': 36,\n",
       " 'Tourism': 37,\n",
       " 'Transportation': 38}"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_class2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_df['topic'] = topic_df['topic'].map(topic_class2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = topic_df['vectors'].values\n",
    "y = topic_df['topic'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=17)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.3, stratify=y_trainval, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_list = torch.tensor(y_train)\n",
    "class_count = [i for i in get_class_distribution('topic').values()]\n",
    "class_weights = 1./torch.tensor(class_count, dtype=torch.float) \n",
    "class_weights_all = class_weights[target_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'fast_dev_run': True,\n",
    "    'pin_memory': True,\n",
    "    'device': device,\n",
    "    'num_workers': 12,\n",
    "    'shuffle': False,\n",
    "    'batch_size': 32,\n",
    "    'logger': comet_logger,\n",
    "    'weights': class_weights_all\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EarlyStopping mode set to min for monitoring avg_val_loss.\n"
     ]
    }
   ],
   "source": [
    "model = Model(X_train, y_train, X_val, y_val, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Running in fast_dev_run mode: will run a full train, val and test loop using a single batch\n",
      "\n",
      "  | Name | Type | Params\n",
      "------------------------------\n",
      "0 | net  | Net  | 103 K \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|█████     | 1/2 [00:03<00:03,  3.06s/it, loss=3.662, v_num=f3df]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating: 100%|██████████| 1/1 [00:01<00:00,  1.45s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: avg_val_loss reached 3.65514 (best 3.65514), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v8.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 2/2 [00:04<00:00,  2.38s/it, loss=3.662, v_num=f3df]\n",
      "Epoch 0: 100%|██████████| 2/2 [00:05<00:00,  2.51s/it, loss=3.662, v_num=f3df]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Starting saving the offline archive\n",
      "COMET INFO: To upload this offline experiment, run:\n",
      "    comet upload logs/21c5c34b8e1a449aa163461147b0f3df.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.57 s, sys: 3.3 s, total: 5.87 s\n",
      "Wall time: 6.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'pin_memory': True,\n",
    "    'device': device,\n",
    "    'num_workers': 12,\n",
    "    'logger': comet_logger,\n",
    "    'max_epochs': 30,\n",
    "    'lr': 1e-3,\n",
    "    'num_warmup_steps': 2000,\n",
    "    'dropout': 0.2,\n",
    "    'weights': class_weights_all\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EarlyStopping mode set to min for monitoring avg_val_loss.\n"
     ]
    }
   ],
   "source": [
    "model = Model(X_train, y_train, X_val, y_val, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (net): Net(\n",
       "    (fc1): Linear(in_features=768, out_features=128, bias=True)\n",
       "    (fc2): Linear(in_features=128, out_features=39, bias=True)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "    (loss_func): CrossEntropyLoss()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2677/2677 [00:02<00:00, 950.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000       764\n",
      "           1      0.012     0.005     0.008       931\n",
      "           2      0.003     0.024     0.005       246\n",
      "           3      0.003     0.040     0.006       325\n",
      "           4      0.070     0.353     0.117      6460\n",
      "           5      0.000     0.000     0.000       248\n",
      "           6      0.000     0.000     0.000       807\n",
      "           7      0.000     0.000     0.000       446\n",
      "           8      0.005     0.003     0.004       895\n",
      "           9      0.000     0.000     0.000       782\n",
      "          10      0.066     0.010     0.018      4003\n",
      "          11      0.000     0.000     0.000       218\n",
      "          12      0.000     0.000     0.000      1169\n",
      "          13      0.058     0.015     0.024      5917\n",
      "          14      0.000     0.000     0.000      2304\n",
      "          15      0.000     0.000     0.000       117\n",
      "          16      0.012     0.005     0.007       967\n",
      "          17      0.029     0.001     0.001      1368\n",
      "          18      0.018     0.005     0.008       601\n",
      "          19      0.000     0.000     0.000      3186\n",
      "          20      0.000     0.000     0.000       256\n",
      "          21      0.000     0.000     0.000      1792\n",
      "          22      0.003     0.048     0.006       373\n",
      "          23      0.000     0.000     0.000       441\n",
      "          24      0.001     0.145     0.002        55\n",
      "          25      0.010     0.100     0.018       942\n",
      "          26      0.004     0.011     0.006       621\n",
      "          27      0.006     0.044     0.010       618\n",
      "          28      0.032     0.002     0.003      2926\n",
      "          29      0.000     0.000     0.000      1542\n",
      "          30      0.000     0.000     0.000       573\n",
      "          31      0.010     0.001     0.002      1042\n",
      "          32      0.020     0.001     0.001      1443\n",
      "          33      0.009     0.023     0.013       604\n",
      "          34      0.377     0.057     0.098     30676\n",
      "          35      0.123     0.010     0.019      8372\n",
      "          36      0.008     0.032     0.013       775\n",
      "          37      0.000     0.000     0.000       387\n",
      "          38      0.007     0.017     0.010       464\n",
      "\n",
      "    accuracy                          0.052     85656\n",
      "   macro avg      0.023     0.024     0.010     85656\n",
      "weighted avg      0.162     0.052     0.049     85656\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/payonear/Cases_recruit/netguru-case/netguru-env/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict_eval(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type | Params\n",
      "------------------------------\n",
      "0 | net  | Net  | 103 K \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  70%|██████▉   | 7495/10708 [00:34<00:14, 216.55it/s, loss=3.265, v_num=f535]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  70%|███████   | 7520/10708 [00:36<00:15, 208.28it/s, loss=3.265, v_num=f535]\n",
      "Epoch 0:  71%|███████   | 7611/10708 [00:36<00:14, 210.22it/s, loss=3.265, v_num=f535]\n",
      "Epoch 0:  72%|███████▏  | 7702/10708 [00:36<00:14, 212.05it/s, loss=3.265, v_num=f535]\n",
      "Epoch 0:  73%|███████▎  | 7793/10708 [00:36<00:13, 213.93it/s, loss=3.265, v_num=f535]\n",
      "Epoch 0:  74%|███████▎  | 7884/10708 [00:36<00:13, 215.78it/s, loss=3.265, v_num=f535]\n",
      "Validating:  12%|█▏        | 392/3213 [00:01<11:18,  4.16it/s]\u001b[A\n",
      "Epoch 0:  74%|███████▍  | 7975/10708 [00:36<00:12, 217.59it/s, loss=3.265, v_num=f535]\n",
      "Epoch 0:  75%|███████▌  | 8066/10708 [00:36<00:12, 219.40it/s, loss=3.265, v_num=f535]\n",
      "Epoch 0:  76%|███████▌  | 8157/10708 [00:36<00:11, 221.22it/s, loss=3.265, v_num=f535]\n",
      "Epoch 0:  77%|███████▋  | 8248/10708 [00:36<00:11, 223.00it/s, loss=3.265, v_num=f535]\n",
      "Epoch 0:  78%|███████▊  | 8339/10708 [00:37<00:10, 224.79it/s, loss=3.265, v_num=f535]\n",
      "Epoch 0:  79%|███████▊  | 8430/10708 [00:37<00:10, 226.59it/s, loss=3.265, v_num=f535]\n",
      "Epoch 0:  80%|███████▉  | 8521/10708 [00:37<00:09, 228.37it/s, loss=3.265, v_num=f535]\n",
      "Epoch 0:  80%|████████  | 8612/10708 [00:37<00:09, 230.12it/s, loss=3.265, v_num=f535]\n",
      "Epoch 0:  81%|████████▏ | 8703/10708 [00:37<00:08, 231.88it/s, loss=3.265, v_num=f535]\n",
      "Epoch 0:  82%|████████▏ | 8794/10708 [00:37<00:08, 233.59it/s, loss=3.265, v_num=f535]\n",
      "Epoch 0:  83%|████████▎ | 8885/10708 [00:37<00:07, 235.34it/s, loss=3.265, v_num=f535]\n",
      "Validating:  43%|████▎     | 1390/3213 [00:03<00:08, 221.07it/s]\u001b[A\n",
      "Epoch 0:  84%|████████▍ | 8976/10708 [00:37<00:07, 237.06it/s, loss=3.265, v_num=f535]\n",
      "Epoch 0:  85%|████████▍ | 9067/10708 [00:37<00:06, 238.79it/s, loss=3.265, v_num=f535]\n",
      "Epoch 0:  86%|████████▌ | 9158/10708 [00:38<00:06, 240.49it/s, loss=3.265, v_num=f535]\n",
      "Epoch 0:  86%|████████▋ | 9249/10708 [00:38<00:06, 242.15it/s, loss=3.265, v_num=f535]\n",
      "Epoch 0:  87%|████████▋ | 9340/10708 [00:38<00:05, 243.83it/s, loss=3.265, v_num=f535]\n",
      "Epoch 0:  88%|████████▊ | 9431/10708 [00:38<00:05, 245.51it/s, loss=3.265, v_num=f535]\n",
      "Epoch 0:  89%|████████▉ | 9522/10708 [00:38<00:04, 247.18it/s, loss=3.265, v_num=f535]\n",
      "Epoch 0:  90%|████████▉ | 9613/10708 [00:38<00:04, 248.80it/s, loss=3.265, v_num=f535]\n",
      "Epoch 0:  91%|█████████ | 9704/10708 [00:38<00:04, 250.47it/s, loss=3.265, v_num=f535]\n",
      "Epoch 0:  91%|█████████▏| 9795/10708 [00:38<00:03, 252.09it/s, loss=3.265, v_num=f535]\n",
      "Epoch 0:  92%|█████████▏| 9886/10708 [00:38<00:03, 253.70it/s, loss=3.265, v_num=f535]\n",
      "Epoch 0:  93%|█████████▎| 9977/10708 [00:39<00:02, 255.33it/s, loss=3.265, v_num=f535]\n",
      "Validating:  77%|███████▋  | 2484/3213 [00:04<00:00, 804.11it/s]\u001b[A\n",
      "Epoch 0:  94%|█████████▍| 10068/10708 [00:39<00:02, 256.94it/s, loss=3.265, v_num=f535]\n",
      "Epoch 0:  95%|█████████▍| 10159/10708 [00:39<00:02, 258.54it/s, loss=3.265, v_num=f535]\n",
      "Epoch 0:  96%|█████████▌| 10250/10708 [00:39<00:01, 260.17it/s, loss=3.265, v_num=f535]\n",
      "Epoch 0:  97%|█████████▋| 10341/10708 [00:39<00:01, 261.78it/s, loss=3.265, v_num=f535]\n",
      "Epoch 0:  97%|█████████▋| 10432/10708 [00:39<00:01, 263.36it/s, loss=3.265, v_num=f535]\n",
      "Epoch 0:  98%|█████████▊| 10523/10708 [00:39<00:00, 264.92it/s, loss=3.265, v_num=f535]\n",
      "Epoch 0:  99%|█████████▉| 10614/10708 [00:39<00:00, 266.47it/s, loss=3.265, v_num=f535]\n",
      "Epoch 0: 100%|█████████▉| 10705/10708 [00:39<00:00, 268.03it/s, loss=3.265, v_num=f535]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: avg_val_loss reached 3.43985 (best 3.43985), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v9.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 10708/10708 [00:40<00:00, 266.58it/s, loss=3.265, v_num=f535]\n",
      "Epoch 1:  70%|██████▉   | 7495/10708 [00:34<00:14, 214.71it/s, loss=3.047, v_num=f535] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1:  71%|███████   | 7553/10708 [00:36<00:15, 206.66it/s, loss=3.047, v_num=f535]\n",
      "Validating:   2%|▏         | 63/3213 [00:01<56:52,  1.08s/it] \u001b[A\n",
      "Epoch 1:  71%|███████▏  | 7644/10708 [00:36<00:14, 208.45it/s, loss=3.047, v_num=f535]\n",
      "Epoch 1:  72%|███████▏  | 7735/10708 [00:36<00:14, 210.27it/s, loss=3.047, v_num=f535]\n",
      "Epoch 1:  73%|███████▎  | 7826/10708 [00:36<00:13, 212.08it/s, loss=3.047, v_num=f535]\n",
      "Epoch 1:  74%|███████▍  | 7917/10708 [00:37<00:13, 213.93it/s, loss=3.047, v_num=f535]\n",
      "Epoch 1:  75%|███████▍  | 8008/10708 [00:37<00:12, 215.77it/s, loss=3.047, v_num=f535]\n",
      "Epoch 1:  76%|███████▌  | 8099/10708 [00:37<00:11, 217.59it/s, loss=3.047, v_num=f535]\n",
      "Epoch 1:  76%|███████▋  | 8190/10708 [00:37<00:11, 219.40it/s, loss=3.047, v_num=f535]\n",
      "Epoch 1:  77%|███████▋  | 8281/10708 [00:37<00:10, 221.19it/s, loss=3.047, v_num=f535]\n",
      "Epoch 1:  78%|███████▊  | 8372/10708 [00:37<00:10, 222.99it/s, loss=3.047, v_num=f535]\n",
      "Epoch 1:  79%|███████▉  | 8463/10708 [00:37<00:09, 224.76it/s, loss=3.047, v_num=f535]\n",
      "Validating:  30%|███       | 974/3213 [00:02<00:50, 44.26it/s]\u001b[A\n",
      "Epoch 1:  80%|███████▉  | 8554/10708 [00:37<00:09, 226.50it/s, loss=3.047, v_num=f535]\n",
      "Epoch 1:  81%|████████  | 8645/10708 [00:37<00:09, 228.27it/s, loss=3.047, v_num=f535]\n",
      "Epoch 1:  82%|████████▏ | 8736/10708 [00:37<00:08, 229.99it/s, loss=3.047, v_num=f535]\n",
      "Epoch 1:  82%|████████▏ | 8827/10708 [00:38<00:08, 231.74it/s, loss=3.047, v_num=f535]\n",
      "Epoch 1:  83%|████████▎ | 8918/10708 [00:38<00:07, 233.46it/s, loss=3.047, v_num=f535]\n",
      "Epoch 1:  84%|████████▍ | 9009/10708 [00:38<00:07, 235.17it/s, loss=3.047, v_num=f535]\n",
      "Epoch 1:  85%|████████▍ | 9100/10708 [00:38<00:06, 236.89it/s, loss=3.047, v_num=f535]\n",
      "Epoch 1:  86%|████████▌ | 9191/10708 [00:38<00:06, 238.58it/s, loss=3.047, v_num=f535]\n",
      "Epoch 1:  87%|████████▋ | 9282/10708 [00:38<00:05, 240.30it/s, loss=3.047, v_num=f535]\n",
      "Epoch 1:  88%|████████▊ | 9373/10708 [00:38<00:05, 241.95it/s, loss=3.047, v_num=f535]\n",
      "Epoch 1:  88%|████████▊ | 9464/10708 [00:38<00:05, 243.63it/s, loss=3.047, v_num=f535]\n",
      "Epoch 1:  89%|████████▉ | 9555/10708 [00:38<00:04, 245.30it/s, loss=3.047, v_num=f535]\n",
      "Epoch 1:  90%|█████████ | 9646/10708 [00:39<00:04, 246.96it/s, loss=3.047, v_num=f535]\n",
      "Epoch 1:  91%|█████████ | 9737/10708 [00:39<00:03, 248.62it/s, loss=3.047, v_num=f535]\n",
      "Epoch 1:  92%|█████████▏| 9828/10708 [00:39<00:03, 250.24it/s, loss=3.047, v_num=f535]\n",
      "Epoch 1:  93%|█████████▎| 9919/10708 [00:39<00:03, 251.89it/s, loss=3.047, v_num=f535]\n",
      "Validating:  76%|███████▌  | 2427/3213 [00:04<00:00, 814.89it/s]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 10010/10708 [00:39<00:02, 253.49it/s, loss=3.047, v_num=f535]\n",
      "Epoch 1:  94%|█████████▍| 10101/10708 [00:39<00:02, 255.08it/s, loss=3.047, v_num=f535]\n",
      "Epoch 1:  95%|█████████▌| 10192/10708 [00:39<00:02, 256.65it/s, loss=3.047, v_num=f535]\n",
      "Epoch 1:  96%|█████████▌| 10283/10708 [00:39<00:01, 258.24it/s, loss=3.047, v_num=f535]\n",
      "Epoch 1:  97%|█████████▋| 10374/10708 [00:39<00:01, 259.83it/s, loss=3.047, v_num=f535]\n",
      "Epoch 1:  98%|█████████▊| 10465/10708 [00:40<00:00, 261.41it/s, loss=3.047, v_num=f535]\n",
      "Epoch 1:  99%|█████████▊| 10556/10708 [00:40<00:00, 262.98it/s, loss=3.047, v_num=f535]\n",
      "Epoch 1:  99%|█████████▉| 10647/10708 [00:40<00:00, 264.56it/s, loss=3.047, v_num=f535]\n",
      "Validating: 100%|█████████▉| 3200/3213 [00:05<00:00, 855.71it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: avg_val_loss reached 3.42638 (best 3.42638), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v10.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 10708/10708 [00:40<00:00, 264.08it/s, loss=3.047, v_num=f535]\n",
      "Epoch 2:  70%|██████▉   | 7495/10708 [00:35<00:15, 212.34it/s, loss=3.026, v_num=f535] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2:  71%|███████   | 7553/10708 [00:36<00:15, 206.46it/s, loss=3.026, v_num=f535]\n",
      "Epoch 2:  71%|███████▏  | 7644/10708 [00:36<00:14, 208.32it/s, loss=3.026, v_num=f535]\n",
      "Validating:   5%|▍         | 153/3213 [00:01<30:01,  1.70it/s]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 7735/10708 [00:36<00:14, 210.17it/s, loss=3.026, v_num=f535]\n",
      "Epoch 2:  73%|███████▎  | 7826/10708 [00:36<00:13, 212.02it/s, loss=3.026, v_num=f535]\n",
      "Epoch 2:  74%|███████▍  | 7917/10708 [00:37<00:13, 213.83it/s, loss=3.026, v_num=f535]\n",
      "Epoch 2:  75%|███████▍  | 8008/10708 [00:37<00:12, 215.65it/s, loss=3.026, v_num=f535]\n",
      "Epoch 2:  76%|███████▌  | 8099/10708 [00:37<00:11, 217.48it/s, loss=3.026, v_num=f535]\n",
      "Epoch 2:  76%|███████▋  | 8190/10708 [00:37<00:11, 219.31it/s, loss=3.026, v_num=f535]\n",
      "Epoch 2:  77%|███████▋  | 8281/10708 [00:37<00:10, 221.12it/s, loss=3.026, v_num=f535]\n",
      "Epoch 2:  78%|███████▊  | 8372/10708 [00:37<00:10, 222.91it/s, loss=3.026, v_num=f535]\n",
      "Epoch 2:  79%|███████▉  | 8463/10708 [00:37<00:09, 224.69it/s, loss=3.026, v_num=f535]\n",
      "Epoch 2:  80%|███████▉  | 8554/10708 [00:37<00:09, 226.46it/s, loss=3.026, v_num=f535]\n",
      "Epoch 2:  81%|████████  | 8645/10708 [00:37<00:09, 228.19it/s, loss=3.026, v_num=f535]\n",
      "Epoch 2:  82%|████████▏ | 8736/10708 [00:37<00:08, 229.92it/s, loss=3.026, v_num=f535]\n",
      "Epoch 2:  82%|████████▏ | 8827/10708 [00:38<00:08, 231.65it/s, loss=3.026, v_num=f535]\n",
      "Validating:  42%|████▏     | 1339/3213 [00:02<00:09, 192.65it/s]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 8918/10708 [00:38<00:07, 233.34it/s, loss=3.026, v_num=f535]\n",
      "Epoch 2:  84%|████████▍ | 9009/10708 [00:38<00:07, 235.02it/s, loss=3.026, v_num=f535]\n",
      "Epoch 2:  85%|████████▍ | 9100/10708 [00:38<00:06, 236.69it/s, loss=3.026, v_num=f535]\n",
      "Epoch 2:  86%|████████▌ | 9191/10708 [00:38<00:06, 238.36it/s, loss=3.026, v_num=f535]\n",
      "Epoch 2:  87%|████████▋ | 9282/10708 [00:38<00:05, 240.03it/s, loss=3.026, v_num=f535]\n",
      "Epoch 2:  88%|████████▊ | 9373/10708 [00:38<00:05, 241.70it/s, loss=3.026, v_num=f535]\n",
      "Epoch 2:  88%|████████▊ | 9464/10708 [00:38<00:05, 243.33it/s, loss=3.026, v_num=f535]\n",
      "Epoch 2:  89%|████████▉ | 9555/10708 [00:39<00:04, 244.95it/s, loss=3.026, v_num=f535]\n",
      "Epoch 2:  90%|█████████ | 9646/10708 [00:39<00:04, 246.58it/s, loss=3.026, v_num=f535]\n",
      "Epoch 2:  91%|█████████ | 9737/10708 [00:39<00:03, 248.19it/s, loss=3.026, v_num=f535]\n",
      "Validating:  70%|██████▉   | 2243/3213 [00:03<00:01, 758.34it/s]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 9828/10708 [00:39<00:03, 249.79it/s, loss=3.026, v_num=f535]\n",
      "Epoch 2:  93%|█████████▎| 9919/10708 [00:39<00:03, 251.36it/s, loss=3.026, v_num=f535]\n",
      "Epoch 2:  93%|█████████▎| 10010/10708 [00:39<00:02, 252.93it/s, loss=3.026, v_num=f535]\n",
      "Epoch 2:  94%|█████████▍| 10101/10708 [00:39<00:02, 254.51it/s, loss=3.026, v_num=f535]\n",
      "Epoch 2:  95%|█████████▌| 10192/10708 [00:39<00:02, 256.07it/s, loss=3.026, v_num=f535]\n",
      "Epoch 2:  96%|█████████▌| 10283/10708 [00:39<00:01, 257.63it/s, loss=3.026, v_num=f535]\n",
      "Epoch 2:  97%|█████████▋| 10374/10708 [00:40<00:01, 259.20it/s, loss=3.026, v_num=f535]\n",
      "Epoch 2:  98%|█████████▊| 10465/10708 [00:40<00:00, 260.74it/s, loss=3.026, v_num=f535]\n",
      "Epoch 2:  99%|█████████▊| 10556/10708 [00:40<00:00, 262.32it/s, loss=3.026, v_num=f535]\n",
      "Validating:  95%|█████████▌| 3067/3213 [00:04<00:00, 824.08it/s]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 10647/10708 [00:40<00:00, 263.84it/s, loss=3.026, v_num=f535]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: avg_val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 10708/10708 [00:40<00:00, 263.30it/s, loss=3.026, v_num=f535]\n",
      "Epoch 3:  70%|██████▉   | 7495/10708 [00:35<00:15, 214.08it/s, loss=2.819, v_num=f535] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 3:  71%|███████   | 7553/10708 [00:36<00:15, 207.09it/s, loss=2.819, v_num=f535]\n",
      "Validating:   2%|▏         | 62/3213 [00:01<50:14,  1.05it/s] \u001b[A\n",
      "Epoch 3:  71%|███████▏  | 7644/10708 [00:36<00:14, 208.88it/s, loss=2.819, v_num=f535]\n",
      "Epoch 3:  72%|███████▏  | 7735/10708 [00:36<00:14, 210.71it/s, loss=2.819, v_num=f535]\n",
      "Epoch 3:  73%|███████▎  | 7826/10708 [00:36<00:13, 212.54it/s, loss=2.819, v_num=f535]\n",
      "Epoch 3:  74%|███████▍  | 7917/10708 [00:36<00:13, 214.36it/s, loss=2.819, v_num=f535]\n",
      "Epoch 3:  75%|███████▍  | 8008/10708 [00:37<00:12, 216.17it/s, loss=2.819, v_num=f535]\n",
      "Epoch 3:  76%|███████▌  | 8099/10708 [00:37<00:11, 217.98it/s, loss=2.819, v_num=f535]\n",
      "Epoch 3:  76%|███████▋  | 8190/10708 [00:37<00:11, 219.79it/s, loss=2.819, v_num=f535]\n",
      "Epoch 3:  77%|███████▋  | 8281/10708 [00:37<00:10, 221.58it/s, loss=2.819, v_num=f535]\n",
      "Epoch 3:  78%|███████▊  | 8372/10708 [00:37<00:10, 223.34it/s, loss=2.819, v_num=f535]\n",
      "Validating:  27%|██▋       | 877/3213 [00:02<01:05, 35.45it/s]\u001b[A\n",
      "Epoch 3:  79%|███████▉  | 8463/10708 [00:37<00:09, 225.07it/s, loss=2.819, v_num=f535]\n",
      "Epoch 3:  80%|███████▉  | 8554/10708 [00:37<00:09, 226.80it/s, loss=2.819, v_num=f535]\n",
      "Epoch 3:  81%|████████  | 8645/10708 [00:37<00:09, 228.52it/s, loss=2.819, v_num=f535]\n",
      "Epoch 3:  82%|████████▏ | 8736/10708 [00:37<00:08, 230.26it/s, loss=2.819, v_num=f535]\n",
      "Epoch 3:  82%|████████▏ | 8827/10708 [00:38<00:08, 231.99it/s, loss=2.819, v_num=f535]\n",
      "Epoch 3:  83%|████████▎ | 8918/10708 [00:38<00:07, 233.72it/s, loss=2.819, v_num=f535]\n",
      "Epoch 3:  84%|████████▍ | 9009/10708 [00:38<00:07, 235.42it/s, loss=2.819, v_num=f535]\n",
      "Epoch 3:  85%|████████▍ | 9100/10708 [00:38<00:06, 237.12it/s, loss=2.819, v_num=f535]\n",
      "Epoch 3:  86%|████████▌ | 9191/10708 [00:38<00:06, 238.81it/s, loss=2.819, v_num=f535]\n",
      "Validating:  53%|█████▎    | 1703/3213 [00:03<00:02, 506.90it/s]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 9282/10708 [00:38<00:05, 240.42it/s, loss=2.819, v_num=f535]\n",
      "Epoch 3:  88%|████████▊ | 9373/10708 [00:38<00:05, 242.05it/s, loss=2.819, v_num=f535]\n",
      "Epoch 3:  88%|████████▊ | 9464/10708 [00:38<00:05, 243.69it/s, loss=2.819, v_num=f535]\n",
      "Epoch 3:  89%|████████▉ | 9555/10708 [00:38<00:04, 245.31it/s, loss=2.819, v_num=f535]\n",
      "Epoch 3:  90%|█████████ | 9646/10708 [00:39<00:04, 246.92it/s, loss=2.819, v_num=f535]\n",
      "Epoch 3:  91%|█████████ | 9737/10708 [00:39<00:03, 248.50it/s, loss=2.819, v_num=f535]\n",
      "Epoch 3:  92%|█████████▏| 9828/10708 [00:39<00:03, 250.08it/s, loss=2.819, v_num=f535]\n",
      "Epoch 3:  93%|█████████▎| 9919/10708 [00:39<00:03, 251.66it/s, loss=2.819, v_num=f535]\n",
      "Epoch 3:  93%|█████████▎| 10010/10708 [00:39<00:02, 253.27it/s, loss=2.819, v_num=f535]\n",
      "Validating:  78%|███████▊  | 2516/3213 [00:04<00:00, 788.22it/s]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 10101/10708 [00:39<00:02, 254.88it/s, loss=2.819, v_num=f535]\n",
      "Epoch 3:  95%|█████████▌| 10192/10708 [00:39<00:02, 256.47it/s, loss=2.819, v_num=f535]\n",
      "Epoch 3:  96%|█████████▌| 10283/10708 [00:39<00:01, 258.08it/s, loss=2.819, v_num=f535]\n",
      "Epoch 3:  97%|█████████▋| 10374/10708 [00:39<00:01, 259.66it/s, loss=2.819, v_num=f535]\n",
      "Epoch 3:  98%|█████████▊| 10465/10708 [00:40<00:00, 261.24it/s, loss=2.819, v_num=f535]\n",
      "Epoch 3:  99%|█████████▊| 10556/10708 [00:40<00:00, 262.80it/s, loss=2.819, v_num=f535]\n",
      "Epoch 3:  99%|█████████▉| 10647/10708 [00:40<00:00, 264.35it/s, loss=2.819, v_num=f535]\n",
      "Validating: 100%|█████████▉| 3200/3213 [00:05<00:00, 838.34it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: avg_val_loss reached 3.39029 (best 3.39029), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v9.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 10708/10708 [00:40<00:00, 263.78it/s, loss=2.819, v_num=f535]\n",
      "Epoch 4:  70%|██████▉   | 7495/10708 [00:35<00:15, 213.46it/s, loss=2.766, v_num=f535] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 4:  71%|███████   | 7553/10708 [00:36<00:15, 206.20it/s, loss=2.766, v_num=f535]\n",
      "Validating:   2%|▏         | 62/3213 [00:01<52:18,  1.00it/s] \u001b[A\n",
      "Epoch 4:  71%|███████▏  | 7644/10708 [00:36<00:14, 208.01it/s, loss=2.766, v_num=f535]\n",
      "Epoch 4:  72%|███████▏  | 7735/10708 [00:36<00:14, 209.86it/s, loss=2.766, v_num=f535]\n",
      "Epoch 4:  73%|███████▎  | 7826/10708 [00:36<00:13, 211.70it/s, loss=2.766, v_num=f535]\n",
      "Epoch 4:  74%|███████▍  | 7917/10708 [00:37<00:13, 213.54it/s, loss=2.766, v_num=f535]\n",
      "Epoch 4:  75%|███████▍  | 8008/10708 [00:37<00:12, 215.36it/s, loss=2.766, v_num=f535]\n",
      "Epoch 4:  76%|███████▌  | 8099/10708 [00:37<00:12, 217.17it/s, loss=2.766, v_num=f535]\n",
      "Epoch 4:  76%|███████▋  | 8190/10708 [00:37<00:11, 218.92it/s, loss=2.766, v_num=f535]\n",
      "Epoch 4:  77%|███████▋  | 8281/10708 [00:37<00:10, 220.67it/s, loss=2.766, v_num=f535]\n",
      "Epoch 4:  78%|███████▊  | 8372/10708 [00:37<00:10, 222.42it/s, loss=2.766, v_num=f535]\n",
      "Validating:  27%|██▋       | 879/3213 [00:02<01:08, 34.07it/s]\u001b[A\n",
      "Epoch 4:  79%|███████▉  | 8463/10708 [00:37<00:10, 224.15it/s, loss=2.766, v_num=f535]\n",
      "Epoch 4:  80%|███████▉  | 8554/10708 [00:37<00:09, 225.85it/s, loss=2.766, v_num=f535]\n",
      "Epoch 4:  81%|████████  | 8645/10708 [00:37<00:09, 227.56it/s, loss=2.766, v_num=f535]\n",
      "Epoch 4:  82%|████████▏ | 8736/10708 [00:38<00:08, 229.28it/s, loss=2.766, v_num=f535]\n",
      "Epoch 4:  82%|████████▏ | 8827/10708 [00:38<00:08, 230.94it/s, loss=2.766, v_num=f535]\n",
      "Epoch 4:  83%|████████▎ | 8918/10708 [00:38<00:07, 232.61it/s, loss=2.766, v_num=f535]\n",
      "Epoch 4:  84%|████████▍ | 9009/10708 [00:38<00:07, 234.28it/s, loss=2.766, v_num=f535]\n",
      "Validating:  47%|████▋     | 1521/3213 [00:03<00:04, 344.96it/s]\u001b[A\n",
      "Epoch 4:  85%|████████▍ | 9100/10708 [00:38<00:06, 235.94it/s, loss=2.766, v_num=f535]\n",
      "Epoch 4:  86%|████████▌ | 9191/10708 [00:38<00:06, 237.63it/s, loss=2.766, v_num=f535]\n",
      "Epoch 4:  87%|████████▋ | 9282/10708 [00:38<00:05, 239.29it/s, loss=2.766, v_num=f535]\n",
      "Epoch 4:  88%|████████▊ | 9373/10708 [00:38<00:05, 240.93it/s, loss=2.766, v_num=f535]\n",
      "Epoch 4:  88%|████████▊ | 9464/10708 [00:39<00:05, 242.59it/s, loss=2.766, v_num=f535]\n",
      "Epoch 4:  89%|████████▉ | 9555/10708 [00:39<00:04, 244.20it/s, loss=2.766, v_num=f535]\n",
      "Epoch 4:  90%|█████████ | 9646/10708 [00:39<00:04, 245.81it/s, loss=2.766, v_num=f535]\n",
      "Epoch 4:  91%|█████████ | 9737/10708 [00:39<00:03, 247.43it/s, loss=2.766, v_num=f535]\n",
      "Epoch 4:  92%|█████████▏| 9828/10708 [00:39<00:03, 249.06it/s, loss=2.766, v_num=f535]\n",
      "Epoch 4:  93%|█████████▎| 9919/10708 [00:39<00:03, 250.62it/s, loss=2.766, v_num=f535]\n",
      "Validating:  76%|███████▌  | 2429/3213 [00:04<00:01, 779.62it/s]\u001b[A\n",
      "Epoch 4:  93%|█████████▎| 10010/10708 [00:39<00:02, 252.12it/s, loss=2.766, v_num=f535]\n",
      "Epoch 4:  94%|█████████▍| 10101/10708 [00:39<00:02, 253.71it/s, loss=2.766, v_num=f535]\n",
      "Epoch 4:  95%|█████████▌| 10192/10708 [00:39<00:02, 255.29it/s, loss=2.766, v_num=f535]\n",
      "Epoch 4:  96%|█████████▌| 10283/10708 [00:40<00:01, 256.85it/s, loss=2.766, v_num=f535]\n",
      "Epoch 4:  97%|█████████▋| 10374/10708 [00:40<00:01, 258.41it/s, loss=2.766, v_num=f535]\n",
      "Epoch 4:  98%|█████████▊| 10465/10708 [00:40<00:00, 259.97it/s, loss=2.766, v_num=f535]\n",
      "Epoch 4:  99%|█████████▊| 10556/10708 [00:40<00:00, 261.53it/s, loss=2.766, v_num=f535]\n",
      "Epoch 4:  99%|█████████▉| 10647/10708 [00:40<00:00, 263.05it/s, loss=2.766, v_num=f535]\n",
      "Validating:  99%|█████████▉| 3175/3213 [00:05<00:00, 810.58it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: avg_val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 10708/10708 [00:40<00:00, 262.53it/s, loss=2.766, v_num=f535]\n",
      "Epoch 5:  70%|██████▉   | 7495/10708 [00:35<00:15, 213.64it/s, loss=2.812, v_num=f535] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 5:  71%|███████   | 7553/10708 [00:36<00:15, 207.02it/s, loss=2.812, v_num=f535]\n",
      "Validating:   2%|▏         | 61/3213 [00:01<48:00,  1.09it/s] \u001b[A\n",
      "Epoch 5:  71%|███████▏  | 7644/10708 [00:36<00:14, 208.84it/s, loss=2.812, v_num=f535]\n",
      "Epoch 5:  72%|███████▏  | 7735/10708 [00:36<00:14, 210.67it/s, loss=2.812, v_num=f535]\n",
      "Epoch 5:  73%|███████▎  | 7826/10708 [00:36<00:13, 212.47it/s, loss=2.812, v_num=f535]\n",
      "Epoch 5:  74%|███████▍  | 7917/10708 [00:36<00:13, 214.30it/s, loss=2.812, v_num=f535]\n",
      "Epoch 5:  75%|███████▍  | 8008/10708 [00:37<00:12, 216.09it/s, loss=2.812, v_num=f535]\n",
      "Epoch 5:  76%|███████▌  | 8099/10708 [00:37<00:11, 217.92it/s, loss=2.812, v_num=f535]\n",
      "Epoch 5:  76%|███████▋  | 8190/10708 [00:37<00:11, 219.73it/s, loss=2.812, v_num=f535]\n",
      "Epoch 5:  77%|███████▋  | 8281/10708 [00:37<00:10, 221.45it/s, loss=2.812, v_num=f535]\n",
      "Validating:  24%|██▍       | 787/3213 [00:02<01:32, 26.25it/s]\u001b[A\n",
      "Epoch 5:  78%|███████▊  | 8372/10708 [00:37<00:10, 223.18it/s, loss=2.812, v_num=f535]\n",
      "Epoch 5:  79%|███████▉  | 8463/10708 [00:37<00:09, 224.94it/s, loss=2.812, v_num=f535]\n",
      "Epoch 5:  80%|███████▉  | 8554/10708 [00:37<00:09, 226.68it/s, loss=2.812, v_num=f535]\n",
      "Epoch 5:  81%|████████  | 8645/10708 [00:37<00:09, 228.41it/s, loss=2.812, v_num=f535]\n",
      "Epoch 5:  82%|████████▏ | 8736/10708 [00:37<00:08, 230.14it/s, loss=2.812, v_num=f535]\n",
      "Epoch 5:  82%|████████▏ | 8827/10708 [00:38<00:08, 231.85it/s, loss=2.812, v_num=f535]\n",
      "Epoch 5:  83%|████████▎ | 8918/10708 [00:38<00:07, 233.58it/s, loss=2.812, v_num=f535]\n",
      "Epoch 5:  84%|████████▍ | 9009/10708 [00:38<00:07, 235.27it/s, loss=2.812, v_num=f535]\n",
      "Epoch 5:  85%|████████▍ | 9100/10708 [00:38<00:06, 236.99it/s, loss=2.812, v_num=f535]\n",
      "Epoch 5:  86%|████████▌ | 9191/10708 [00:38<00:06, 238.68it/s, loss=2.812, v_num=f535]\n",
      "Validating:  53%|█████▎    | 1696/3213 [00:03<00:02, 517.69it/s]\u001b[A\n",
      "Epoch 5:  87%|████████▋ | 9282/10708 [00:38<00:05, 240.37it/s, loss=2.812, v_num=f535]\n",
      "Epoch 5:  88%|████████▊ | 9373/10708 [00:38<00:05, 242.03it/s, loss=2.812, v_num=f535]\n",
      "Epoch 5:  88%|████████▊ | 9464/10708 [00:38<00:05, 243.69it/s, loss=2.812, v_num=f535]\n",
      "Epoch 5:  89%|████████▉ | 9555/10708 [00:38<00:04, 245.34it/s, loss=2.812, v_num=f535]\n",
      "Epoch 5:  90%|█████████ | 9646/10708 [00:39<00:04, 246.96it/s, loss=2.812, v_num=f535]\n",
      "Epoch 5:  91%|█████████ | 9737/10708 [00:39<00:03, 248.57it/s, loss=2.812, v_num=f535]\n",
      "Epoch 5:  92%|█████████▏| 9828/10708 [00:39<00:03, 250.19it/s, loss=2.812, v_num=f535]\n",
      "Epoch 5:  93%|█████████▎| 9919/10708 [00:39<00:03, 251.74it/s, loss=2.812, v_num=f535]\n",
      "Epoch 5:  93%|█████████▎| 10010/10708 [00:39<00:02, 253.30it/s, loss=2.812, v_num=f535]\n",
      "Epoch 5:  94%|█████████▍| 10101/10708 [00:39<00:02, 254.90it/s, loss=2.812, v_num=f535]\n",
      "Validating:  81%|████████▏ | 2614/3213 [00:04<00:00, 794.62it/s]\u001b[A\n",
      "Epoch 5:  95%|█████████▌| 10192/10708 [00:39<00:02, 256.45it/s, loss=2.812, v_num=f535]\n",
      "Epoch 5:  96%|█████████▌| 10283/10708 [00:39<00:01, 258.03it/s, loss=2.812, v_num=f535]\n",
      "Epoch 5:  97%|█████████▋| 10374/10708 [00:39<00:01, 259.62it/s, loss=2.812, v_num=f535]\n",
      "Epoch 5:  98%|█████████▊| 10465/10708 [00:40<00:00, 261.21it/s, loss=2.812, v_num=f535]\n",
      "Epoch 5:  99%|█████████▊| 10556/10708 [00:40<00:00, 262.74it/s, loss=2.812, v_num=f535]\n",
      "Epoch 5:  99%|█████████▉| 10647/10708 [00:40<00:00, 264.26it/s, loss=2.812, v_num=f535]\n",
      "Validating: 100%|█████████▉| 3202/3213 [00:05<00:00, 814.84it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: avg_val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 10708/10708 [00:40<00:00, 263.69it/s, loss=2.812, v_num=f535]\n",
      "Epoch 6:  70%|██████▉   | 7495/10708 [00:35<00:15, 212.51it/s, loss=2.765, v_num=f535] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 1/3213 [00:01<1:19:41,  1.49s/it]\u001b[A\n",
      "Epoch 6:  71%|███████   | 7553/10708 [00:36<00:15, 204.86it/s, loss=2.765, v_num=f535]\n",
      "Epoch 6:  71%|███████▏  | 7644/10708 [00:36<00:14, 206.68it/s, loss=2.765, v_num=f535]\n",
      "Epoch 6:  72%|███████▏  | 7735/10708 [00:37<00:14, 208.53it/s, loss=2.765, v_num=f535]\n",
      "Epoch 6:  73%|███████▎  | 7826/10708 [00:37<00:13, 210.37it/s, loss=2.765, v_num=f535]\n",
      "Epoch 6:  74%|███████▍  | 7917/10708 [00:37<00:13, 212.19it/s, loss=2.765, v_num=f535]\n",
      "Epoch 6:  75%|███████▍  | 8008/10708 [00:37<00:12, 214.00it/s, loss=2.765, v_num=f535]\n",
      "Epoch 6:  76%|███████▌  | 8099/10708 [00:37<00:12, 215.76it/s, loss=2.765, v_num=f535]\n",
      "Epoch 6:  76%|███████▋  | 8190/10708 [00:37<00:11, 217.51it/s, loss=2.765, v_num=f535]\n",
      "Validating:  22%|██▏       | 704/3213 [00:02<02:33, 16.32it/s]\u001b[A\n",
      "Epoch 6:  77%|███████▋  | 8281/10708 [00:37<00:11, 219.24it/s, loss=2.765, v_num=f535]\n",
      "Epoch 6:  78%|███████▊  | 8372/10708 [00:37<00:10, 221.00it/s, loss=2.765, v_num=f535]\n",
      "Epoch 6:  79%|███████▉  | 8463/10708 [00:37<00:10, 222.73it/s, loss=2.765, v_num=f535]\n",
      "Epoch 6:  80%|███████▉  | 8554/10708 [00:38<00:09, 224.44it/s, loss=2.765, v_num=f535]\n",
      "Epoch 6:  81%|████████  | 8645/10708 [00:38<00:09, 226.18it/s, loss=2.765, v_num=f535]\n",
      "Epoch 6:  82%|████████▏ | 8736/10708 [00:38<00:08, 227.90it/s, loss=2.765, v_num=f535]\n",
      "Epoch 6:  82%|████████▏ | 8827/10708 [00:38<00:08, 229.60it/s, loss=2.765, v_num=f535]\n",
      "Epoch 6:  83%|████████▎ | 8918/10708 [00:38<00:07, 231.28it/s, loss=2.765, v_num=f535]\n",
      "Epoch 6:  84%|████████▍ | 9009/10708 [00:38<00:07, 232.95it/s, loss=2.765, v_num=f535]\n",
      "Validating:  47%|████▋     | 1520/3213 [00:03<00:04, 338.90it/s]\u001b[A\n",
      "Epoch 6:  85%|████████▍ | 9100/10708 [00:38<00:06, 234.55it/s, loss=2.765, v_num=f535]\n",
      "Epoch 6:  86%|████████▌ | 9191/10708 [00:38<00:06, 236.18it/s, loss=2.765, v_num=f535]\n",
      "Epoch 6:  87%|████████▋ | 9282/10708 [00:39<00:05, 237.85it/s, loss=2.765, v_num=f535]\n",
      "Epoch 6:  88%|████████▊ | 9373/10708 [00:39<00:05, 239.51it/s, loss=2.765, v_num=f535]\n",
      "Epoch 6:  88%|████████▊ | 9464/10708 [00:39<00:05, 241.16it/s, loss=2.765, v_num=f535]\n",
      "Epoch 6:  89%|████████▉ | 9555/10708 [00:39<00:04, 242.79it/s, loss=2.765, v_num=f535]\n",
      "Epoch 6:  90%|█████████ | 9646/10708 [00:39<00:04, 244.41it/s, loss=2.765, v_num=f535]\n",
      "Epoch 6:  91%|█████████ | 9737/10708 [00:39<00:03, 245.98it/s, loss=2.765, v_num=f535]\n",
      "Epoch 6:  92%|█████████▏| 9828/10708 [00:39<00:03, 247.58it/s, loss=2.765, v_num=f535]\n",
      "Epoch 6:  93%|█████████▎| 9919/10708 [00:39<00:03, 249.20it/s, loss=2.765, v_num=f535]\n",
      "Validating:  75%|███████▌  | 2425/3213 [00:04<00:00, 793.95it/s]\u001b[A\n",
      "Epoch 6:  93%|█████████▎| 10010/10708 [00:39<00:02, 250.79it/s, loss=2.765, v_num=f535]\n",
      "Epoch 6:  94%|█████████▍| 10101/10708 [00:40<00:02, 252.38it/s, loss=2.765, v_num=f535]\n",
      "Epoch 6:  95%|█████████▌| 10192/10708 [00:40<00:02, 253.91it/s, loss=2.765, v_num=f535]\n",
      "Epoch 6:  96%|█████████▌| 10283/10708 [00:40<00:01, 255.47it/s, loss=2.765, v_num=f535]\n",
      "Epoch 6:  97%|█████████▋| 10374/10708 [00:40<00:01, 257.00it/s, loss=2.765, v_num=f535]\n",
      "Epoch 6:  98%|█████████▊| 10465/10708 [00:40<00:00, 258.51it/s, loss=2.765, v_num=f535]\n",
      "Epoch 6:  99%|█████████▊| 10556/10708 [00:40<00:00, 260.04it/s, loss=2.765, v_num=f535]\n",
      "Epoch 6:  99%|█████████▉| 10647/10708 [00:40<00:00, 261.53it/s, loss=2.765, v_num=f535]\n",
      "Validating:  99%|█████████▊| 3167/3213 [00:05<00:00, 789.38it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: avg_val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 10708/10708 [00:41<00:00, 261.04it/s, loss=2.765, v_num=f535]\n",
      "Epoch 6: 100%|██████████| 10708/10708 [00:41<00:00, 258.14it/s, loss=2.765, v_num=f535]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Starting saving the offline archive\n",
      "COMET INFO: To upload this offline experiment, run:\n",
      "    comet upload logs/5f40e3d743a7484ebcfac4921f45f535.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 41s, sys: 56.4 s, total: 5min 37s\n",
      "Wall time: 4min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EarlyStopping mode set to min for monitoring avg_val_loss.\n",
      "INFO:lightning:EarlyStopping mode set to min for monitoring avg_val_loss.\n"
     ]
    }
   ],
   "source": [
    "topic_model = Model.load_from_checkpoint(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, hparams=hparams, \\\n",
    "                                   checkpoint_path=\"./checkpoints/model-outputs-v9.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (net): Net(\n",
       "    (fc1): Linear(in_features=768, out_features=128, bias=True)\n",
       "    (fc2): Linear(in_features=128, out_features=39, bias=True)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "    (loss_func): CrossEntropyLoss()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2677/2677 [00:02<00:00, 1004.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.067     0.141     0.091       764\n",
      "           1      0.028     0.070     0.040       931\n",
      "           2      0.007     0.118     0.014       246\n",
      "           3      0.028     0.243     0.050       325\n",
      "           4      0.126     0.005     0.010      6460\n",
      "           5      0.009     0.177     0.018       248\n",
      "           6      0.042     0.089     0.057       807\n",
      "           7      0.022     0.177     0.039       446\n",
      "           8      0.098     0.111     0.104       895\n",
      "           9      0.046     0.072     0.056       782\n",
      "          10      0.073     0.013     0.022      4003\n",
      "          11      0.017     0.138     0.030       218\n",
      "          12      0.034     0.022     0.027      1169\n",
      "          13      0.249     0.010     0.020      5917\n",
      "          14      0.091     0.020     0.033      2304\n",
      "          15      0.009     0.077     0.016       117\n",
      "          16      0.051     0.146     0.076       967\n",
      "          17      0.029     0.012     0.017      1368\n",
      "          18      0.036     0.070     0.048       601\n",
      "          19      0.151     0.044     0.068      3186\n",
      "          20      0.011     0.141     0.021       256\n",
      "          21      0.125     0.107     0.115      1792\n",
      "          22      0.013     0.129     0.023       373\n",
      "          23      0.017     0.104     0.029       441\n",
      "          24      0.004     0.036     0.007        55\n",
      "          25      0.023     0.042     0.030       942\n",
      "          26      0.023     0.101     0.038       621\n",
      "          27      0.061     0.225     0.096       618\n",
      "          28      0.084     0.013     0.023      2926\n",
      "          29      0.080     0.196     0.113      1542\n",
      "          30      0.020     0.136     0.035       573\n",
      "          31      0.063     0.270     0.102      1042\n",
      "          32      0.047     0.031     0.037      1443\n",
      "          33      0.015     0.180     0.027       604\n",
      "          34      0.615     0.081     0.144     30676\n",
      "          35      0.292     0.011     0.021      8372\n",
      "          36      0.071     0.110     0.086       775\n",
      "          37      0.012     0.147     0.021       387\n",
      "          38      0.049     0.209     0.079       464\n",
      "\n",
      "    accuracy                          0.064     85656\n",
      "   macro avg      0.073     0.103     0.048     85656\n",
      "weighted avg      0.303     0.064     0.076     85656\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pred = topic_model.predict_eval(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model has learnt a bit. Not much better than random model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and alternative approaches\n",
    "\n",
    "So, in this notebook we built 4 models, predicting gender, zodiac sign, age and industry of post's author. For the first model we found out that text semantic allows us identify the gender of the author with accuray in 65% (F1-score - 65%). In case of age, zodiac sign and industry prediction tasks the models were not so successful. Why were we able to predict gender, but experienced hard time predicting all the other classes. So, imagine you have a task, the same as the model, you want to identify who wrote the post. Let's see an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"                 hey every one! like my new page? awsome eh? so any way i have soooooooooooooomuch to say! ok! #1 i broke up with my best friend but for some odd reason we are better friends than before! #2 next week monday is grad and my dress is amazing . #3 on june 15 its my birthday and thats only 6 days away!yippee! #4 i am going with my class to algonquin park on my birthday!:( #5 i ordered a great corsage for grad and its pink roses with black ribbon to match my dress #6 i am going to a class party at alyssa's house and (lane and caitlin don't tell sarah):) sarah isn't coming so i get to hang out with caitlin the whole time and see the guys in bathing suits thats alll bye!        \""
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.gender == 'female'].iloc[231834].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, trying to not look at the answer try to predict what is the gender of the author. You probably will succeed in this one, as there are some obvious patterns. Let's see what our model predicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = preprocess(df[df.gender == 'female'].iloc[231834].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = torch.Tensor(st.encode(text)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_gender = gender_model.eval()(vector)[0].cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.90481406, 0.09518593], dtype=float32)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'female'"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_idx2class[predicted_gender.argmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model confidentaly predicts `female`, which is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'female'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.gender == 'female'].iloc[231834].gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try to predict the age or zodiac sign. You probaly will not pick up correct zodiac sign, but for the age you'll guess probably that this woman is rather young. Model thinks so as well, predicting age 14. And it's wrong in both cases. True age is 27 and sign is Virgo. But the task is really challenging and probably it's impossible to predict accurate age and zodiac sign. What we can do is to look at probability distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_sign = sign_model.eval()(vector)[0].cpu().detach().numpy().argmax()\n",
    "predicted_age = age_model.eval()(vector)[0].cpu().detach().numpy().argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libra 14\n"
     ]
    }
   ],
   "source": [
    "print(sign_idx2class[predicted_sign], age_idx2class[predicted_age])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sign    Virgo\n",
       "age        27\n",
       "Name: 485088, dtype: object"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.gender == 'female'].iloc[231834][['sign', 'age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_sign = sign_model.eval()(vector)[0].cpu().detach().numpy()\n",
    "predicted_age = age_model.eval()(vector)[0].cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(13, 0.09437068),\n",
       " (14, 0.21328478),\n",
       " (15, 0.12863785),\n",
       " (16, 0.15329292),\n",
       " (17, 0.15337548),\n",
       " (23, 0.056838296),\n",
       " (24, 0.03767414),\n",
       " (25, 0.056725144),\n",
       " (26, 0.024052203),\n",
       " (27, 0.029786255),\n",
       " (33, 0.01419571),\n",
       " (34, 0.0047723195),\n",
       " (35, 0.005985534),\n",
       " (36, 0.010998002),\n",
       " (37, 0.003112552),\n",
       " (38, 0.0029899282),\n",
       " (39, 0.0024896355),\n",
       " (40, 0.0028890413),\n",
       " (41, 0.0027690053),\n",
       " (42, 0.0001380087),\n",
       " (43, 6.026105e-05),\n",
       " (44, 1.3888938e-07),\n",
       " (45, 5.4783766e-05),\n",
       " (46, 0.0015011466),\n",
       " (47, 1.1774153e-07),\n",
       " (48, 6.1246774e-06)]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(age_idx2class[i], p) for i, p in enumerate(predicted_age)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about industry. Let's check smth we can predict ourselves. So, below's text most probably was written by some person who works in Technology. And that's intuitive. Model fails predicting topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"           I didn't have much to say today.  Sorry, friends.         \""
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.gender == 'male'].iloc[3761].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'indUnk'"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.gender == 'male'].iloc[3561].topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = preprocess(df[df.gender == 'male'].iloc[3561].text)\n",
    "vector = torch.Tensor(st.encode(text)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"urllink      *looks at the current world's population* you must have a lot of frustration then.       urllink  what pisses you off?     created by  urllink ptocheia\""
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LawEnforcement-Security'"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_topic = topic_model.eval()(vector)[0].cpu().detach().numpy()\n",
    "topic_idx2class[predicted_topic.argmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the probability distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Accounting', 0.0006344702),\n",
       " ('Advertising', 0.06908908),\n",
       " ('Agriculture', 0.0035132733),\n",
       " ('Architecture', 0.004737135),\n",
       " ('Arts', 0.021759262),\n",
       " ('Automotive', 3.2274029e-06),\n",
       " ('Banking', 0.0032650155),\n",
       " ('Biotech', 0.00025785534),\n",
       " ('BusinessServices', 0.0013621093),\n",
       " ('Chemicals', 0.0060384157),\n",
       " ('Communications-Media', 0.014075405),\n",
       " ('Construction', 7.8638965e-05),\n",
       " ('Consulting', 0.007511453),\n",
       " ('Education', 0.02473506),\n",
       " ('Engineering', 0.013310639),\n",
       " ('Environment', 2.919822e-10),\n",
       " ('Fashion', 0.0068733795),\n",
       " ('Government', 0.024206908),\n",
       " ('HumanResources', 0.0045313393),\n",
       " ('Internet', 0.019448742),\n",
       " ('InvestmentBanking', 2.857006e-06),\n",
       " ('Law', 0.029692285),\n",
       " ('LawEnforcement-Security', 0.34076357),\n",
       " ('Manufacturing', 0.053050335),\n",
       " ('Maritime', 0.047695607),\n",
       " ('Marketing', 0.043120157),\n",
       " ('Military', 0.0012988782),\n",
       " ('Museums-Libraries', 0.0017344335),\n",
       " ('Non-Profit', 0.012616176),\n",
       " ('Publishing', 0.007515926),\n",
       " ('RealEstate', 0.013460796),\n",
       " ('Religion', 0.031857736),\n",
       " ('Science', 0.02934149),\n",
       " ('Sports-Recreation', 0.105270565),\n",
       " ('Student', 0.024406394),\n",
       " ('Technology', 0.015164982),\n",
       " ('Telecommunications', 0.014697475),\n",
       " ('Tourism', 0.00021636029),\n",
       " ('Transportation', 0.0026625302)]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(topic_idx2class[i], p) for i, p in enumerate(predicted_topic)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "netguru-env",
   "language": "python",
   "name": "netguru-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
