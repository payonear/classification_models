{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this notebook we'll try to solve quite a challenging task. Using Blog Authorship Corpus which consists of the collected posts of 19,320 bloggers we'll try using solely text of this posts predict the gender, age, zodiac sign and industry of post author. For this I propose to use SentenceTransformers embeddings generated by Siamese BERT-Networks and classifier which is a small Neural Network with two linear layers. Starting with gender prediction model, which I consider the easiest one due to it's binary nature and nice almost ideal balance of classes, I'll proceed to more complex models trying to solve multiclass prediction problems for balanced and non-balanced classes. To speed up computation I'll use GPU, but if GPU is not available on your machine it will automatically compute everything on CPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content\n",
    "\n",
    "1. [EDA](#EDA)\n",
    "2. [Gender model](#Gender-model)\n",
    "3. [Sign mdoel](#Sign-model)\n",
    "4. [Age model](#Age-model)\n",
    "5. [Topic model](#Topic-model)\n",
    "6. [Summary and alternative approaches](#Summary-and-alternative-approaches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "comet_ml is installed but `COMET_API_KEY` is not set.\n"
     ]
    }
   ],
   "source": [
    "from model import Model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "pd.options.mode.chained_assignment = None\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define device (GPU if available, othervise CPU) and logger for Pytorch Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CometLogger will be initialized in offline mode\n"
     ]
    }
   ],
   "source": [
    "comet_logger = pl_loggers.CometLogger(save_dir='logs/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>14,May,2004</td>\n",
       "      <td>Info has been found (+/- 100 pages,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>13,May,2004</td>\n",
       "      <td>These are the team members:   Drewe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>In het kader van kernfusie op aarde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>testing!!!  testing!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>11,June,2004</td>\n",
       "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id gender  age              topic      sign          date  \\\n",
       "0  2059027   male   15            Student       Leo   14,May,2004   \n",
       "1  2059027   male   15            Student       Leo   13,May,2004   \n",
       "2  2059027   male   15            Student       Leo   12,May,2004   \n",
       "3  2059027   male   15            Student       Leo   12,May,2004   \n",
       "4  3581210   male   33  InvestmentBanking  Aquarius  11,June,2004   \n",
       "\n",
       "                                                text  \n",
       "0             Info has been found (+/- 100 pages,...  \n",
       "1             These are the team members:   Drewe...  \n",
       "2             In het kader van kernfusie op aarde...  \n",
       "3                   testing!!!  testing!!!            \n",
       "4               Thanks to Yahoo!'s Toolbar I can ...  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/blogtext.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA\n",
    "\n",
    "There are few important things to be noticed during Exploratory Data Analysis in this case. First of all gender and sign are well balanced (classes almost equally distributed). Conversely, age and topic are not-balanced. Text length rarely exceeds threshold of 512 words, which is a cut-off value for BERT. There are records with empty posts. Numerous records have no topic specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(681284, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id         int64\n",
       "gender    object\n",
       "age        int64\n",
       "topic     object\n",
       "sign      object\n",
       "date      object\n",
       "text      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id        0\n",
       "gender    0\n",
       "age       0\n",
       "topic     0\n",
       "sign      0\n",
       "date      0\n",
       "text      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id', 19320),\n",
       " ('gender', 2),\n",
       " ('age', 26),\n",
       " ('topic', 40),\n",
       " ('sign', 12),\n",
       " ('date', 2616),\n",
       " ('text', 611652)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(x, len(df[x].unique())) for x in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_len'] = df.text.apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize = (15, 6))\n",
    "sns.countplot(x = df.gender, ax = ax[0][0])\n",
    "sns.countplot(x = df.age, ax = ax[0][1])\n",
    "sns.countplot(x = df.sign, ax = ax[1][0])\n",
    "sns.distplot(a = df.text_len, ax = ax[1][1])\n",
    "ax[1][0].set_xticklabels(ax[1][0].get_xticklabels(), rotation = 90)\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    681284.000000\n",
       "mean        200.786742\n",
       "std         415.160622\n",
       "min           0.000000\n",
       "50%         112.000000\n",
       "85%         370.000000\n",
       "90%         470.000000\n",
       "95%         663.000000\n",
       "99%        1257.000000\n",
       "max      131169.000000\n",
       "Name: text_len, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text_len.describe([.85, .9, .95, .99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3119, 8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.text_len == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "indUnk                     251015\n",
       "Student                    153903\n",
       "Technology                  42055\n",
       "Arts                        32449\n",
       "Education                   29633\n",
       "Communications-Media        20140\n",
       "Internet                    16006\n",
       "Non-Profit                  14700\n",
       "Engineering                 11653\n",
       "Law                          9040\n",
       "Publishing                   7753\n",
       "Science                      7269\n",
       "Government                   6907\n",
       "Consulting                   5862\n",
       "Religion                     5235\n",
       "Fashion                      4851\n",
       "Marketing                    4769\n",
       "Advertising                  4676\n",
       "BusinessServices             4500\n",
       "Banking                      4049\n",
       "Chemicals                    3928\n",
       "Telecommunications           3891\n",
       "Accounting                   3832\n",
       "Military                     3128\n",
       "Museums-Libraries            3096\n",
       "Sports-Recreation            3038\n",
       "HumanResources               3010\n",
       "RealEstate                   2870\n",
       "Transportation               2326\n",
       "Manufacturing                2272\n",
       "Biotech                      2234\n",
       "Tourism                      1942\n",
       "LawEnforcement-Security      1878\n",
       "Architecture                 1638\n",
       "InvestmentBanking            1292\n",
       "Automotive                   1244\n",
       "Agriculture                  1235\n",
       "Construction                 1093\n",
       "Environment                   592\n",
       "Maritime                      280\n",
       "Name: topic, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.topic.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.groupby('age').text_len.mean().plot(kind = 'bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.groupby('sign').text_len.mean().plot(kind = 'bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's filter out empty posts. For good practices I create a copy of existent dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[df.text_len > 0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(678165, 8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fast preprocessing by lowercasing texts and removing redundant spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower().split()\n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.08 s, sys: 264 ms, total: 7.35 s\n",
      "Wall time: 7.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data['prepr_text'] = data.text.apply(lambda x: preprocess(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's encode sentences with SentenceTransformer. See doc [here](https://www.sbert.net/). It will take a while. On my machine it took slightly above 2 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = SentenceTransformer('roberta-base-nli-stsb-mean-tokens').eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2h 12min 38s, sys: 5.9 s, total: 2h 12min 43s\n",
      "Wall time: 2h 12min 49s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>text_len</th>\n",
       "      <th>prepr_text</th>\n",
       "      <th>vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>14,May,2004</td>\n",
       "      <td>Info has been found (+/- 100 pages,...</td>\n",
       "      <td>28</td>\n",
       "      <td>info has been found (+/- 100 pages, and 4.5 mb...</td>\n",
       "      <td>[-0.022713589, -0.03159448, -0.1542669, -0.791...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>13,May,2004</td>\n",
       "      <td>These are the team members:   Drewe...</td>\n",
       "      <td>20</td>\n",
       "      <td>these are the team members: drewes van der laa...</td>\n",
       "      <td>[0.42498702, -0.38697943, 0.45772505, 1.349861...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>In het kader van kernfusie op aarde...</td>\n",
       "      <td>4326</td>\n",
       "      <td>in het kader van kernfusie op aarde: maak je e...</td>\n",
       "      <td>[-0.10179597, -0.772578, -0.58268136, -0.31995...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>testing!!!  testing!!!</td>\n",
       "      <td>2</td>\n",
       "      <td>testing!!! testing!!!</td>\n",
       "      <td>[-0.1319768, -0.85336256, 0.3637177, 0.252747,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>11,June,2004</td>\n",
       "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
       "      <td>65</td>\n",
       "      <td>thanks to yahoo!'s toolbar i can now 'capture'...</td>\n",
       "      <td>[0.8307138, -0.21023807, -0.4450357, -0.637345...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id gender  age              topic      sign          date  \\\n",
       "0  2059027   male   15            Student       Leo   14,May,2004   \n",
       "1  2059027   male   15            Student       Leo   13,May,2004   \n",
       "2  2059027   male   15            Student       Leo   12,May,2004   \n",
       "3  2059027   male   15            Student       Leo   12,May,2004   \n",
       "4  3581210   male   33  InvestmentBanking  Aquarius  11,June,2004   \n",
       "\n",
       "                                                text  text_len  \\\n",
       "0             Info has been found (+/- 100 pages,...        28   \n",
       "1             These are the team members:   Drewe...        20   \n",
       "2             In het kader van kernfusie op aarde...      4326   \n",
       "3                   testing!!!  testing!!!                   2   \n",
       "4               Thanks to Yahoo!'s Toolbar I can ...        65   \n",
       "\n",
       "                                          prepr_text  \\\n",
       "0  info has been found (+/- 100 pages, and 4.5 mb...   \n",
       "1  these are the team members: drewes van der laa...   \n",
       "2  in het kader van kernfusie op aarde: maak je e...   \n",
       "3                              testing!!! testing!!!   \n",
       "4  thanks to yahoo!'s toolbar i can now 'capture'...   \n",
       "\n",
       "                                             vectors  \n",
       "0  [-0.022713589, -0.03159448, -0.1542669, -0.791...  \n",
       "1  [0.42498702, -0.38697943, 0.45772505, 1.349861...  \n",
       "2  [-0.10179597, -0.772578, -0.58268136, -0.31995...  \n",
       "3  [-0.1319768, -0.85336256, 0.3637177, 0.252747,...  \n",
       "4  [0.8307138, -0.21023807, -0.4450357, -0.637345...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "data['vectors'] = data.prepr_text.apply(lambda x: st.encode(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure it's still no missings in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          0\n",
       "gender      0\n",
       "age         0\n",
       "topic       0\n",
       "sign        0\n",
       "date        0\n",
       "text        0\n",
       "text_len    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving to pickle to not repeat sentences encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_pickle('./data/blogtext_vec.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>text_len</th>\n",
       "      <th>prepr_text</th>\n",
       "      <th>vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>14,May,2004</td>\n",
       "      <td>Info has been found (+/- 100 pages,...</td>\n",
       "      <td>28</td>\n",
       "      <td>info has been found (+/- 100 pages, and 4.5 mb...</td>\n",
       "      <td>[-0.022713589, -0.03159448, -0.1542669, -0.791...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>13,May,2004</td>\n",
       "      <td>These are the team members:   Drewe...</td>\n",
       "      <td>20</td>\n",
       "      <td>these are the team members: drewes van der laa...</td>\n",
       "      <td>[0.42498702, -0.38697943, 0.45772505, 1.349861...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>In het kader van kernfusie op aarde...</td>\n",
       "      <td>4326</td>\n",
       "      <td>in het kader van kernfusie op aarde: maak je e...</td>\n",
       "      <td>[-0.10179597, -0.772578, -0.58268136, -0.31995...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>testing!!!  testing!!!</td>\n",
       "      <td>2</td>\n",
       "      <td>testing!!! testing!!!</td>\n",
       "      <td>[-0.1319768, -0.85336256, 0.3637177, 0.252747,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>11,June,2004</td>\n",
       "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
       "      <td>65</td>\n",
       "      <td>thanks to yahoo!'s toolbar i can now 'capture'...</td>\n",
       "      <td>[0.8307138, -0.21023807, -0.4450357, -0.637345...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id gender  age              topic      sign          date  \\\n",
       "0  2059027   male   15            Student       Leo   14,May,2004   \n",
       "1  2059027   male   15            Student       Leo   13,May,2004   \n",
       "2  2059027   male   15            Student       Leo   12,May,2004   \n",
       "3  2059027   male   15            Student       Leo   12,May,2004   \n",
       "4  3581210   male   33  InvestmentBanking  Aquarius  11,June,2004   \n",
       "\n",
       "                                                text  text_len  \\\n",
       "0             Info has been found (+/- 100 pages,...        28   \n",
       "1             These are the team members:   Drewe...        20   \n",
       "2             In het kader van kernfusie op aarde...      4326   \n",
       "3                   testing!!!  testing!!!                   2   \n",
       "4               Thanks to Yahoo!'s Toolbar I can ...        65   \n",
       "\n",
       "                                          prepr_text  \\\n",
       "0  info has been found (+/- 100 pages, and 4.5 mb...   \n",
       "1  these are the team members: drewes van der laa...   \n",
       "2  in het kader van kernfusie op aarde: maak je e...   \n",
       "3                              testing!!! testing!!!   \n",
       "4  thanks to yahoo!'s toolbar i can now 'capture'...   \n",
       "\n",
       "                                             vectors  \n",
       "0  [-0.022713589, -0.03159448, -0.1542669, -0.791...  \n",
       "1  [0.42498702, -0.38697943, 0.45772505, 1.349861...  \n",
       "2  [-0.10179597, -0.772578, -0.58268136, -0.31995...  \n",
       "3  [-0.1319768, -0.85336256, 0.3637177, 0.252747,...  \n",
       "4  [0.8307138, -0.21023807, -0.4450357, -0.637345...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_pickle('./data/blogtext_vec.pkl')\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gender model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert gender labels to format acceptable by Neural Net we should map it to labels 0 and 1 for `female` and `male` respectively. We create dictionary to map gender values to labels and inverse dictionary to be able to identify which value predicted by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_class2idx = {k: v for v, k in enumerate(sorted(df2['gender'].unique()))}\n",
    "gender_idx2class = {v: k for k, v in gender_class2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'female': 0, 'male': 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_class2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['gender'] = df2['gender'].map(gender_class2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.506509\n",
       "0    0.493491\n",
       "Name: gender, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.gender.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we perform split on train, validation and test samples. I do this with two steps, firstly separating test sample, then spliting train and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2['vectors'].values\n",
    "y = df2['gender'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=17)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.3, stratify=y_trainval, random_state=43)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen stratified split resulted in almost identical share of classes throughout all three samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49349083 0.50650917]\n",
      "[0.49348734 0.50651266]\n",
      "[0.49349347 0.50650653]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y_train, return_counts=True)[1]/len(y_train))\n",
    "print(np.unique(y_val, return_counts=True)[1]/len(y_val))\n",
    "print(np.unique(y_test, return_counts=True)[1]/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379772 162760 135633\n"
     ]
    }
   ],
   "source": [
    "print(X_train.size, X_val.size, X_test.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first run is simple sanity check. We just want to make sure, that there is no serious bug in the code of model implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'fast_dev_run': True,\n",
    "    'pin_memory': True,\n",
    "    'device': device,\n",
    "    'num_workers': 12,\n",
    "    'shuffle': False,\n",
    "    'batch_size': 32,\n",
    "    'logger': comet_logger\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EarlyStopping mode set to min for monitoring avg_val_loss.\n",
      "INFO:lightning:EarlyStopping mode set to min for monitoring avg_val_loss.\n"
     ]
    }
   ],
   "source": [
    "model = Model(X_train, y_train, X_val, y_val, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "INFO:lightning:GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "INFO:lightning:TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:lightning:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Running in fast_dev_run mode: will run a full train, val and test loop using a single batch\n",
      "INFO:lightning:Running in fast_dev_run mode: will run a full train, val and test loop using a single batch\n",
      "\n",
      "  | Name | Type | Params\n",
      "------------------------------\n",
      "0 | net  | Net  | 98.7 K\n",
      "INFO:lightning:\n",
      "  | Name | Type | Params\n",
      "------------------------------\n",
      "0 | net  | Net  | 98.7 K\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|█████     | 1/2 [00:01<00:01,  1.99s/it, loss=0.701, v_num=ecee]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating: 100%|██████████| 1/1 [00:02<00:00,  2.40s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: avg_val_loss reached 0.71426 (best 0.71426), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs.ckpt as top 1\n",
      "INFO:lightning:Epoch 0: avg_val_loss reached 0.71426 (best 0.71426), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 2/2 [00:04<00:00,  2.37s/it, loss=0.701, v_num=ecee]\n",
      "Epoch 0: 100%|██████████| 2/2 [00:05<00:00,  2.54s/it, loss=0.701, v_num=ecee]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: ----------------------------------\n",
      "COMET INFO: Comet.ml OfflineExperiment Summary\n",
      "COMET INFO: ----------------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : [OfflineExperiment will get URL after upload]\n",
      "COMET INFO:   Metrics:\n",
      "COMET INFO:     avg_train_loss : 0.7012262940406799\n",
      "COMET INFO:     avg_val_loss   : 0.7142595052719116\n",
      "COMET INFO:   Others:\n",
      "COMET INFO:     offline_experiment : True\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     batch_size   : 32\n",
      "COMET INFO:     device       : cuda\n",
      "COMET INFO:     fast_dev_run : True\n",
      "COMET INFO:     logger       : <pytorch_lightning.loggers.comet.CometLogger object at 0x7ff01ffc18d0>\n",
      "COMET INFO:     num_workers  : 12\n",
      "COMET INFO:     pin_memory   : True\n",
      "COMET INFO:     shuffle      : 1\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     code                     : 1 (3 KB)\n",
      "COMET INFO:     environment details      : 1\n",
      "COMET INFO:     filename                 : 1\n",
      "COMET INFO:     git metadata             : 1\n",
      "COMET INFO:     git-patch (uncompressed) : 1 (25 KB)\n",
      "COMET INFO:     installed packages       : 1\n",
      "COMET INFO:     notebook                 : 1\n",
      "COMET INFO:     os packages              : 1\n",
      "COMET INFO: ----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Saving offline stats to disk before program termination (may take several seconds)\n",
      "COMET INFO: Starting saving the offline archive\n",
      "COMET INFO: To upload this offline experiment, run:\n",
      "    comet upload logs/38319611f8f046819643125fefeeecee.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 128 ms, sys: 4.56 s, total: 4.68 s\n",
      "Wall time: 5.58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check went well. Then to make sure NN is learning I try to overfit on small subsaple. And as can be seen below, model does it successfuly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'overfit_batches': 1e-3,\n",
    "    'num_warmup_steps': 0,\n",
    "    'pin_memory': True,\n",
    "    'device': device,\n",
    "    'num_workers': 12,\n",
    "    'max_epochs': 40,\n",
    "    'lr': 1e-3,\n",
    "    'logger': comet_logger,\n",
    "    'shuffle': False # it's important not to shuffle training samples\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EarlyStopping mode set to min for monitoring avg_val_loss.\n",
      "INFO:lightning:EarlyStopping mode set to min for monitoring avg_val_loss.\n"
     ]
    }
   ],
   "source": [
    "model = Model(X_train, y_train, X_val, y_val, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "INFO:lightning:GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "INFO:lightning:TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:lightning:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type | Params\n",
      "------------------------------\n",
      "0 | net  | Net  | 98.7 K\n",
      "INFO:lightning:\n",
      "  | Name | Type | Params\n",
      "------------------------------\n",
      "0 | net  | Net  | 98.7 K\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|█████     | 11/22 [00:02<00:02,  4.09it/s, loss=0.712, v_num=d0c3]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  59%|█████▉    | 13/22 [00:05<00:03,  2.43it/s, loss=0.712, v_num=d0c3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: avg_val_loss reached 0.62183 (best 0.62183), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v0.ckpt as top 1\n",
      "INFO:lightning:Epoch 0: avg_val_loss reached 0.62183 (best 0.62183), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v0.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 22/22 [00:05<00:00,  3.82it/s, loss=0.712, v_num=d0c3]\n",
      "Epoch 1:  55%|█████▍    | 12/22 [00:02<00:01,  5.11it/s, loss=0.649, v_num=d0c3]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:02<00:25,  2.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: avg_val_loss reached 0.55029 (best 0.55029), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v1.ckpt as top 1\n",
      "INFO:lightning:Epoch 1: avg_val_loss reached 0.55029 (best 0.55029), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v1.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 22/22 [00:05<00:00,  4.13it/s, loss=0.649, v_num=d0c3]\n",
      "Epoch 2:  55%|█████▍    | 12/22 [00:02<00:02,  4.93it/s, loss=0.563, v_num=d0c3]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:02<00:26,  2.60s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: avg_val_loss reached 0.46864 (best 0.46864), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v0.ckpt as top 1\n",
      "INFO:lightning:Epoch 2: avg_val_loss reached 0.46864 (best 0.46864), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v0.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 22/22 [00:05<00:00,  4.03it/s, loss=0.563, v_num=d0c3]\n",
      "Epoch 3:  55%|█████▍    | 12/22 [00:02<00:01,  5.88it/s, loss=0.483, v_num=d0c3]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:02<00:23,  2.35s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: avg_val_loss reached 0.38164 (best 0.38164), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v1.ckpt as top 1\n",
      "INFO:lightning:Epoch 3: avg_val_loss reached 0.38164 (best 0.38164), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v1.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 22/22 [00:04<00:00,  4.57it/s, loss=0.483, v_num=d0c3]\n",
      "Epoch 4:  55%|█████▍    | 12/22 [00:02<00:02,  4.95it/s, loss=0.394, v_num=d0c3]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:02<00:24,  2.47s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: avg_val_loss reached 0.29319 (best 0.29319), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v0.ckpt as top 1\n",
      "INFO:lightning:Epoch 4: avg_val_loss reached 0.29319 (best 0.29319), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v0.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 22/22 [00:05<00:00,  4.15it/s, loss=0.394, v_num=d0c3]\n",
      "Epoch 5:  55%|█████▍    | 12/22 [00:02<00:01,  5.40it/s, loss=0.307, v_num=d0c3]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:02<00:22,  2.26s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: avg_val_loss reached 0.21598 (best 0.21598), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v1.ckpt as top 1\n",
      "INFO:lightning:Epoch 5: avg_val_loss reached 0.21598 (best 0.21598), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v1.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 22/22 [00:04<00:00,  4.50it/s, loss=0.307, v_num=d0c3]\n",
      "Epoch 6:  55%|█████▍    | 12/22 [00:02<00:02,  4.43it/s, loss=0.228, v_num=d0c3]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:02<00:25,  2.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: avg_val_loss reached 0.15859 (best 0.15859), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v0.ckpt as top 1\n",
      "INFO:lightning:Epoch 6: avg_val_loss reached 0.15859 (best 0.15859), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v0.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 22/22 [00:05<00:00,  3.91it/s, loss=0.228, v_num=d0c3]\n",
      "Epoch 7:  55%|█████▍    | 12/22 [00:02<00:01,  5.06it/s, loss=0.164, v_num=d0c3]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:02<00:22,  2.27s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: avg_val_loss reached 0.11616 (best 0.11616), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v1.ckpt as top 1\n",
      "INFO:lightning:Epoch 7: avg_val_loss reached 0.11616 (best 0.11616), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v1.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 22/22 [00:05<00:00,  4.33it/s, loss=0.164, v_num=d0c3]\n",
      "Epoch 8:  55%|█████▍    | 12/22 [00:02<00:02,  4.62it/s, loss=0.120, v_num=d0c3]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:02<00:24,  2.48s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: avg_val_loss reached 0.08028 (best 0.08028), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v0.ckpt as top 1\n",
      "INFO:lightning:Epoch 8: avg_val_loss reached 0.08028 (best 0.08028), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v0.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 22/22 [00:05<00:00,  4.00it/s, loss=0.120, v_num=d0c3]\n",
      "Epoch 9:  55%|█████▍    | 12/22 [00:02<00:02,  4.80it/s, loss=0.093, v_num=d0c3]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:02<00:23,  2.33s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: avg_val_loss reached 0.07686 (best 0.07686), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v1.ckpt as top 1\n",
      "INFO:lightning:Epoch 9: avg_val_loss reached 0.07686 (best 0.07686), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v1.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 22/22 [00:05<00:00,  4.18it/s, loss=0.093, v_num=d0c3]\n",
      "Epoch 10:  55%|█████▍    | 12/22 [00:02<00:02,  4.41it/s, loss=0.077, v_num=d0c3]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:02<00:24,  2.44s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: avg_val_loss reached 0.06625 (best 0.06625), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v0.ckpt as top 1\n",
      "INFO:lightning:Epoch 10: avg_val_loss reached 0.06625 (best 0.06625), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v0.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 22/22 [00:05<00:00,  3.95it/s, loss=0.077, v_num=d0c3]\n",
      "Epoch 11:  55%|█████▍    | 12/22 [00:02<00:01,  5.10it/s, loss=0.069, v_num=d0c3]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:02<00:22,  2.20s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: avg_val_loss reached 0.04438 (best 0.04438), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v1.ckpt as top 1\n",
      "INFO:lightning:Epoch 11: avg_val_loss reached 0.04438 (best 0.04438), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v1.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 22/22 [00:04<00:00,  4.41it/s, loss=0.069, v_num=d0c3]\n",
      "Epoch 12:  55%|█████▍    | 12/22 [00:02<00:02,  4.79it/s, loss=0.056, v_num=d0c3]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:02<00:25,  2.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: avg_val_loss reached 0.03461 (best 0.03461), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v0.ckpt as top 1\n",
      "INFO:lightning:Epoch 12: avg_val_loss reached 0.03461 (best 0.03461), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v0.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 22/22 [00:05<00:00,  4.06it/s, loss=0.056, v_num=d0c3]\n",
      "Epoch 13:  55%|█████▍    | 12/22 [00:02<00:01,  5.41it/s, loss=0.039, v_num=d0c3]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:02<00:27,  2.77s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: avg_val_loss reached 0.02777 (best 0.02777), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v1.ckpt as top 1\n",
      "INFO:lightning:Epoch 13: avg_val_loss reached 0.02777 (best 0.02777), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v1.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 22/22 [00:05<00:00,  4.07it/s, loss=0.039, v_num=d0c3]\n",
      "Epoch 14:  55%|█████▍    | 12/22 [00:02<00:02,  4.91it/s, loss=0.027, v_num=d0c3]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:02<00:23,  2.37s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: avg_val_loss reached 0.02178 (best 0.02178), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v0.ckpt as top 1\n",
      "INFO:lightning:Epoch 14: avg_val_loss reached 0.02178 (best 0.02178), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v0.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 22/22 [00:05<00:00,  4.13it/s, loss=0.027, v_num=d0c3]\n",
      "Epoch 15:  55%|█████▍    | 12/22 [00:02<00:02,  4.65it/s, loss=0.022, v_num=d0c3]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:02<00:23,  2.40s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: avg_val_loss reached 0.01789 (best 0.01789), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v1.ckpt as top 1\n",
      "INFO:lightning:Epoch 15: avg_val_loss reached 0.01789 (best 0.01789), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v1.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 22/22 [00:05<00:00,  4.07it/s, loss=0.022, v_num=d0c3]\n",
      "Epoch 16:  55%|█████▍    | 12/22 [00:02<00:02,  4.33it/s, loss=0.018, v_num=d0c3]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:02<00:27,  2.75s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: avg_val_loss reached 0.01575 (best 0.01575), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v0.ckpt as top 1\n",
      "INFO:lightning:Epoch 16: avg_val_loss reached 0.01575 (best 0.01575), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v0.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 22/22 [00:05<00:00,  3.70it/s, loss=0.018, v_num=d0c3]\n",
      "Epoch 17:  55%|█████▍    | 12/22 [00:02<00:02,  4.22it/s, loss=0.016, v_num=d0c3]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:02<00:21,  2.18s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: avg_val_loss reached 0.01420 (best 0.01420), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v1.ckpt as top 1\n",
      "INFO:lightning:Epoch 17: avg_val_loss reached 0.01420 (best 0.01420), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v1.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 22/22 [00:05<00:00,  4.01it/s, loss=0.016, v_num=d0c3]\n",
      "Epoch 18:  55%|█████▍    | 12/22 [00:02<00:01,  5.26it/s, loss=0.014, v_num=d0c3]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:02<00:23,  2.38s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: avg_val_loss reached 0.01299 (best 0.01299), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v0.ckpt as top 1\n",
      "INFO:lightning:Epoch 18: avg_val_loss reached 0.01299 (best 0.01299), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v0.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 22/22 [00:05<00:00,  4.34it/s, loss=0.014, v_num=d0c3]\n",
      "Epoch 19:  55%|█████▍    | 12/22 [00:02<00:02,  4.98it/s, loss=0.013, v_num=d0c3]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:02<00:21,  2.13s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: avg_val_loss reached 0.01203 (best 0.01203), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v1.ckpt as top 1\n",
      "INFO:lightning:Epoch 19: avg_val_loss reached 0.01203 (best 0.01203), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v1.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 22/22 [00:04<00:00,  4.41it/s, loss=0.013, v_num=d0c3]\n",
      "Epoch 20:  55%|█████▍    | 12/22 [00:02<00:01,  5.14it/s, loss=0.012, v_num=d0c3]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:02<00:24,  2.49s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: avg_val_loss reached 0.01124 (best 0.01124), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v0.ckpt as top 1\n",
      "INFO:lightning:Epoch 20: avg_val_loss reached 0.01124 (best 0.01124), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v0.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 22/22 [00:05<00:00,  4.19it/s, loss=0.012, v_num=d0c3]\n",
      "Epoch 21:  55%|█████▍    | 12/22 [00:02<00:02,  4.83it/s, loss=0.011, v_num=d0c3]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:02<00:23,  2.38s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: avg_val_loss reached 0.01058 (best 0.01058), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v1.ckpt as top 1\n",
      "INFO:lightning:Epoch 21: avg_val_loss reached 0.01058 (best 0.01058), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v1.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 22/22 [00:05<00:00,  4.17it/s, loss=0.011, v_num=d0c3]\n",
      "Epoch 22:  55%|█████▍    | 12/22 [00:02<00:01,  5.12it/s, loss=0.011, v_num=d0c3]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:02<00:24,  2.44s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: avg_val_loss reached 0.01003 (best 0.01003), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v0.ckpt as top 1\n",
      "INFO:lightning:Epoch 22: avg_val_loss reached 0.01003 (best 0.01003), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v0.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 22/22 [00:05<00:00,  4.23it/s, loss=0.011, v_num=d0c3]\n",
      "Epoch 23:  55%|█████▍    | 12/22 [00:02<00:02,  4.75it/s, loss=0.010, v_num=d0c3]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:02<00:22,  2.25s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: avg_val_loss reached 0.00956 (best 0.00956), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v1.ckpt as top 1\n",
      "INFO:lightning:Epoch 23: avg_val_loss reached 0.00956 (best 0.00956), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v1.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 22/22 [00:05<00:00,  4.23it/s, loss=0.010, v_num=d0c3]\n",
      "Epoch 24:  55%|█████▍    | 12/22 [00:02<00:02,  4.88it/s, loss=0.010, v_num=d0c3]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:02<00:25,  2.53s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: avg_val_loss reached 0.00917 (best 0.00917), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v0.ckpt as top 1\n",
      "INFO:lightning:Epoch 24: avg_val_loss reached 0.00917 (best 0.00917), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v0.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 22/22 [00:05<00:00,  4.08it/s, loss=0.010, v_num=d0c3]\n",
      "Epoch 25:  55%|█████▍    | 12/22 [00:02<00:02,  4.90it/s, loss=0.009, v_num=d0c3]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:02<00:22,  2.20s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: avg_val_loss reached 0.00884 (best 0.00884), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v1.ckpt as top 1\n",
      "INFO:lightning:Epoch 25: avg_val_loss reached 0.00884 (best 0.00884), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v1.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 22/22 [00:05<00:00,  4.34it/s, loss=0.009, v_num=d0c3]\n",
      "Epoch 26:  55%|█████▍    | 12/22 [00:02<00:01,  5.09it/s, loss=0.009, v_num=d0c3]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:02<00:22,  2.26s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: avg_val_loss reached 0.00855 (best 0.00855), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v0.ckpt as top 1\n",
      "INFO:lightning:Epoch 26: avg_val_loss reached 0.00855 (best 0.00855), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v0.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 22/22 [00:05<00:00,  4.38it/s, loss=0.009, v_num=d0c3]\n",
      "Epoch 27:  55%|█████▍    | 12/22 [00:02<00:01,  5.17it/s, loss=0.009, v_num=d0c3]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:02<00:24,  2.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: avg_val_loss reached 0.00832 (best 0.00832), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v1.ckpt as top 1\n",
      "INFO:lightning:Epoch 27: avg_val_loss reached 0.00832 (best 0.00832), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v1.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 22/22 [00:05<00:00,  4.16it/s, loss=0.009, v_num=d0c3]\n",
      "Epoch 28:  55%|█████▍    | 12/22 [00:02<00:02,  4.74it/s, loss=0.008, v_num=d0c3]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:02<00:27,  2.72s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: avg_val_loss reached 0.00812 (best 0.00812), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v0.ckpt as top 1\n",
      "INFO:lightning:Epoch 28: avg_val_loss reached 0.00812 (best 0.00812), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v0.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 22/22 [00:05<00:00,  3.85it/s, loss=0.008, v_num=d0c3]\n",
      "Epoch 28: 100%|██████████| 22/22 [00:06<00:00,  3.58it/s, loss=0.008, v_num=d0c3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: ----------------------------------\n",
      "COMET INFO: Comet.ml OfflineExperiment Summary\n",
      "COMET INFO: ----------------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : [OfflineExperiment will get URL after upload]\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     avg_train_loss [29] : (0.008260891772806644, 0.7119700908660889)\n",
      "COMET INFO:     avg_val_loss [29]   : (0.008115561679005623, 0.6218330264091492)\n",
      "COMET INFO:   Others:\n",
      "COMET INFO:     offline_experiment : True\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     device           : cuda\n",
      "COMET INFO:     logger           : <pytorch_lightning.loggers.comet.CometLogger object at 0x7ff01e8d2d50>\n",
      "COMET INFO:     lr               : 0.001\n",
      "COMET INFO:     max_epochs       : 40\n",
      "COMET INFO:     num_warmup_steps : 1\n",
      "COMET INFO:     num_workers      : 12\n",
      "COMET INFO:     overfit_batches  : 0.001\n",
      "COMET INFO:     pin_memory       : True\n",
      "COMET INFO:     shuffle          : 1\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     code                     : 1 (3 KB)\n",
      "COMET INFO:     environment details      : 1\n",
      "COMET INFO:     filename                 : 1\n",
      "COMET INFO:     git metadata             : 1\n",
      "COMET INFO:     git-patch (uncompressed) : 1 (39 KB)\n",
      "COMET INFO:     installed packages       : 1\n",
      "COMET INFO:     notebook                 : 1\n",
      "COMET INFO:     os packages              : 1\n",
      "COMET INFO: ----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Starting saving the offline archive\n",
      "COMET INFO: To upload this offline experiment, run:\n",
      "    comet upload logs/89048baa99cd466db01f02611e48d0c3.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.31 s, sys: 2min 31s, total: 2min 34s\n",
      "Wall time: 2min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, running the model itself. I specified 2000 warmup steps and learning rate 0.001. Model automatically will stop if validation loss averaged on batches will not reduce for three consecutive epochs at least by 0.001. Additionally it will save the best model in checkpoint folder for us to be able to load it and try on test sample. There are some additional features which are provided by Pytorch Lightning, like learning rate scheduler and different logging possibilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'pin_memory': True,\n",
    "    'device': device,\n",
    "    'num_workers': 12,\n",
    "    'logger': comet_logger,\n",
    "    'max_epochs': 30,\n",
    "    'lr': 1e-3,\n",
    "    'num_warmup_steps': 2000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EarlyStopping mode set to min for monitoring avg_val_loss.\n",
      "INFO:lightning:EarlyStopping mode set to min for monitoring avg_val_loss.\n"
     ]
    }
   ],
   "source": [
    "model = Model(X_train, y_train, X_val, y_val, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (net): Net(\n",
       "    (fc1): Linear(in_features=768, out_features=128, bias=True)\n",
       "    (fc2): Linear(in_features=128, out_features=2, bias=True)\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (loss_func): CrossEntropyLoss()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the mertics before training. By now model is not better than a random one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4239/4239 [00:04<00:00, 976.79it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.493     0.995     0.660     66934\n",
      "           1      0.445     0.004     0.007     68699\n",
      "\n",
      "    accuracy                          0.493    135633\n",
      "   macro avg      0.469     0.499     0.333    135633\n",
      "weighted avg      0.469     0.493     0.329    135633\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict_eval(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "INFO:lightning:GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "INFO:lightning:TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:lightning:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type | Params\n",
      "------------------------------\n",
      "0 | net  | Net  | 98.7 K\n",
      "INFO:lightning:\n",
      "  | Name | Type | Params\n",
      "------------------------------\n",
      "0 | net  | Net  | 98.7 K\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  70%|██████▉   | 11868/16955 [01:17<00:33, 153.19it/s, loss=0.637, v_num=cba1]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  70%|███████   | 11875/16955 [01:19<00:34, 148.83it/s, loss=0.637, v_num=cba1]\n",
      "Epoch 0:  70%|███████   | 11951/16955 [01:19<00:33, 149.60it/s, loss=0.637, v_num=cba1]\n",
      "Epoch 0:  71%|███████   | 12027/16955 [01:20<00:32, 150.08it/s, loss=0.637, v_num=cba1]\n",
      "Epoch 0:  71%|███████▏  | 12110/16955 [01:20<00:32, 150.93it/s, loss=0.637, v_num=cba1]\n",
      "Epoch 0:  72%|███████▏  | 12193/16955 [01:20<00:31, 151.77it/s, loss=0.637, v_num=cba1]\n",
      "Epoch 0:  72%|███████▏  | 12276/16955 [01:20<00:30, 152.61it/s, loss=0.637, v_num=cba1]\n",
      "Epoch 0:  73%|███████▎  | 12359/16955 [01:20<00:29, 153.44it/s, loss=0.637, v_num=cba1]\n",
      "Epoch 0:  73%|███████▎  | 12444/16955 [01:20<00:29, 154.30it/s, loss=0.637, v_num=cba1]\n",
      "Epoch 0:  74%|███████▍  | 12530/16955 [01:20<00:28, 155.17it/s, loss=0.637, v_num=cba1]\n",
      "Epoch 0:  74%|███████▍  | 12619/16955 [01:20<00:27, 156.08it/s, loss=0.637, v_num=cba1]\n",
      "Epoch 0:  75%|███████▍  | 12708/16955 [01:20<00:27, 156.99it/s, loss=0.637, v_num=cba1]\n",
      "Epoch 0:  75%|███████▌  | 12797/16955 [01:21<00:26, 157.89it/s, loss=0.637, v_num=cba1]\n",
      "Epoch 0:  76%|███████▌  | 12886/16955 [01:21<00:25, 158.78it/s, loss=0.637, v_num=cba1]\n",
      "Epoch 0:  77%|███████▋  | 12975/16955 [01:21<00:24, 159.65it/s, loss=0.637, v_num=cba1]\n",
      "Epoch 0:  77%|███████▋  | 13064/16955 [01:21<00:24, 160.53it/s, loss=0.637, v_num=cba1]\n",
      "Epoch 0:  78%|███████▊  | 13153/16955 [01:21<00:23, 161.41it/s, loss=0.637, v_num=cba1]\n",
      "Epoch 0:  78%|███████▊  | 13242/16955 [01:21<00:22, 162.29it/s, loss=0.637, v_num=cba1]\n",
      "Validating:  27%|██▋       | 1375/5087 [00:04<00:24, 151.97it/s]\u001b[A\n",
      "Epoch 0:  79%|███████▊  | 13331/16955 [01:21<00:22, 163.16it/s, loss=0.637, v_num=cba1]\n",
      "Epoch 0:  79%|███████▉  | 13420/16955 [01:21<00:21, 164.05it/s, loss=0.637, v_num=cba1]\n",
      "Epoch 0:  80%|███████▉  | 13509/16955 [01:21<00:20, 164.93it/s, loss=0.637, v_num=cba1]\n",
      "Epoch 0:  80%|████████  | 13598/16955 [01:22<00:20, 165.80it/s, loss=0.637, v_num=cba1]\n",
      "Epoch 0:  81%|████████  | 13687/16955 [01:22<00:19, 166.67it/s, loss=0.637, v_num=cba1]\n",
      "Epoch 0:  81%|████████▏ | 13776/16955 [01:22<00:18, 167.54it/s, loss=0.637, v_num=cba1]\n",
      "Epoch 0:  82%|████████▏ | 13865/16955 [01:22<00:18, 168.39it/s, loss=0.637, v_num=cba1]\n",
      "Epoch 0:  82%|████████▏ | 13954/16955 [01:22<00:17, 169.25it/s, loss=0.637, v_num=cba1]\n",
      "Epoch 0:  83%|████████▎ | 14043/16955 [01:22<00:17, 170.12it/s, loss=0.637, v_num=cba1]\n",
      "Epoch 0:  83%|████████▎ | 14132/16955 [01:22<00:16, 170.97it/s, loss=0.637, v_num=cba1]\n",
      "Epoch 0:  84%|████████▍ | 14221/16955 [01:22<00:15, 171.82it/s, loss=0.637, v_num=cba1]\n",
      "Epoch 0:  84%|████████▍ | 14310/16955 [01:22<00:15, 172.68it/s, loss=0.637, v_num=cba1]\n",
      "Epoch 0:  85%|████████▍ | 14399/16955 [01:22<00:14, 173.52it/s, loss=0.637, v_num=cba1]\n",
      "Epoch 0:  85%|████████▌ | 14488/16955 [01:23<00:14, 174.37it/s, loss=0.637, v_num=cba1]\n",
      "Epoch 0:  86%|████████▌ | 14577/16955 [01:23<00:13, 175.22it/s, loss=0.637, v_num=cba1]\n",
      "Epoch 0:  86%|████████▋ | 14666/16955 [01:23<00:13, 176.07it/s, loss=0.637, v_num=cba1]\n",
      "Epoch 0:  87%|████████▋ | 14755/16955 [01:23<00:12, 176.91it/s, loss=0.637, v_num=cba1]\n",
      "Epoch 0:  88%|████████▊ | 14844/16955 [01:23<00:11, 177.75it/s, loss=0.637, v_num=cba1]\n",
      "Epoch 0:  88%|████████▊ | 14933/16955 [01:23<00:11, 178.59it/s, loss=0.637, v_num=cba1]\n",
      "Epoch 0:  89%|████████▊ | 15023/16955 [01:23<00:10, 179.45it/s, loss=0.637, v_num=cba1]\n",
      "Epoch 0:  89%|████████▉ | 15113/16955 [01:23<00:10, 180.31it/s, loss=0.637, v_num=cba1]\n",
      "Epoch 0:  90%|████████▉ | 15203/16955 [01:23<00:09, 181.15it/s, loss=0.637, v_num=cba1]\n",
      "Epoch 0:  90%|█████████ | 15293/16955 [01:24<00:09, 182.00it/s, loss=0.637, v_num=cba1]\n",
      "Epoch 0:  91%|█████████ | 15383/16955 [01:24<00:08, 182.83it/s, loss=0.637, v_num=cba1]\n",
      "Epoch 0:  91%|█████████▏| 15473/16955 [01:24<00:08, 183.67it/s, loss=0.637, v_num=cba1]\n",
      "Epoch 0:  92%|█████████▏| 15563/16955 [01:24<00:07, 184.51it/s, loss=0.637, v_num=cba1]\n",
      "Validating:  73%|███████▎  | 3697/5087 [00:06<00:01, 848.33it/s]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 15653/16955 [01:24<00:07, 185.33it/s, loss=0.637, v_num=cba1]\n",
      "Epoch 0:  93%|█████████▎| 15743/16955 [01:24<00:06, 186.16it/s, loss=0.637, v_num=cba1]\n",
      "Epoch 0:  93%|█████████▎| 15833/16955 [01:24<00:06, 186.99it/s, loss=0.637, v_num=cba1]\n",
      "Epoch 0:  94%|█████████▍| 15923/16955 [01:24<00:05, 187.82it/s, loss=0.637, v_num=cba1]\n",
      "Epoch 0:  94%|█████████▍| 16013/16955 [01:24<00:04, 188.65it/s, loss=0.637, v_num=cba1]\n",
      "Epoch 0:  95%|█████████▍| 16103/16955 [01:24<00:04, 189.47it/s, loss=0.637, v_num=cba1]\n",
      "Epoch 0:  96%|█████████▌| 16193/16955 [01:25<00:04, 190.30it/s, loss=0.637, v_num=cba1]\n",
      "Epoch 0:  96%|█████████▌| 16283/16955 [01:25<00:03, 191.10it/s, loss=0.637, v_num=cba1]\n",
      "Epoch 0:  97%|█████████▋| 16373/16955 [01:25<00:03, 191.92it/s, loss=0.637, v_num=cba1]\n",
      "Epoch 0:  97%|█████████▋| 16463/16955 [01:25<00:02, 192.73it/s, loss=0.637, v_num=cba1]\n",
      "Epoch 0:  98%|█████████▊| 16553/16955 [01:25<00:02, 193.53it/s, loss=0.637, v_num=cba1]\n",
      "Epoch 0:  98%|█████████▊| 16643/16955 [01:25<00:01, 194.33it/s, loss=0.637, v_num=cba1]\n",
      "Epoch 0:  99%|█████████▊| 16733/16955 [01:25<00:01, 195.13it/s, loss=0.637, v_num=cba1]\n",
      "Epoch 0:  99%|█████████▉| 16823/16955 [01:25<00:00, 195.93it/s, loss=0.637, v_num=cba1]\n",
      "Epoch 0: 100%|█████████▉| 16913/16955 [01:25<00:00, 196.73it/s, loss=0.637, v_num=cba1]\n",
      "Validating:  99%|█████████▉| 5055/5087 [00:08<00:00, 822.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: avg_val_loss reached 0.63463 (best 0.63463), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v1.ckpt as top 1\n",
      "INFO:lightning:Epoch 0: avg_val_loss reached 0.63463 (best 0.63463), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v1.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 16955/16955 [01:26<00:00, 196.17it/s, loss=0.637, v_num=cba1]\n",
      "Epoch 1:  70%|██████▉   | 11868/16955 [00:51<00:21, 231.81it/s, loss=0.643, v_num=cba1]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1:  70%|███████   | 11880/16955 [00:53<00:22, 221.94it/s, loss=0.643, v_num=cba1]\n",
      "Epoch 1:  71%|███████   | 11975/16955 [00:53<00:22, 223.29it/s, loss=0.643, v_num=cba1]\n",
      "Epoch 1:  71%|███████   | 12070/16955 [00:53<00:21, 224.60it/s, loss=0.643, v_num=cba1]\n",
      "Epoch 1:  72%|███████▏  | 12165/16955 [00:53<00:21, 225.89it/s, loss=0.643, v_num=cba1]\n",
      "Epoch 1:  72%|███████▏  | 12260/16955 [00:53<00:20, 227.18it/s, loss=0.643, v_num=cba1]\n",
      "Epoch 1:  73%|███████▎  | 12355/16955 [00:54<00:20, 228.48it/s, loss=0.643, v_num=cba1]\n",
      "Epoch 1:  73%|███████▎  | 12450/16955 [00:54<00:19, 229.76it/s, loss=0.643, v_num=cba1]\n",
      "Validating:  11%|█▏        | 584/5087 [00:02<14:13,  5.27it/s]\u001b[A\n",
      "Epoch 1:  74%|███████▍  | 12545/16955 [00:54<00:19, 231.02it/s, loss=0.643, v_num=cba1]\n",
      "Epoch 1:  75%|███████▍  | 12640/16955 [00:54<00:18, 232.29it/s, loss=0.643, v_num=cba1]\n",
      "Epoch 1:  75%|███████▌  | 12735/16955 [00:54<00:18, 233.54it/s, loss=0.643, v_num=cba1]\n",
      "Epoch 1:  76%|███████▌  | 12830/16955 [00:54<00:17, 234.78it/s, loss=0.643, v_num=cba1]\n",
      "Epoch 1:  76%|███████▌  | 12925/16955 [00:54<00:17, 236.00it/s, loss=0.643, v_num=cba1]\n",
      "Epoch 1:  77%|███████▋  | 13020/16955 [00:54<00:16, 237.22it/s, loss=0.643, v_num=cba1]\n",
      "Validating:  23%|██▎       | 1163/5087 [00:03<01:05, 59.69it/s]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 13115/16955 [00:55<00:16, 238.42it/s, loss=0.643, v_num=cba1]\n",
      "Epoch 1:  78%|███████▊  | 13210/16955 [00:55<00:15, 239.65it/s, loss=0.643, v_num=cba1]\n",
      "Epoch 1:  78%|███████▊  | 13305/16955 [00:55<00:15, 240.89it/s, loss=0.643, v_num=cba1]\n",
      "Epoch 1:  79%|███████▉  | 13400/16955 [00:55<00:14, 242.12it/s, loss=0.643, v_num=cba1]\n",
      "Epoch 1:  80%|███████▉  | 13495/16955 [00:55<00:14, 243.34it/s, loss=0.643, v_num=cba1]\n",
      "Epoch 1:  80%|████████  | 13590/16955 [00:55<00:13, 244.55it/s, loss=0.643, v_num=cba1]\n",
      "Epoch 1:  81%|████████  | 13685/16955 [00:55<00:13, 245.77it/s, loss=0.643, v_num=cba1]\n",
      "Epoch 1:  81%|████████▏ | 13780/16955 [00:55<00:12, 246.97it/s, loss=0.643, v_num=cba1]\n",
      "Epoch 1:  82%|████████▏ | 13875/16955 [00:55<00:12, 248.19it/s, loss=0.643, v_num=cba1]\n",
      "Epoch 1:  82%|████████▏ | 13970/16955 [00:56<00:11, 249.42it/s, loss=0.643, v_num=cba1]\n",
      "Validating:  41%|████▏     | 2102/5087 [00:04<00:04, 681.90it/s]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 14065/16955 [00:56<00:11, 250.61it/s, loss=0.643, v_num=cba1]\n",
      "Epoch 1:  84%|████████▎ | 14160/16955 [00:56<00:11, 251.81it/s, loss=0.643, v_num=cba1]\n",
      "Epoch 1:  84%|████████▍ | 14255/16955 [00:56<00:10, 252.99it/s, loss=0.643, v_num=cba1]\n",
      "Epoch 1:  85%|████████▍ | 14350/16955 [00:56<00:10, 254.15it/s, loss=0.643, v_num=cba1]\n",
      "Epoch 1:  85%|████████▌ | 14445/16955 [00:56<00:09, 255.32it/s, loss=0.643, v_num=cba1]\n",
      "Epoch 1:  86%|████████▌ | 14540/16955 [00:56<00:09, 256.50it/s, loss=0.643, v_num=cba1]\n",
      "Epoch 1:  86%|████████▋ | 14635/16955 [00:56<00:09, 257.67it/s, loss=0.643, v_num=cba1]\n",
      "Epoch 1:  87%|████████▋ | 14730/16955 [00:56<00:08, 258.84it/s, loss=0.643, v_num=cba1]\n",
      "Epoch 1:  87%|████████▋ | 14825/16955 [00:57<00:08, 259.99it/s, loss=0.643, v_num=cba1]\n",
      "Epoch 1:  88%|████████▊ | 14920/16955 [00:57<00:07, 261.15it/s, loss=0.643, v_num=cba1]\n",
      "Validating:  60%|██████    | 3053/5087 [00:05<00:02, 843.20it/s]\u001b[A\n",
      "Epoch 1:  89%|████████▊ | 15015/16955 [00:57<00:07, 262.27it/s, loss=0.643, v_num=cba1]\n",
      "Epoch 1:  89%|████████▉ | 15110/16955 [00:57<00:07, 263.43it/s, loss=0.643, v_num=cba1]\n",
      "Epoch 1:  90%|████████▉ | 15205/16955 [00:57<00:06, 264.55it/s, loss=0.643, v_num=cba1]\n",
      "Epoch 1:  90%|█████████ | 15300/16955 [00:57<00:06, 265.68it/s, loss=0.643, v_num=cba1]\n",
      "Epoch 1:  91%|█████████ | 15395/16955 [00:57<00:05, 266.82it/s, loss=0.643, v_num=cba1]\n",
      "Epoch 1:  91%|█████████▏| 15490/16955 [00:57<00:05, 267.93it/s, loss=0.643, v_num=cba1]\n",
      "Epoch 1:  92%|█████████▏| 15585/16955 [00:57<00:05, 269.07it/s, loss=0.643, v_num=cba1]\n",
      "Epoch 1:  92%|█████████▏| 15680/16955 [00:58<00:04, 270.19it/s, loss=0.643, v_num=cba1]\n",
      "Epoch 1:  93%|█████████▎| 15775/16955 [00:58<00:04, 271.32it/s, loss=0.643, v_num=cba1]\n",
      "Epoch 1:  94%|█████████▎| 15870/16955 [00:58<00:03, 272.46it/s, loss=0.643, v_num=cba1]\n",
      "Validating:  79%|███████▊  | 4003/5087 [00:07<00:01, 865.66it/s]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 15965/16955 [00:58<00:03, 273.49it/s, loss=0.643, v_num=cba1]\n",
      "Epoch 1:  95%|█████████▍| 16060/16955 [00:58<00:03, 274.59it/s, loss=0.643, v_num=cba1]\n",
      "Epoch 1:  95%|█████████▌| 16155/16955 [00:58<00:02, 275.68it/s, loss=0.643, v_num=cba1]\n",
      "Epoch 1:  96%|█████████▌| 16250/16955 [00:58<00:02, 276.78it/s, loss=0.643, v_num=cba1]\n",
      "Epoch 1:  96%|█████████▋| 16345/16955 [00:58<00:02, 277.87it/s, loss=0.643, v_num=cba1]\n",
      "Epoch 1:  97%|█████████▋| 16440/16955 [00:58<00:01, 278.96it/s, loss=0.643, v_num=cba1]\n",
      "Epoch 1:  98%|█████████▊| 16535/16955 [00:59<00:01, 280.03it/s, loss=0.643, v_num=cba1]\n",
      "Epoch 1:  98%|█████████▊| 16630/16955 [00:59<00:01, 281.10it/s, loss=0.643, v_num=cba1]\n",
      "Validating:  94%|█████████▍| 4770/5087 [00:07<00:00, 844.48it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▊| 16725/16955 [00:59<00:00, 282.17it/s, loss=0.643, v_num=cba1]\n",
      "Epoch 1:  99%|█████████▉| 16820/16955 [00:59<00:00, 283.21it/s, loss=0.643, v_num=cba1]\n",
      "Epoch 1: 100%|█████████▉| 16915/16955 [00:59<00:00, 284.26it/s, loss=0.643, v_num=cba1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: avg_val_loss reached 0.62691 (best 0.62691), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v2.ckpt as top 1\n",
      "INFO:lightning:Epoch 1: avg_val_loss reached 0.62691 (best 0.62691), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v2.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 16955/16955 [00:59<00:00, 282.82it/s, loss=0.643, v_num=cba1]\n",
      "Epoch 2:  70%|██████▉   | 11868/16955 [00:51<00:22, 229.39it/s, loss=0.639, v_num=cba1]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2:  70%|███████   | 11875/16955 [00:54<00:23, 219.27it/s, loss=0.639, v_num=cba1]\n",
      "Epoch 2:  71%|███████   | 11970/16955 [00:54<00:22, 220.54it/s, loss=0.639, v_num=cba1]\n",
      "Epoch 2:  71%|███████   | 12065/16955 [00:54<00:22, 221.79it/s, loss=0.639, v_num=cba1]\n",
      "Epoch 2:  72%|███████▏  | 12160/16955 [00:54<00:21, 223.05it/s, loss=0.639, v_num=cba1]\n",
      "Epoch 2:  72%|███████▏  | 12255/16955 [00:54<00:20, 224.32it/s, loss=0.639, v_num=cba1]\n",
      "Epoch 2:  73%|███████▎  | 12350/16955 [00:54<00:20, 225.60it/s, loss=0.639, v_num=cba1]\n",
      "Epoch 2:  73%|███████▎  | 12445/16955 [00:54<00:19, 226.88it/s, loss=0.639, v_num=cba1]\n",
      "Validating:  11%|█▏        | 577/5087 [00:03<15:00,  5.01it/s]\u001b[A\n",
      "Epoch 2:  74%|███████▍  | 12540/16955 [00:54<00:19, 228.12it/s, loss=0.639, v_num=cba1]\n",
      "Epoch 2:  75%|███████▍  | 12635/16955 [00:55<00:18, 229.40it/s, loss=0.639, v_num=cba1]\n",
      "Epoch 2:  75%|███████▌  | 12730/16955 [00:55<00:18, 230.65it/s, loss=0.639, v_num=cba1]\n",
      "Epoch 2:  76%|███████▌  | 12825/16955 [00:55<00:17, 231.90it/s, loss=0.639, v_num=cba1]\n",
      "Epoch 2:  76%|███████▌  | 12920/16955 [00:55<00:17, 233.14it/s, loss=0.639, v_num=cba1]\n",
      "Epoch 2:  77%|███████▋  | 13015/16955 [00:55<00:16, 234.37it/s, loss=0.639, v_num=cba1]\n",
      "Epoch 2:  77%|███████▋  | 13110/16955 [00:55<00:16, 235.62it/s, loss=0.639, v_num=cba1]\n",
      "Epoch 2:  78%|███████▊  | 13205/16955 [00:55<00:15, 236.84it/s, loss=0.639, v_num=cba1]\n",
      "Validating:  26%|██▋       | 1342/5087 [00:04<00:34, 108.78it/s]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 13300/16955 [00:55<00:15, 238.06it/s, loss=0.639, v_num=cba1]\n",
      "Epoch 2:  79%|███████▉  | 13395/16955 [00:55<00:14, 239.28it/s, loss=0.639, v_num=cba1]\n",
      "Epoch 2:  80%|███████▉  | 13490/16955 [00:56<00:14, 240.51it/s, loss=0.639, v_num=cba1]\n",
      "Epoch 2:  80%|████████  | 13585/16955 [00:56<00:13, 241.71it/s, loss=0.639, v_num=cba1]\n",
      "Epoch 2:  81%|████████  | 13680/16955 [00:56<00:13, 242.91it/s, loss=0.639, v_num=cba1]\n",
      "Epoch 2:  81%|████████  | 13775/16955 [00:56<00:13, 244.10it/s, loss=0.639, v_num=cba1]\n",
      "Epoch 2:  82%|████████▏ | 13870/16955 [00:56<00:12, 245.27it/s, loss=0.639, v_num=cba1]\n",
      "Epoch 2:  82%|████████▏ | 13965/16955 [00:56<00:12, 246.46it/s, loss=0.639, v_num=cba1]\n",
      "Epoch 2:  83%|████████▎ | 14060/16955 [00:56<00:11, 247.64it/s, loss=0.639, v_num=cba1]\n",
      "Validating:  43%|████▎     | 2192/5087 [00:05<00:04, 700.31it/s]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 14155/16955 [00:56<00:11, 248.80it/s, loss=0.639, v_num=cba1]\n",
      "Epoch 2:  84%|████████▍ | 14250/16955 [00:57<00:10, 249.98it/s, loss=0.639, v_num=cba1]\n",
      "Epoch 2:  85%|████████▍ | 14345/16955 [00:57<00:10, 251.17it/s, loss=0.639, v_num=cba1]\n",
      "Epoch 2:  85%|████████▌ | 14440/16955 [00:57<00:09, 252.34it/s, loss=0.639, v_num=cba1]\n",
      "Epoch 2:  86%|████████▌ | 14535/16955 [00:57<00:09, 253.51it/s, loss=0.639, v_num=cba1]\n",
      "Epoch 2:  86%|████████▋ | 14630/16955 [00:57<00:09, 254.68it/s, loss=0.639, v_num=cba1]\n",
      "Epoch 2:  87%|████████▋ | 14725/16955 [00:57<00:08, 255.83it/s, loss=0.639, v_num=cba1]\n",
      "Epoch 2:  87%|████████▋ | 14820/16955 [00:57<00:08, 256.96it/s, loss=0.639, v_num=cba1]\n",
      "Epoch 2:  88%|████████▊ | 14915/16955 [00:57<00:07, 258.10it/s, loss=0.639, v_num=cba1]\n",
      "Validating:  60%|█████▉    | 3049/5087 [00:06<00:02, 830.13it/s]\u001b[A\n",
      "Epoch 2:  89%|████████▊ | 15010/16955 [00:57<00:07, 259.21it/s, loss=0.639, v_num=cba1]\n",
      "Epoch 2:  89%|████████▉ | 15105/16955 [00:58<00:07, 260.32it/s, loss=0.639, v_num=cba1]\n",
      "Epoch 2:  90%|████████▉ | 15200/16955 [00:58<00:06, 261.40it/s, loss=0.639, v_num=cba1]\n",
      "Epoch 2:  90%|█████████ | 15295/16955 [00:58<00:06, 262.49it/s, loss=0.639, v_num=cba1]\n",
      "Epoch 2:  91%|█████████ | 15390/16955 [00:58<00:05, 263.57it/s, loss=0.639, v_num=cba1]\n",
      "Epoch 2:  91%|█████████▏| 15485/16955 [00:58<00:05, 264.64it/s, loss=0.639, v_num=cba1]\n",
      "Validating:  71%|███████   | 3622/5087 [00:06<00:01, 780.33it/s]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 15580/16955 [00:58<00:05, 265.73it/s, loss=0.639, v_num=cba1]\n",
      "Epoch 2:  92%|█████████▏| 15675/16955 [00:58<00:04, 266.84it/s, loss=0.639, v_num=cba1]\n",
      "Epoch 2:  93%|█████████▎| 15770/16955 [00:58<00:04, 267.94it/s, loss=0.639, v_num=cba1]\n",
      "Epoch 2:  94%|█████████▎| 15865/16955 [00:59<00:04, 268.49it/s, loss=0.639, v_num=cba1]\n",
      "Epoch 2:  94%|█████████▍| 15960/16955 [00:59<00:03, 269.56it/s, loss=0.639, v_num=cba1]\n",
      "Epoch 2:  95%|█████████▍| 16055/16955 [00:59<00:03, 270.63it/s, loss=0.639, v_num=cba1]\n",
      "Epoch 2:  95%|█████████▌| 16150/16955 [00:59<00:02, 271.72it/s, loss=0.639, v_num=cba1]\n",
      "Epoch 2:  96%|█████████▌| 16245/16955 [00:59<00:02, 272.82it/s, loss=0.639, v_num=cba1]\n",
      "Validating:  86%|████████▌ | 4377/5087 [00:07<00:00, 790.40it/s]\u001b[A\n",
      "Epoch 2:  96%|█████████▋| 16340/16955 [00:59<00:02, 273.91it/s, loss=0.639, v_num=cba1]\n",
      "Epoch 2:  97%|█████████▋| 16435/16955 [00:59<00:01, 274.97it/s, loss=0.639, v_num=cba1]\n",
      "Epoch 2:  97%|█████████▋| 16530/16955 [00:59<00:01, 276.05it/s, loss=0.639, v_num=cba1]\n",
      "Epoch 2:  98%|█████████▊| 16625/16955 [00:59<00:01, 277.12it/s, loss=0.639, v_num=cba1]\n",
      "Epoch 2:  99%|█████████▊| 16720/16955 [01:00<00:00, 278.20it/s, loss=0.639, v_num=cba1]\n",
      "Epoch 2:  99%|█████████▉| 16815/16955 [01:00<00:00, 279.23it/s, loss=0.639, v_num=cba1]\n",
      "Epoch 2: 100%|█████████▉| 16910/16955 [01:00<00:00, 280.28it/s, loss=0.639, v_num=cba1]\n",
      "Validating: 100%|█████████▉| 5063/5087 [00:08<00:00, 832.54it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: avg_val_loss reached 0.62482 (best 0.62482), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v1.ckpt as top 1\n",
      "INFO:lightning:Epoch 2: avg_val_loss reached 0.62482 (best 0.62482), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v1.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 16955/16955 [01:00<00:00, 278.92it/s, loss=0.639, v_num=cba1]\n",
      "Epoch 3:  70%|██████▉   | 11868/16955 [00:51<00:21, 231.53it/s, loss=0.627, v_num=cba1]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 3:  70%|███████   | 11875/16955 [00:53<00:22, 221.40it/s, loss=0.627, v_num=cba1]\n",
      "Epoch 3:  71%|███████   | 11970/16955 [00:53<00:22, 222.67it/s, loss=0.627, v_num=cba1]\n",
      "Epoch 3:  71%|███████   | 12065/16955 [00:53<00:21, 223.98it/s, loss=0.627, v_num=cba1]\n",
      "Epoch 3:  72%|███████▏  | 12160/16955 [00:53<00:21, 225.28it/s, loss=0.627, v_num=cba1]\n",
      "Epoch 3:  72%|███████▏  | 12255/16955 [00:54<00:20, 226.57it/s, loss=0.627, v_num=cba1]\n",
      "Epoch 3:  73%|███████▎  | 12350/16955 [00:54<00:20, 227.87it/s, loss=0.627, v_num=cba1]\n",
      "Epoch 3:  73%|███████▎  | 12445/16955 [00:54<00:19, 229.13it/s, loss=0.627, v_num=cba1]\n",
      "Epoch 3:  74%|███████▍  | 12540/16955 [00:54<00:19, 230.39it/s, loss=0.627, v_num=cba1]\n",
      "Validating:  13%|█▎        | 672/5087 [00:03<10:06,  7.27it/s]\u001b[A\n",
      "Epoch 3:  75%|███████▍  | 12635/16955 [00:54<00:18, 231.62it/s, loss=0.627, v_num=cba1]\n",
      "Epoch 3:  75%|███████▌  | 12730/16955 [00:54<00:18, 232.88it/s, loss=0.627, v_num=cba1]\n",
      "Epoch 3:  76%|███████▌  | 12825/16955 [00:54<00:17, 234.14it/s, loss=0.627, v_num=cba1]\n",
      "Epoch 3:  76%|███████▌  | 12920/16955 [00:54<00:17, 235.37it/s, loss=0.627, v_num=cba1]\n",
      "Epoch 3:  77%|███████▋  | 13015/16955 [00:55<00:16, 236.61it/s, loss=0.627, v_num=cba1]\n",
      "Epoch 3:  77%|███████▋  | 13110/16955 [00:55<00:16, 237.85it/s, loss=0.627, v_num=cba1]\n",
      "Epoch 3:  78%|███████▊  | 13205/16955 [00:55<00:15, 239.10it/s, loss=0.627, v_num=cba1]\n",
      "Epoch 3:  78%|███████▊  | 13300/16955 [00:55<00:15, 240.34it/s, loss=0.627, v_num=cba1]\n",
      "Validating:  28%|██▊       | 1436/5087 [00:04<00:24, 149.71it/s]\u001b[A\n",
      "Epoch 3:  79%|███████▉  | 13395/16955 [00:55<00:14, 241.57it/s, loss=0.627, v_num=cba1]\n",
      "Epoch 3:  80%|███████▉  | 13490/16955 [00:55<00:14, 242.81it/s, loss=0.627, v_num=cba1]\n",
      "Epoch 3:  80%|████████  | 13585/16955 [00:55<00:13, 244.02it/s, loss=0.627, v_num=cba1]\n",
      "Epoch 3:  81%|████████  | 13680/16955 [00:55<00:13, 245.25it/s, loss=0.627, v_num=cba1]\n",
      "Epoch 3:  81%|████████  | 13775/16955 [00:55<00:12, 246.45it/s, loss=0.627, v_num=cba1]\n",
      "Epoch 3:  82%|████████▏ | 13870/16955 [00:56<00:12, 247.66it/s, loss=0.627, v_num=cba1]\n",
      "Epoch 3:  82%|████████▏ | 13965/16955 [00:56<00:12, 248.87it/s, loss=0.627, v_num=cba1]\n",
      "Epoch 3:  83%|████████▎ | 14060/16955 [00:56<00:11, 250.05it/s, loss=0.627, v_num=cba1]\n",
      "Epoch 3:  83%|████████▎ | 14155/16955 [00:56<00:11, 251.22it/s, loss=0.627, v_num=cba1]\n",
      "Epoch 3:  84%|████████▍ | 14250/16955 [00:56<00:10, 252.36it/s, loss=0.627, v_num=cba1]\n",
      "Validating:  47%|████▋     | 2387/5087 [00:05<00:03, 747.28it/s]\u001b[A\n",
      "Epoch 3:  85%|████████▍ | 14345/16955 [00:56<00:10, 253.51it/s, loss=0.627, v_num=cba1]\n",
      "Epoch 3:  85%|████████▌ | 14440/16955 [00:56<00:09, 254.68it/s, loss=0.627, v_num=cba1]\n",
      "Epoch 3:  86%|████████▌ | 14535/16955 [00:56<00:09, 255.83it/s, loss=0.627, v_num=cba1]\n",
      "Epoch 3:  86%|████████▋ | 14630/16955 [00:56<00:09, 256.97it/s, loss=0.627, v_num=cba1]\n",
      "Epoch 3:  87%|████████▋ | 14725/16955 [00:57<00:08, 258.14it/s, loss=0.627, v_num=cba1]\n",
      "Epoch 3:  87%|████████▋ | 14820/16955 [00:57<00:08, 259.28it/s, loss=0.627, v_num=cba1]\n",
      "Epoch 3:  88%|████████▊ | 14915/16955 [00:57<00:07, 260.41it/s, loss=0.627, v_num=cba1]\n",
      "Epoch 3:  89%|████████▊ | 15010/16955 [00:57<00:07, 261.54it/s, loss=0.627, v_num=cba1]\n",
      "Validating:  62%|██████▏   | 3142/5087 [00:06<00:02, 816.47it/s]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 15105/16955 [00:57<00:07, 262.67it/s, loss=0.627, v_num=cba1]\n",
      "Epoch 3:  90%|████████▉ | 15200/16955 [00:57<00:06, 263.79it/s, loss=0.627, v_num=cba1]\n",
      "Epoch 3:  90%|█████████ | 15295/16955 [00:57<00:06, 264.89it/s, loss=0.627, v_num=cba1]\n",
      "Epoch 3:  91%|█████████ | 15390/16955 [00:57<00:05, 266.02it/s, loss=0.627, v_num=cba1]\n",
      "Epoch 3:  91%|█████████▏| 15485/16955 [00:57<00:05, 267.10it/s, loss=0.627, v_num=cba1]\n",
      "Epoch 3:  92%|█████████▏| 15580/16955 [00:58<00:05, 268.20it/s, loss=0.627, v_num=cba1]\n",
      "Epoch 3:  92%|█████████▏| 15675/16955 [00:58<00:04, 269.31it/s, loss=0.627, v_num=cba1]\n",
      "Validating:  75%|███████▍  | 3812/5087 [00:06<00:01, 817.29it/s]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 15770/16955 [00:58<00:04, 270.40it/s, loss=0.627, v_num=cba1]\n",
      "Epoch 3:  94%|█████████▎| 15865/16955 [00:58<00:04, 271.51it/s, loss=0.627, v_num=cba1]\n",
      "Epoch 3:  94%|█████████▍| 15960/16955 [00:58<00:03, 272.58it/s, loss=0.627, v_num=cba1]\n",
      "Epoch 3:  95%|█████████▍| 16055/16955 [00:58<00:03, 273.67it/s, loss=0.627, v_num=cba1]\n",
      "Epoch 3:  95%|█████████▌| 16150/16955 [00:58<00:02, 274.75it/s, loss=0.627, v_num=cba1]\n",
      "Epoch 3:  96%|█████████▌| 16245/16955 [00:58<00:02, 275.84it/s, loss=0.627, v_num=cba1]\n",
      "Epoch 3:  96%|█████████▋| 16340/16955 [00:59<00:02, 276.94it/s, loss=0.627, v_num=cba1]\n",
      "Epoch 3:  97%|█████████▋| 16435/16955 [00:59<00:01, 278.01it/s, loss=0.627, v_num=cba1]\n",
      "Validating:  90%|████████▉ | 4573/5087 [00:07<00:00, 836.74it/s]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 16530/16955 [00:59<00:01, 279.02it/s, loss=0.627, v_num=cba1]\n",
      "Epoch 3:  98%|█████████▊| 16625/16955 [00:59<00:01, 280.10it/s, loss=0.627, v_num=cba1]\n",
      "Epoch 3:  99%|█████████▊| 16720/16955 [00:59<00:00, 281.15it/s, loss=0.627, v_num=cba1]\n",
      "Epoch 3:  99%|█████████▉| 16815/16955 [00:59<00:00, 282.20it/s, loss=0.627, v_num=cba1]\n",
      "Epoch 3: 100%|█████████▉| 16910/16955 [00:59<00:00, 283.26it/s, loss=0.627, v_num=cba1]\n",
      "Validating: 100%|█████████▉| 5080/5087 [00:08<00:00, 835.94it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: avg_val_loss was not in top 1\n",
      "INFO:lightning:Epoch 3: avg_val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 16955/16955 [01:00<00:00, 281.99it/s, loss=0.627, v_num=cba1]\n",
      "Epoch 4:  70%|██████▉   | 11868/16955 [00:53<00:22, 223.13it/s, loss=0.623, v_num=cba1]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 4:  70%|███████   | 11875/16955 [00:55<00:23, 213.67it/s, loss=0.623, v_num=cba1]\n",
      "Epoch 4:  71%|███████   | 11970/16955 [00:55<00:23, 214.93it/s, loss=0.623, v_num=cba1]\n",
      "Epoch 4:  71%|███████   | 12065/16955 [00:55<00:22, 216.20it/s, loss=0.623, v_num=cba1]\n",
      "Epoch 4:  72%|███████▏  | 12160/16955 [00:55<00:22, 217.46it/s, loss=0.623, v_num=cba1]\n",
      "Epoch 4:  72%|███████▏  | 12255/16955 [00:56<00:21, 218.73it/s, loss=0.623, v_num=cba1]\n",
      "Epoch 4:  73%|███████▎  | 12350/16955 [00:56<00:20, 219.99it/s, loss=0.623, v_num=cba1]\n",
      "Epoch 4:  73%|███████▎  | 12445/16955 [00:56<00:20, 221.25it/s, loss=0.623, v_num=cba1]\n",
      "Epoch 4:  74%|███████▍  | 12540/16955 [00:56<00:19, 222.48it/s, loss=0.623, v_num=cba1]\n",
      "Validating:  13%|█▎        | 678/5087 [00:03<10:09,  7.24it/s]\u001b[A\n",
      "Epoch 4:  75%|███████▍  | 12635/16955 [00:56<00:19, 223.70it/s, loss=0.623, v_num=cba1]\n",
      "Epoch 4:  75%|███████▌  | 12730/16955 [00:56<00:18, 224.93it/s, loss=0.623, v_num=cba1]\n",
      "Epoch 4:  76%|███████▌  | 12825/16955 [00:56<00:18, 226.15it/s, loss=0.623, v_num=cba1]\n",
      "Epoch 4:  76%|███████▌  | 12920/16955 [00:56<00:17, 227.38it/s, loss=0.623, v_num=cba1]\n",
      "Epoch 4:  77%|███████▋  | 13015/16955 [00:56<00:17, 228.59it/s, loss=0.623, v_num=cba1]\n",
      "Epoch 4:  77%|███████▋  | 13110/16955 [00:57<00:16, 229.81it/s, loss=0.623, v_num=cba1]\n",
      "Epoch 4:  78%|███████▊  | 13205/16955 [00:57<00:16, 231.02it/s, loss=0.623, v_num=cba1]\n",
      "Epoch 4:  78%|███████▊  | 13300/16955 [00:57<00:15, 232.22it/s, loss=0.623, v_num=cba1]\n",
      "Validating:  28%|██▊       | 1433/5087 [00:04<00:24, 148.80it/s]\u001b[A\n",
      "Epoch 4:  79%|███████▉  | 13395/16955 [00:57<00:15, 233.41it/s, loss=0.623, v_num=cba1]\n",
      "Epoch 4:  80%|███████▉  | 13490/16955 [00:57<00:14, 234.61it/s, loss=0.623, v_num=cba1]\n",
      "Epoch 4:  80%|████████  | 13585/16955 [00:57<00:14, 235.79it/s, loss=0.623, v_num=cba1]\n",
      "Epoch 4:  81%|████████  | 13680/16955 [00:57<00:13, 236.97it/s, loss=0.623, v_num=cba1]\n",
      "Epoch 4:  81%|████████  | 13775/16955 [00:57<00:13, 238.15it/s, loss=0.623, v_num=cba1]\n",
      "Epoch 4:  82%|████████▏ | 13870/16955 [00:57<00:12, 239.33it/s, loss=0.623, v_num=cba1]\n",
      "Epoch 4:  82%|████████▏ | 13965/16955 [00:58<00:12, 240.50it/s, loss=0.623, v_num=cba1]\n",
      "Epoch 4:  83%|████████▎ | 14060/16955 [00:58<00:11, 241.68it/s, loss=0.623, v_num=cba1]\n",
      "Validating:  43%|████▎     | 2199/5087 [00:04<00:04, 711.25it/s]\u001b[A\n",
      "Epoch 4:  83%|████████▎ | 14155/16955 [00:58<00:11, 242.82it/s, loss=0.623, v_num=cba1]\n",
      "Epoch 4:  84%|████████▍ | 14250/16955 [00:58<00:11, 243.98it/s, loss=0.623, v_num=cba1]\n",
      "Epoch 4:  85%|████████▍ | 14345/16955 [00:58<00:10, 245.14it/s, loss=0.623, v_num=cba1]\n",
      "Epoch 4:  85%|████████▌ | 14440/16955 [00:58<00:10, 246.29it/s, loss=0.623, v_num=cba1]\n",
      "Epoch 4:  86%|████████▌ | 14535/16955 [00:58<00:09, 247.44it/s, loss=0.623, v_num=cba1]\n",
      "Epoch 4:  86%|████████▋ | 14630/16955 [00:58<00:09, 248.58it/s, loss=0.623, v_num=cba1]\n",
      "Epoch 4:  87%|████████▋ | 14725/16955 [00:58<00:08, 249.72it/s, loss=0.623, v_num=cba1]\n",
      "Epoch 4:  87%|████████▋ | 14820/16955 [00:59<00:08, 250.82it/s, loss=0.623, v_num=cba1]\n",
      "Epoch 4:  88%|████████▊ | 14915/16955 [00:59<00:08, 251.94it/s, loss=0.623, v_num=cba1]\n",
      "Validating:  60%|█████▉    | 3049/5087 [00:06<00:02, 817.95it/s]\u001b[A\n",
      "Epoch 4:  89%|████████▊ | 15010/16955 [00:59<00:07, 253.05it/s, loss=0.623, v_num=cba1]\n",
      "Epoch 4:  89%|████████▉ | 15105/16955 [00:59<00:07, 254.18it/s, loss=0.623, v_num=cba1]\n",
      "Epoch 4:  90%|████████▉ | 15200/16955 [00:59<00:06, 255.28it/s, loss=0.623, v_num=cba1]\n",
      "Epoch 4:  90%|█████████ | 15295/16955 [00:59<00:06, 256.39it/s, loss=0.623, v_num=cba1]\n",
      "Epoch 4:  91%|█████████ | 15390/16955 [00:59<00:06, 257.50it/s, loss=0.623, v_num=cba1]\n",
      "Epoch 4:  91%|█████████▏| 15485/16955 [00:59<00:05, 258.59it/s, loss=0.623, v_num=cba1]\n",
      "Epoch 4:  92%|█████████▏| 15580/16955 [00:59<00:05, 259.71it/s, loss=0.623, v_num=cba1]\n",
      "Epoch 4:  92%|█████████▏| 15675/16955 [01:00<00:04, 260.79it/s, loss=0.623, v_num=cba1]\n",
      "Epoch 4:  93%|█████████▎| 15770/16955 [01:00<00:04, 261.87it/s, loss=0.623, v_num=cba1]\n",
      "Validating:  77%|███████▋  | 3903/5087 [00:07<00:01, 832.19it/s]\u001b[A\n",
      "Epoch 4:  94%|█████████▎| 15865/16955 [01:00<00:04, 262.95it/s, loss=0.623, v_num=cba1]\n",
      "Epoch 4:  94%|█████████▍| 15960/16955 [01:00<00:03, 264.00it/s, loss=0.623, v_num=cba1]\n",
      "Epoch 4:  95%|█████████▍| 16055/16955 [01:00<00:03, 265.08it/s, loss=0.623, v_num=cba1]\n",
      "Epoch 4:  95%|█████████▌| 16150/16955 [01:00<00:03, 266.16it/s, loss=0.623, v_num=cba1]\n",
      "Epoch 4:  96%|█████████▌| 16245/16955 [01:00<00:02, 267.21it/s, loss=0.623, v_num=cba1]\n",
      "Epoch 4:  96%|█████████▋| 16340/16955 [01:00<00:02, 268.26it/s, loss=0.623, v_num=cba1]\n",
      "Epoch 4:  97%|█████████▋| 16435/16955 [01:01<00:01, 269.30it/s, loss=0.623, v_num=cba1]\n",
      "Epoch 4:  97%|█████████▋| 16530/16955 [01:01<00:01, 270.36it/s, loss=0.623, v_num=cba1]\n",
      "Validating:  92%|█████████▏| 4663/5087 [00:07<00:00, 825.92it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 16625/16955 [01:01<00:01, 271.40it/s, loss=0.623, v_num=cba1]\n",
      "Epoch 4:  99%|█████████▊| 16720/16955 [01:01<00:00, 272.44it/s, loss=0.623, v_num=cba1]\n",
      "Epoch 4:  99%|█████████▉| 16815/16955 [01:01<00:00, 273.48it/s, loss=0.623, v_num=cba1]\n",
      "Epoch 4: 100%|█████████▉| 16910/16955 [01:01<00:00, 274.52it/s, loss=0.623, v_num=cba1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: avg_val_loss was not in top 1\n",
      "INFO:lightning:Epoch 4: avg_val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 16955/16955 [01:02<00:00, 273.25it/s, loss=0.623, v_num=cba1]\n",
      "Epoch 5:  70%|██████▉   | 11868/16955 [00:52<00:22, 226.84it/s, loss=0.624, v_num=cba1]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 5:  70%|███████   | 11875/16955 [00:54<00:23, 217.42it/s, loss=0.624, v_num=cba1]\n",
      "Epoch 5:  71%|███████   | 11970/16955 [00:54<00:22, 218.70it/s, loss=0.624, v_num=cba1]\n",
      "Epoch 5:  71%|███████   | 12065/16955 [00:54<00:22, 219.99it/s, loss=0.624, v_num=cba1]\n",
      "Epoch 5:  72%|███████▏  | 12160/16955 [00:54<00:21, 221.27it/s, loss=0.624, v_num=cba1]\n",
      "Epoch 5:  72%|███████▏  | 12255/16955 [00:55<00:21, 222.57it/s, loss=0.624, v_num=cba1]\n",
      "Epoch 5:  73%|███████▎  | 12350/16955 [00:55<00:20, 223.85it/s, loss=0.624, v_num=cba1]\n",
      "Epoch 5:  73%|███████▎  | 12445/16955 [00:55<00:20, 225.12it/s, loss=0.624, v_num=cba1]\n",
      "Epoch 5:  74%|███████▍  | 12540/16955 [00:55<00:19, 226.39it/s, loss=0.624, v_num=cba1]\n",
      "Epoch 5:  75%|███████▍  | 12635/16955 [00:55<00:18, 227.64it/s, loss=0.624, v_num=cba1]\n",
      "Validating:  15%|█▌        | 773/5087 [00:03<06:43, 10.70it/s]\u001b[A\n",
      "Epoch 5:  75%|███████▌  | 12730/16955 [00:55<00:18, 228.87it/s, loss=0.624, v_num=cba1]\n",
      "Epoch 5:  76%|███████▌  | 12825/16955 [00:55<00:17, 230.13it/s, loss=0.624, v_num=cba1]\n",
      "Epoch 5:  76%|███████▌  | 12920/16955 [00:55<00:17, 231.37it/s, loss=0.624, v_num=cba1]\n",
      "Epoch 5:  77%|███████▋  | 13015/16955 [00:55<00:16, 232.62it/s, loss=0.624, v_num=cba1]\n",
      "Epoch 5:  77%|███████▋  | 13110/16955 [00:56<00:16, 233.86it/s, loss=0.624, v_num=cba1]\n",
      "Epoch 5:  78%|███████▊  | 13205/16955 [00:56<00:15, 235.10it/s, loss=0.624, v_num=cba1]\n",
      "Epoch 5:  78%|███████▊  | 13300/16955 [00:56<00:15, 236.28it/s, loss=0.624, v_num=cba1]\n",
      "Epoch 5:  79%|███████▉  | 13395/16955 [00:56<00:14, 237.48it/s, loss=0.624, v_num=cba1]\n",
      "Epoch 5:  80%|███████▉  | 13490/16955 [00:56<00:14, 238.67it/s, loss=0.624, v_num=cba1]\n",
      "Validating:  32%|███▏      | 1632/5087 [00:04<00:13, 261.84it/s]\u001b[A\n",
      "Epoch 5:  80%|████████  | 13585/16955 [00:56<00:14, 239.83it/s, loss=0.624, v_num=cba1]\n",
      "Epoch 5:  81%|████████  | 13680/16955 [00:56<00:13, 241.00it/s, loss=0.624, v_num=cba1]\n",
      "Epoch 5:  81%|████████  | 13775/16955 [00:56<00:13, 242.20it/s, loss=0.624, v_num=cba1]\n",
      "Epoch 5:  82%|████████▏ | 13870/16955 [00:56<00:12, 243.39it/s, loss=0.624, v_num=cba1]\n",
      "Epoch 5:  82%|████████▏ | 13965/16955 [00:57<00:12, 244.59it/s, loss=0.624, v_num=cba1]\n",
      "Epoch 5:  83%|████████▎ | 14060/16955 [00:57<00:11, 245.79it/s, loss=0.624, v_num=cba1]\n",
      "Epoch 5:  83%|████████▎ | 14155/16955 [00:57<00:11, 246.99it/s, loss=0.624, v_num=cba1]\n",
      "Epoch 5:  84%|████████▍ | 14250/16955 [00:57<00:10, 248.16it/s, loss=0.624, v_num=cba1]\n",
      "Epoch 5:  85%|████████▍ | 14345/16955 [00:57<00:10, 249.32it/s, loss=0.624, v_num=cba1]\n",
      "Epoch 5:  85%|████████▌ | 14440/16955 [00:57<00:10, 250.46it/s, loss=0.624, v_num=cba1]\n",
      "Validating:  51%|█████     | 2575/5087 [00:05<00:03, 796.91it/s]\u001b[A\n",
      "Epoch 5:  86%|████████▌ | 14535/16955 [00:57<00:09, 251.57it/s, loss=0.624, v_num=cba1]\n",
      "Epoch 5:  86%|████████▋ | 14630/16955 [00:57<00:09, 252.69it/s, loss=0.624, v_num=cba1]\n",
      "Epoch 5:  87%|████████▋ | 14725/16955 [00:58<00:08, 253.81it/s, loss=0.624, v_num=cba1]\n",
      "Epoch 5:  87%|████████▋ | 14820/16955 [00:58<00:08, 254.95it/s, loss=0.624, v_num=cba1]\n",
      "Epoch 5:  88%|████████▊ | 14915/16955 [00:58<00:07, 256.11it/s, loss=0.624, v_num=cba1]\n",
      "Epoch 5:  89%|████████▊ | 15010/16955 [00:58<00:07, 257.26it/s, loss=0.624, v_num=cba1]\n",
      "Epoch 5:  89%|████████▉ | 15105/16955 [00:58<00:07, 258.41it/s, loss=0.624, v_num=cba1]\n",
      "Epoch 5:  90%|████████▉ | 15200/16955 [00:58<00:06, 259.53it/s, loss=0.624, v_num=cba1]\n",
      "Validating:  66%|██████▌   | 3341/5087 [00:06<00:02, 843.07it/s]\u001b[A\n",
      "Epoch 5:  90%|█████████ | 15295/16955 [00:58<00:06, 260.63it/s, loss=0.624, v_num=cba1]\n",
      "Epoch 5:  91%|█████████ | 15390/16955 [00:58<00:05, 261.73it/s, loss=0.624, v_num=cba1]\n",
      "Epoch 5:  91%|█████████▏| 15485/16955 [00:58<00:05, 262.85it/s, loss=0.624, v_num=cba1]\n",
      "Epoch 5:  92%|█████████▏| 15580/16955 [00:59<00:05, 263.96it/s, loss=0.624, v_num=cba1]\n",
      "Epoch 5:  92%|█████████▏| 15675/16955 [00:59<00:04, 265.06it/s, loss=0.624, v_num=cba1]\n",
      "Epoch 5:  93%|█████████▎| 15770/16955 [00:59<00:04, 266.15it/s, loss=0.624, v_num=cba1]\n",
      "Epoch 5:  94%|█████████▎| 15865/16955 [00:59<00:04, 267.26it/s, loss=0.624, v_num=cba1]\n",
      "Epoch 5:  94%|█████████▍| 15960/16955 [00:59<00:03, 268.35it/s, loss=0.624, v_num=cba1]\n",
      "Epoch 5:  95%|█████████▍| 16055/16955 [00:59<00:03, 269.46it/s, loss=0.624, v_num=cba1]\n",
      "Epoch 5:  95%|█████████▌| 16150/16955 [00:59<00:02, 270.52it/s, loss=0.624, v_num=cba1]\n",
      "Validating:  84%|████████▍ | 4285/5087 [00:07<00:00, 832.69it/s]\u001b[A\n",
      "Epoch 5:  96%|█████████▌| 16245/16955 [00:59<00:02, 271.58it/s, loss=0.624, v_num=cba1]\n",
      "Epoch 5:  96%|█████████▋| 16340/16955 [00:59<00:02, 272.63it/s, loss=0.624, v_num=cba1]\n",
      "Epoch 5:  97%|█████████▋| 16435/16955 [01:00<00:01, 273.67it/s, loss=0.624, v_num=cba1]\n",
      "Epoch 5:  97%|█████████▋| 16530/16955 [01:00<00:01, 274.72it/s, loss=0.624, v_num=cba1]\n",
      "Epoch 5:  98%|█████████▊| 16625/16955 [01:00<00:01, 275.75it/s, loss=0.624, v_num=cba1]\n",
      "Epoch 5:  99%|█████████▊| 16720/16955 [01:00<00:00, 276.82it/s, loss=0.624, v_num=cba1]\n",
      "Epoch 5:  99%|█████████▉| 16815/16955 [01:00<00:00, 277.89it/s, loss=0.624, v_num=cba1]\n",
      "Epoch 5: 100%|█████████▉| 16910/16955 [01:00<00:00, 278.93it/s, loss=0.624, v_num=cba1]\n",
      "Validating:  99%|█████████▉| 5043/5087 [00:08<00:00, 825.85it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: avg_val_loss reached 0.62406 (best 0.62406), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v2.ckpt as top 1\n",
      "INFO:lightning:Epoch 5: avg_val_loss reached 0.62406 (best 0.62406), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v2.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 16955/16955 [01:01<00:00, 277.53it/s, loss=0.624, v_num=cba1]\n",
      "Epoch 5: 100%|██████████| 16955/16955 [01:01<00:00, 274.40it/s, loss=0.624, v_num=cba1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: ----------------------------------\n",
      "COMET INFO: Comet.ml OfflineExperiment Summary\n",
      "COMET INFO: ----------------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : [OfflineExperiment will get URL after upload]\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     avg_train_loss [6] : (0.6114363074302673, 0.637794554233551)\n",
      "COMET INFO:     avg_val_loss [6]   : (0.6240603923797607, 0.6346268653869629)\n",
      "COMET INFO:   Others:\n",
      "COMET INFO:     offline_experiment : True\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     device           : cuda\n",
      "COMET INFO:     logger           : <pytorch_lightning.loggers.comet.CometLogger object at 0x7ff0047cfa50>\n",
      "COMET INFO:     lr               : 0.001\n",
      "COMET INFO:     max_epochs       : 30\n",
      "COMET INFO:     num_warmup_steps : 2000\n",
      "COMET INFO:     num_workers      : 12\n",
      "COMET INFO:     pin_memory       : True\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     code                     : 1 (4 KB)\n",
      "COMET INFO:     environment details      : 1\n",
      "COMET INFO:     filename                 : 1\n",
      "COMET INFO:     git metadata             : 1\n",
      "COMET INFO:     git-patch (uncompressed) : 1 (78 KB)\n",
      "COMET INFO:     installed packages       : 1\n",
      "COMET INFO:     notebook                 : 1\n",
      "COMET INFO:     os packages              : 1\n",
      "COMET INFO: ----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Starting saving the offline archive\n",
      "COMET INFO: To upload this offline experiment, run:\n",
      "    comet upload logs/f304a24d2a8845ac8be91257f62ecba1.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 56s, sys: 1min 19s, total: 7min 16s\n",
      "Wall time: 6min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the best model from checkpoint and see quite a good performance. The model is able to predict blogger's gender quite successfuly. All metrics are above 60%, F1 score is apx. 65%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EarlyStopping mode set to min for monitoring avg_val_loss.\n"
     ]
    }
   ],
   "source": [
    "gender_model = Model.load_from_checkpoint(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, hparams=hparams,\\\n",
    "                                   checkpoint_path=\"./checkpoints/model-outputs-v2.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (net): Net(\n",
       "    (fc1): Linear(in_features=768, out_features=128, bias=True)\n",
       "    (fc2): Linear(in_features=128, out_features=2, bias=True)\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (loss_func): CrossEntropyLoss()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4239/4239 [00:03<00:00, 1100.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.636     0.675     0.655     66934\n",
      "           1      0.663     0.624     0.643     68699\n",
      "\n",
      "    accuracy                          0.649    135633\n",
      "   macro avg      0.650     0.649     0.649    135633\n",
      "weighted avg      0.650     0.649     0.649    135633\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = gender_model.predict_eval(X_test , y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sign model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's proceed with more challenging model. Multiclass classification task - sign prediciton. As previously, classes are well balanced. Let's create label mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_class2idx = {k: v for v, k in enumerate(sorted(df2['sign'].unique()))}\n",
    "sign_idx2class = {v: k for k, v in sign_class2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Aquarius': 0,\n",
       " 'Aries': 1,\n",
       " 'Cancer': 2,\n",
       " 'Capricorn': 3,\n",
       " 'Gemini': 4,\n",
       " 'Leo': 5,\n",
       " 'Libra': 6,\n",
       " 'Pisces': 7,\n",
       " 'Sagittarius': 8,\n",
       " 'Scorpio': 9,\n",
       " 'Taurus': 10,\n",
       " 'Virgo': 11}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sign_class2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['sign'] = df2['sign'].map(sign_class2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exactly the same stratified samples splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2['vectors'].values\n",
    "y = df2['sign'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=17)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.3, stratify=y_trainval, random_state=43)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check and overfitting on small subsample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'fast_dev_run': True,\n",
    "    'pin_memory': True,\n",
    "    'device': device,\n",
    "    'num_workers': 12,\n",
    "    'shuffle': False,\n",
    "    'batch_size': 32,\n",
    "    'logger': comet_logger\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EarlyStopping mode set to min for monitoring avg_val_loss.\n"
     ]
    }
   ],
   "source": [
    "model = Model(X_train, y_train, X_val, y_val, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Running in fast_dev_run mode: will run a full train, val and test loop using a single batch\n",
      "\n",
      "  | Name | Type | Params \n",
      "-------------------------------\n",
      "0 | net  | Net  | 100.0 K\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|█████     | 1/2 [00:01<00:01,  1.29s/it, loss=2.513, v_num=c394]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating: 100%|██████████| 1/1 [00:01<00:00,  1.37s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: avg_val_loss reached 2.46879 (best 2.46879), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v1.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 2/2 [00:02<00:00,  1.45s/it, loss=2.513, v_num=c394]\n",
      "Epoch 0: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it, loss=2.513, v_num=c394]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: ----------------------------------\n",
      "COMET INFO: Comet.ml OfflineExperiment Summary\n",
      "COMET INFO: ----------------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : [OfflineExperiment will get URL after upload]\n",
      "COMET INFO:   Metrics:\n",
      "COMET INFO:     avg_train_loss : 2.5129876136779785\n",
      "COMET INFO:     avg_val_loss   : 2.4687867164611816\n",
      "COMET INFO:   Others:\n",
      "COMET INFO:     offline_experiment : True\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     batch_size   : 32\n",
      "COMET INFO:     device       : cuda\n",
      "COMET INFO:     fast_dev_run : True\n",
      "COMET INFO:     logger       : <pytorch_lightning.loggers.comet.CometLogger object at 0x7fccf8f29e10>\n",
      "COMET INFO:     num_workers  : 12\n",
      "COMET INFO:     pin_memory   : True\n",
      "COMET INFO:     shuffle      : 1\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     code                     : 1 (4 KB)\n",
      "COMET INFO:     environment details      : 1\n",
      "COMET INFO:     filename                 : 1\n",
      "COMET INFO:     git metadata             : 1\n",
      "COMET INFO:     git-patch (uncompressed) : 1 (189 KB)\n",
      "COMET INFO:     installed packages       : 1\n",
      "COMET INFO:     notebook                 : 1\n",
      "COMET INFO:     os packages              : 1\n",
      "COMET INFO: ----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Saving offline stats to disk before program termination (may take several seconds)\n",
      "COMET INFO: Starting saving the offline archive\n",
      "COMET INFO: To upload this offline experiment, run:\n",
      "    comet upload logs/e92c34b9d1da4e789aefb832f6b3c394.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 153 ms, sys: 2.86 s, total: 3.01 s\n",
      "Wall time: 4.65 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'overfit_batches': 1e-3,\n",
    "    'num_warmup_steps': 0,\n",
    "    'pin_memory': True,\n",
    "    'device': device,\n",
    "    'num_workers': 12,\n",
    "    'max_epochs': 40,\n",
    "    'lr': 1e-3,\n",
    "    'logger': comet_logger,\n",
    "    'shuffle': False # it's important not to shuffle training samples\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EarlyStopping mode set to min for monitoring avg_val_loss.\n"
     ]
    }
   ],
   "source": [
    "model = Model(X_train, y_train, X_val, y_val, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type | Params \n",
      "-------------------------------\n",
      "0 | net  | Net  | 100.0 K\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|█████     | 11/22 [00:01<00:01,  8.42it/s, loss=2.501, v_num=8b64]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  59%|█████▉    | 13/22 [00:02<00:01,  4.81it/s, loss=2.501, v_num=8b64]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: avg_val_loss reached 2.26077 (best 2.26077), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v3.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 22/22 [00:02<00:00,  7.43it/s, loss=2.501, v_num=8b64]\n",
      "Epoch 1:  55%|█████▍    | 12/22 [00:01<00:01,  8.93it/s, loss=2.336, v_num=8b64]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:13,  1.34s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: avg_val_loss reached 2.04526 (best 2.04526), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v4.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 22/22 [00:02<00:00,  7.41it/s, loss=2.336, v_num=8b64]\n",
      "Epoch 2:  55%|█████▍    | 12/22 [00:01<00:01,  8.75it/s, loss=2.097, v_num=8b64]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:12,  1.26s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: avg_val_loss reached 1.84470 (best 1.84470), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v3.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 22/22 [00:02<00:00,  7.55it/s, loss=2.097, v_num=8b64]\n",
      "Epoch 3:  55%|█████▍    | 12/22 [00:01<00:00, 10.48it/s, loss=1.896, v_num=8b64]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:13,  1.33s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: avg_val_loss reached 1.65575 (best 1.65575), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v4.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 22/22 [00:02<00:00,  7.97it/s, loss=1.896, v_num=8b64]\n",
      "Epoch 4:  55%|█████▍    | 12/22 [00:01<00:01,  8.84it/s, loss=1.707, v_num=8b64]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:13,  1.34s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: avg_val_loss reached 1.47650 (best 1.47650), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v3.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 22/22 [00:02<00:00,  7.41it/s, loss=1.707, v_num=8b64]\n",
      "Epoch 5:  55%|█████▍    | 12/22 [00:01<00:01,  8.56it/s, loss=1.528, v_num=8b64]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:12,  1.28s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: avg_val_loss reached 1.30708 (best 1.30708), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v4.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 22/22 [00:03<00:00,  7.32it/s, loss=1.528, v_num=8b64]\n",
      "Epoch 6:  55%|█████▍    | 12/22 [00:01<00:01,  7.77it/s, loss=1.358, v_num=8b64]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:15,  1.51s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: avg_val_loss reached 1.14775 (best 1.14775), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v3.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 22/22 [00:03<00:00,  6.58it/s, loss=1.358, v_num=8b64]\n",
      "Epoch 7:  55%|█████▍    | 12/22 [00:01<00:01,  8.43it/s, loss=1.199, v_num=8b64]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:13,  1.31s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: avg_val_loss reached 0.99997 (best 0.99997), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v4.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 22/22 [00:03<00:00,  7.32it/s, loss=1.199, v_num=8b64]\n",
      "Epoch 8:  55%|█████▍    | 12/22 [00:01<00:01,  8.03it/s, loss=1.050, v_num=8b64]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:14,  1.43s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: avg_val_loss reached 0.86352 (best 0.86352), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v3.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 22/22 [00:03<00:00,  6.88it/s, loss=1.050, v_num=8b64]\n",
      "Epoch 9:  55%|█████▍    | 12/22 [00:01<00:01,  9.25it/s, loss=0.912, v_num=8b64]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:15,  1.60s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: avg_val_loss reached 0.73956 (best 0.73956), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v4.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 22/22 [00:03<00:00,  6.96it/s, loss=0.912, v_num=8b64]\n",
      "Epoch 10:  55%|█████▍    | 12/22 [00:01<00:01,  9.12it/s, loss=0.786, v_num=8b64]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:11,  1.17s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: avg_val_loss reached 0.62882 (best 0.62882), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v3.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 22/22 [00:02<00:00,  7.97it/s, loss=0.786, v_num=8b64]\n",
      "Epoch 11:  55%|█████▍    | 12/22 [00:01<00:00, 10.02it/s, loss=0.672, v_num=8b64]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:11,  1.20s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: avg_val_loss reached 0.53151 (best 0.53151), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v4.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 22/22 [00:02<00:00,  8.26it/s, loss=0.672, v_num=8b64]\n",
      "Epoch 12:  55%|█████▍    | 12/22 [00:01<00:01,  9.01it/s, loss=0.570, v_num=8b64]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:11,  1.19s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: avg_val_loss reached 0.44676 (best 0.44676), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v3.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 22/22 [00:02<00:00,  7.86it/s, loss=0.570, v_num=8b64]\n",
      "Epoch 13:  55%|█████▍    | 12/22 [00:01<00:01,  8.55it/s, loss=0.481, v_num=8b64]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:15,  1.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: avg_val_loss reached 0.37490 (best 0.37490), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v4.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 22/22 [00:03<00:00,  6.84it/s, loss=0.481, v_num=8b64]\n",
      "Epoch 14:  55%|█████▍    | 12/22 [00:01<00:01,  7.71it/s, loss=0.404, v_num=8b64]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:13,  1.32s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: avg_val_loss reached 0.31447 (best 0.31447), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v3.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 22/22 [00:03<00:00,  6.95it/s, loss=0.404, v_num=8b64]\n",
      "Epoch 15:  55%|█████▍    | 12/22 [00:01<00:01,  8.41it/s, loss=0.339, v_num=8b64]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:14,  1.46s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: avg_val_loss reached 0.26438 (best 0.26438), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v4.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 22/22 [00:03<00:00,  6.96it/s, loss=0.339, v_num=8b64]\n",
      "Epoch 16:  55%|█████▍    | 12/22 [00:01<00:01,  9.24it/s, loss=0.285, v_num=8b64]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:14,  1.47s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: avg_val_loss reached 0.22428 (best 0.22428), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v3.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 22/22 [00:03<00:00,  7.22it/s, loss=0.285, v_num=8b64]\n",
      "Epoch 17:  55%|█████▍    | 12/22 [00:01<00:01,  9.92it/s, loss=0.241, v_num=8b64]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:13,  1.37s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: avg_val_loss reached 0.19147 (best 0.19147), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v4.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 22/22 [00:02<00:00,  7.72it/s, loss=0.241, v_num=8b64]\n",
      "Epoch 18:  55%|█████▍    | 12/22 [00:01<00:01,  8.95it/s, loss=0.205, v_num=8b64]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:11,  1.16s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: avg_val_loss reached 0.16570 (best 0.16570), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v3.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 22/22 [00:02<00:00,  7.88it/s, loss=0.205, v_num=8b64]\n",
      "Epoch 19:  55%|█████▍    | 12/22 [00:01<00:01,  9.64it/s, loss=0.176, v_num=8b64]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:12,  1.26s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: avg_val_loss reached 0.14479 (best 0.14479), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v4.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 22/22 [00:02<00:00,  7.90it/s, loss=0.176, v_num=8b64]\n",
      "Epoch 20:  55%|█████▍    | 12/22 [00:01<00:01,  8.05it/s, loss=0.153, v_num=8b64]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:11,  1.19s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: avg_val_loss reached 0.12832 (best 0.12832), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v3.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 22/22 [00:02<00:00,  7.47it/s, loss=0.153, v_num=8b64]\n",
      "Epoch 21:  55%|█████▍    | 12/22 [00:01<00:01,  9.95it/s, loss=0.135, v_num=8b64]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:14,  1.46s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: avg_val_loss reached 0.11493 (best 0.11493), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v4.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 22/22 [00:02<00:00,  7.50it/s, loss=0.135, v_num=8b64]\n",
      "Epoch 22:  55%|█████▍    | 12/22 [00:01<00:01,  7.99it/s, loss=0.120, v_num=8b64]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:13,  1.33s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: avg_val_loss reached 0.10431 (best 0.10431), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v3.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 22/22 [00:03<00:00,  7.08it/s, loss=0.120, v_num=8b64]\n",
      "Epoch 23:  55%|█████▍    | 12/22 [00:01<00:01,  8.61it/s, loss=0.108, v_num=8b64]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:13,  1.35s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: avg_val_loss reached 0.09566 (best 0.09566), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v4.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 22/22 [00:03<00:00,  7.29it/s, loss=0.108, v_num=8b64]\n",
      "Epoch 24:  55%|█████▍    | 12/22 [00:01<00:01,  9.11it/s, loss=0.099, v_num=8b64]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:13,  1.35s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: avg_val_loss reached 0.08865 (best 0.08865), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v3.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 22/22 [00:02<00:00,  7.45it/s, loss=0.099, v_num=8b64]\n",
      "Epoch 25:  55%|█████▍    | 12/22 [00:01<00:01,  8.74it/s, loss=0.091, v_num=8b64]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:14,  1.45s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: avg_val_loss reached 0.08302 (best 0.08302), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v4.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 22/22 [00:03<00:00,  7.10it/s, loss=0.091, v_num=8b64]\n",
      "Epoch 26:  55%|█████▍    | 12/22 [00:01<00:01,  9.79it/s, loss=0.085, v_num=8b64]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: avg_val_loss reached 0.07848 (best 0.07848), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v3.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 22/22 [00:03<00:00,  6.87it/s, loss=0.085, v_num=8b64]\n",
      "Epoch 27:  55%|█████▍    | 12/22 [00:01<00:01,  7.96it/s, loss=0.080, v_num=8b64]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:13,  1.38s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: avg_val_loss reached 0.07485 (best 0.07485), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v4.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 22/22 [00:03<00:00,  6.97it/s, loss=0.080, v_num=8b64]\n",
      "Epoch 28:  55%|█████▍    | 12/22 [00:01<00:01,  8.54it/s, loss=0.076, v_num=8b64]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:12,  1.24s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: avg_val_loss reached 0.07193 (best 0.07193), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v3.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 22/22 [00:02<00:00,  7.55it/s, loss=0.076, v_num=8b64]\n",
      "Epoch 29:  55%|█████▍    | 12/22 [00:01<00:01,  7.79it/s, loss=0.073, v_num=8b64]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:13,  1.34s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: avg_val_loss reached 0.06959 (best 0.06959), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v4.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 22/22 [00:03<00:00,  6.97it/s, loss=0.073, v_num=8b64]\n",
      "Epoch 30:  55%|█████▍    | 12/22 [00:01<00:01,  8.20it/s, loss=0.071, v_num=8b64]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:13,  1.31s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: avg_val_loss reached 0.06772 (best 0.06772), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v3.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 22/22 [00:03<00:00,  7.19it/s, loss=0.071, v_num=8b64]\n",
      "Epoch 31:  55%|█████▍    | 12/22 [00:01<00:01,  9.42it/s, loss=0.069, v_num=8b64]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:12,  1.30s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: avg_val_loss reached 0.06625 (best 0.06625), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v4.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 22/22 [00:02<00:00,  7.78it/s, loss=0.069, v_num=8b64]\n",
      "Epoch 32:  55%|█████▍    | 12/22 [00:01<00:01,  8.03it/s, loss=0.067, v_num=8b64]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:12,  1.24s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: avg_val_loss reached 0.06510 (best 0.06510), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v3.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 22/22 [00:03<00:00,  7.32it/s, loss=0.067, v_num=8b64]\n",
      "Epoch 33:  55%|█████▍    | 12/22 [00:01<00:01,  7.40it/s, loss=0.066, v_num=8b64]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:15,  1.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: avg_val_loss reached 0.06424 (best 0.06424), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v4.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 22/22 [00:03<00:00,  6.44it/s, loss=0.066, v_num=8b64]\n",
      "Epoch 34:  55%|█████▍    | 12/22 [00:01<00:01,  8.56it/s, loss=0.065, v_num=8b64]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:14,  1.44s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: avg_val_loss reached 0.06360 (best 0.06360), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v3.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 22/22 [00:03<00:00,  7.05it/s, loss=0.065, v_num=8b64]\n",
      "Epoch 35:  55%|█████▍    | 12/22 [00:01<00:01,  9.42it/s, loss=0.064, v_num=8b64]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:14,  1.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: avg_val_loss reached 0.06316 (best 0.06316), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v4.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 22/22 [00:03<00:00,  7.24it/s, loss=0.064, v_num=8b64]\n",
      "Epoch 36:  55%|█████▍    | 12/22 [00:01<00:01,  8.90it/s, loss=0.064, v_num=8b64]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:11,  1.16s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: avg_val_loss reached 0.06288 (best 0.06288), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v3.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 22/22 [00:02<00:00,  7.92it/s, loss=0.064, v_num=8b64]\n",
      "Epoch 37:  55%|█████▍    | 12/22 [00:01<00:01,  9.46it/s, loss=0.063, v_num=8b64]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   9%|▉         | 1/11 [00:01<00:14,  1.46s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: avg_val_loss reached 0.06271 (best 0.06271), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v4.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 22/22 [00:03<00:00,  7.22it/s, loss=0.063, v_num=8b64]\n",
      "Epoch 37: 100%|██████████| 22/22 [00:03<00:00,  6.68it/s, loss=0.063, v_num=8b64]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: ----------------------------------\n",
      "COMET INFO: Comet.ml OfflineExperiment Summary\n",
      "COMET INFO: ----------------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : [OfflineExperiment will get URL after upload]\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     avg_train_loss [38] : (0.06283894926309586, 2.500877857208252)\n",
      "COMET INFO:     avg_val_loss [38]   : (0.0627129077911377, 2.2607719898223877)\n",
      "COMET INFO:   Others:\n",
      "COMET INFO:     offline_experiment : True\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     device           : cuda\n",
      "COMET INFO:     logger           : <pytorch_lightning.loggers.comet.CometLogger object at 0x7fcccc594490>\n",
      "COMET INFO:     lr               : 0.001\n",
      "COMET INFO:     max_epochs       : 40\n",
      "COMET INFO:     num_warmup_steps : 1\n",
      "COMET INFO:     num_workers      : 12\n",
      "COMET INFO:     overfit_batches  : 0.001\n",
      "COMET INFO:     pin_memory       : True\n",
      "COMET INFO:     shuffle          : 1\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     code                     : 1 (4 KB)\n",
      "COMET INFO:     environment details      : 1\n",
      "COMET INFO:     filename                 : 1\n",
      "COMET INFO:     git metadata             : 1\n",
      "COMET INFO:     git-patch (uncompressed) : 1 (189 KB)\n",
      "COMET INFO:     installed packages       : 1\n",
      "COMET INFO:     notebook                 : 1\n",
      "COMET INFO:     os packages              : 1\n",
      "COMET INFO: ----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Starting saving the offline archive\n",
      "COMET INFO: To upload this offline experiment, run:\n",
      "    comet upload logs/38719e5890a149899e4329f225288b64.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.28 s, sys: 1min 48s, total: 1min 54s\n",
      "Wall time: 2min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add a dropout this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'pin_memory': True,\n",
    "    'device': device,\n",
    "    'num_workers': 12,\n",
    "    'logger': comet_logger,\n",
    "    'max_epochs': 30,\n",
    "    'lr': 1e-3,\n",
    "    'num_warmup_steps': 2000,\n",
    "    'dropout': 0.2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EarlyStopping mode set to min for monitoring avg_val_loss.\n"
     ]
    }
   ],
   "source": [
    "model = Model(X_train, y_train, X_val, y_val, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (net): Net(\n",
       "    (fc1): Linear(in_features=768, out_features=128, bias=True)\n",
       "    (fc2): Linear(in_features=128, out_features=12, bias=True)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "    (loss_func): CrossEntropyLoss()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trditionally checking metrics before learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4239/4239 [00:04<00:00, 1054.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.076     0.018     0.029      9893\n",
      "           1      0.096     0.116     0.105     12961\n",
      "           2      0.097     0.082     0.089     12949\n",
      "           3      0.060     0.006     0.011      9801\n",
      "           4      0.076     0.343     0.125     10344\n",
      "           5      0.072     0.015     0.025     10708\n",
      "           6      0.107     0.001     0.002     12412\n",
      "           7      0.079     0.296     0.125     10757\n",
      "           8      0.095     0.001     0.002      9963\n",
      "           9      0.119     0.001     0.001     11370\n",
      "          10      0.090     0.002     0.004     12453\n",
      "          11      0.090     0.121     0.103     12022\n",
      "\n",
      "    accuracy                          0.083    135633\n",
      "   macro avg      0.088     0.084     0.052    135633\n",
      "weighted avg      0.089     0.083     0.053    135633\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict_eval(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type | Params \n",
      "-------------------------------\n",
      "0 | net  | Net  | 100.0 K\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  70%|██████▉   | 11868/16955 [00:52<00:22, 225.79it/s, loss=2.480, v_num=5073]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  70%|███████   | 11880/16955 [00:53<00:23, 220.41it/s, loss=2.480, v_num=5073]\n",
      "Epoch 0:  71%|███████   | 11980/16955 [00:53<00:22, 221.85it/s, loss=2.480, v_num=5073]\n",
      "Epoch 0:  71%|███████   | 12080/16955 [00:54<00:21, 223.21it/s, loss=2.480, v_num=5073]\n",
      "Epoch 0:  72%|███████▏  | 12180/16955 [00:54<00:21, 224.55it/s, loss=2.480, v_num=5073]\n",
      "Validating:   6%|▋         | 328/5087 [00:01<24:44,  3.21it/s]\u001b[A\n",
      "Epoch 0:  72%|███████▏  | 12280/16955 [00:54<00:20, 225.86it/s, loss=2.480, v_num=5073]\n",
      "Epoch 0:  73%|███████▎  | 12380/16955 [00:54<00:20, 227.18it/s, loss=2.480, v_num=5073]\n",
      "Epoch 0:  74%|███████▎  | 12480/16955 [00:54<00:19, 228.50it/s, loss=2.480, v_num=5073]\n",
      "Epoch 0:  74%|███████▍  | 12580/16955 [00:54<00:19, 229.81it/s, loss=2.480, v_num=5073]\n",
      "Validating:  14%|█▍        | 729/5087 [00:02<03:53, 18.70it/s]\u001b[A\n",
      "Epoch 0:  75%|███████▍  | 12680/16955 [00:54<00:18, 231.10it/s, loss=2.480, v_num=5073]\n",
      "Epoch 0:  75%|███████▌  | 12780/16955 [00:54<00:17, 232.39it/s, loss=2.480, v_num=5073]\n",
      "Epoch 0:  76%|███████▌  | 12880/16955 [00:55<00:17, 233.73it/s, loss=2.480, v_num=5073]\n",
      "Epoch 0:  77%|███████▋  | 12980/16955 [00:55<00:16, 235.06it/s, loss=2.480, v_num=5073]\n",
      "Epoch 0:  77%|███████▋  | 13080/16955 [00:55<00:16, 236.35it/s, loss=2.480, v_num=5073]\n",
      "Epoch 0:  78%|███████▊  | 13180/16955 [00:55<00:15, 237.65it/s, loss=2.480, v_num=5073]\n",
      "Validating:  26%|██▌       | 1324/5087 [00:02<00:20, 181.99it/s]\u001b[A\n",
      "Epoch 0:  78%|███████▊  | 13280/16955 [00:55<00:15, 238.93it/s, loss=2.480, v_num=5073]\n",
      "Epoch 0:  79%|███████▉  | 13380/16955 [00:55<00:14, 240.22it/s, loss=2.480, v_num=5073]\n",
      "Epoch 0:  80%|███████▉  | 13480/16955 [00:55<00:14, 241.53it/s, loss=2.480, v_num=5073]\n",
      "Epoch 0:  80%|████████  | 13580/16955 [00:55<00:13, 242.80it/s, loss=2.480, v_num=5073]\n",
      "Epoch 0:  81%|████████  | 13680/16955 [00:56<00:13, 244.07it/s, loss=2.480, v_num=5073]\n",
      "Epoch 0:  81%|████████▏ | 13780/16955 [00:56<00:12, 245.34it/s, loss=2.480, v_num=5073]\n",
      "Epoch 0:  82%|████████▏ | 13880/16955 [00:56<00:12, 246.62it/s, loss=2.480, v_num=5073]\n",
      "Validating:  40%|███▉      | 2013/5087 [00:03<00:04, 704.14it/s]\u001b[A\n",
      "Epoch 0:  82%|████████▏ | 13980/16955 [00:56<00:12, 247.87it/s, loss=2.480, v_num=5073]\n",
      "Epoch 0:  83%|████████▎ | 14080/16955 [00:56<00:11, 249.13it/s, loss=2.480, v_num=5073]\n",
      "Epoch 0:  84%|████████▎ | 14180/16955 [00:56<00:11, 250.38it/s, loss=2.480, v_num=5073]\n",
      "Epoch 0:  84%|████████▍ | 14280/16955 [00:56<00:10, 251.64it/s, loss=2.480, v_num=5073]\n",
      "Epoch 0:  85%|████████▍ | 14380/16955 [00:56<00:10, 252.87it/s, loss=2.480, v_num=5073]\n",
      "Epoch 0:  85%|████████▌ | 14480/16955 [00:56<00:09, 254.08it/s, loss=2.480, v_num=5073]\n",
      "Validating:  51%|█████▏    | 2618/5087 [00:04<00:02, 823.31it/s]\u001b[A\n",
      "Epoch 0:  86%|████████▌ | 14580/16955 [00:57<00:09, 255.29it/s, loss=2.480, v_num=5073]\n",
      "Epoch 0:  87%|████████▋ | 14680/16955 [00:57<00:08, 256.52it/s, loss=2.480, v_num=5073]\n",
      "Epoch 0:  87%|████████▋ | 14780/16955 [00:57<00:08, 257.73it/s, loss=2.480, v_num=5073]\n",
      "Epoch 0:  88%|████████▊ | 14880/16955 [00:57<00:08, 258.92it/s, loss=2.480, v_num=5073]\n",
      "Epoch 0:  88%|████████▊ | 14980/16955 [00:57<00:07, 260.12it/s, loss=2.480, v_num=5073]\n",
      "Epoch 0:  89%|████████▉ | 15080/16955 [00:57<00:07, 261.32it/s, loss=2.480, v_num=5073]\n",
      "Validating:  63%|██████▎   | 3212/5087 [00:05<00:02, 832.68it/s]\u001b[A\n",
      "Epoch 0:  90%|████████▉ | 15180/16955 [00:57<00:06, 262.51it/s, loss=2.480, v_num=5073]\n",
      "Epoch 0:  90%|█████████ | 15280/16955 [00:57<00:06, 263.71it/s, loss=2.480, v_num=5073]\n",
      "Epoch 0:  91%|█████████ | 15380/16955 [00:58<00:05, 264.88it/s, loss=2.480, v_num=5073]\n",
      "Epoch 0:  91%|█████████▏| 15480/16955 [00:58<00:05, 266.02it/s, loss=2.480, v_num=5073]\n",
      "Epoch 0:  92%|█████████▏| 15580/16955 [00:58<00:05, 267.19it/s, loss=2.480, v_num=5073]\n",
      "Validating:  73%|███████▎  | 3722/5087 [00:05<00:01, 822.53it/s]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 15680/16955 [00:58<00:04, 268.34it/s, loss=2.480, v_num=5073]\n",
      "Epoch 0:  93%|█████████▎| 15780/16955 [00:58<00:04, 269.48it/s, loss=2.480, v_num=5073]\n",
      "Epoch 0:  94%|█████████▎| 15880/16955 [00:58<00:03, 270.60it/s, loss=2.480, v_num=5073]\n",
      "Epoch 0:  94%|█████████▍| 15980/16955 [00:58<00:03, 271.72it/s, loss=2.480, v_num=5073]\n",
      "Epoch 0:  95%|█████████▍| 16080/16955 [00:58<00:03, 272.82it/s, loss=2.480, v_num=5073]\n",
      "Validating:  83%|████████▎ | 4215/5087 [00:06<00:01, 785.17it/s]\u001b[A\n",
      "Epoch 0:  95%|█████████▌| 16180/16955 [00:59<00:02, 273.86it/s, loss=2.480, v_num=5073]\n",
      "Epoch 0:  96%|█████████▌| 16280/16955 [00:59<00:02, 275.01it/s, loss=2.480, v_num=5073]\n",
      "Epoch 0:  97%|█████████▋| 16380/16955 [00:59<00:02, 276.13it/s, loss=2.480, v_num=5073]\n",
      "Epoch 0:  97%|█████████▋| 16480/16955 [00:59<00:01, 277.25it/s, loss=2.480, v_num=5073]\n",
      "Epoch 0:  98%|█████████▊| 16580/16955 [00:59<00:01, 278.38it/s, loss=2.480, v_num=5073]\n",
      "Validating:  93%|█████████▎| 4712/5087 [00:06<00:00, 820.99it/s]\u001b[A\n",
      "Epoch 0:  98%|█████████▊| 16680/16955 [00:59<00:00, 279.46it/s, loss=2.480, v_num=5073]\n",
      "Epoch 0:  99%|█████████▉| 16780/16955 [00:59<00:00, 280.54it/s, loss=2.480, v_num=5073]\n",
      "Epoch 0: 100%|█████████▉| 16880/16955 [00:59<00:00, 281.66it/s, loss=2.480, v_num=5073]\n",
      "Validating:  99%|█████████▉| 5046/5087 [00:07<00:00, 820.70it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: avg_val_loss reached 2.46403 (best 2.46403), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v3.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 16955/16955 [01:00<00:00, 281.17it/s, loss=2.480, v_num=5073]\n",
      "Epoch 1:  70%|██████▉   | 11868/16955 [00:53<00:22, 222.24it/s, loss=2.466, v_num=5073]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1:  70%|███████   | 11900/16955 [00:54<00:23, 217.19it/s, loss=2.466, v_num=5073]\n",
      "Epoch 1:  71%|███████   | 12000/16955 [00:54<00:22, 218.54it/s, loss=2.466, v_num=5073]\n",
      "Validating:   3%|▎         | 145/5087 [00:01<53:22,  1.54it/s] \u001b[A\n",
      "Epoch 1:  71%|███████▏  | 12100/16955 [00:55<00:22, 219.84it/s, loss=2.466, v_num=5073]\n",
      "Epoch 1:  72%|███████▏  | 12200/16955 [00:55<00:21, 221.17it/s, loss=2.466, v_num=5073]\n",
      "Epoch 1:  73%|███████▎  | 12300/16955 [00:55<00:20, 222.48it/s, loss=2.466, v_num=5073]\n",
      "Epoch 1:  73%|███████▎  | 12400/16955 [00:55<00:20, 223.77it/s, loss=2.466, v_num=5073]\n",
      "Validating:  11%|█         | 543/5087 [00:02<08:19,  9.09it/s]\u001b[A\n",
      "Epoch 1:  74%|███████▎  | 12500/16955 [00:55<00:19, 225.05it/s, loss=2.466, v_num=5073]\n",
      "Epoch 1:  74%|███████▍  | 12600/16955 [00:55<00:19, 226.34it/s, loss=2.466, v_num=5073]\n",
      "Epoch 1:  75%|███████▍  | 12700/16955 [00:55<00:18, 227.64it/s, loss=2.466, v_num=5073]\n",
      "Epoch 1:  75%|███████▌  | 12800/16955 [00:55<00:18, 228.90it/s, loss=2.466, v_num=5073]\n",
      "Validating:  19%|█▊        | 944/5087 [00:02<01:20, 51.16it/s]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 12900/16955 [00:56<00:17, 230.17it/s, loss=2.466, v_num=5073]\n",
      "Epoch 1:  77%|███████▋  | 13000/16955 [00:56<00:17, 231.46it/s, loss=2.466, v_num=5073]\n",
      "Epoch 1:  77%|███████▋  | 13100/16955 [00:56<00:16, 232.76it/s, loss=2.466, v_num=5073]\n",
      "Epoch 1:  78%|███████▊  | 13200/16955 [00:56<00:16, 234.05it/s, loss=2.466, v_num=5073]\n",
      "Epoch 1:  78%|███████▊  | 13300/16955 [00:56<00:15, 235.33it/s, loss=2.466, v_num=5073]\n",
      "Epoch 1:  79%|███████▉  | 13400/16955 [00:56<00:15, 236.61it/s, loss=2.466, v_num=5073]\n",
      "Validating:  30%|███       | 1534/5087 [00:03<00:09, 370.36it/s]\u001b[A\n",
      "Epoch 1:  80%|███████▉  | 13500/16955 [00:56<00:14, 237.84it/s, loss=2.466, v_num=5073]\n",
      "Epoch 1:  80%|████████  | 13600/16955 [00:56<00:14, 239.08it/s, loss=2.466, v_num=5073]\n",
      "Epoch 1:  81%|████████  | 13700/16955 [00:57<00:13, 240.35it/s, loss=2.466, v_num=5073]\n",
      "Epoch 1:  81%|████████▏ | 13800/16955 [00:57<00:13, 241.60it/s, loss=2.466, v_num=5073]\n",
      "Epoch 1:  82%|████████▏ | 13900/16955 [00:57<00:12, 242.85it/s, loss=2.466, v_num=5073]\n",
      "Validating:  40%|████      | 2039/5087 [00:03<00:04, 727.07it/s]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 14000/16955 [00:57<00:12, 244.09it/s, loss=2.466, v_num=5073]\n",
      "Epoch 1:  83%|████████▎ | 14100/16955 [00:57<00:11, 245.31it/s, loss=2.466, v_num=5073]\n",
      "Epoch 1:  84%|████████▍ | 14200/16955 [00:57<00:11, 246.53it/s, loss=2.466, v_num=5073]\n",
      "Epoch 1:  84%|████████▍ | 14300/16955 [00:57<00:10, 247.76it/s, loss=2.466, v_num=5073]\n",
      "Epoch 1:  85%|████████▍ | 14400/16955 [00:57<00:10, 249.00it/s, loss=2.466, v_num=5073]\n",
      "Epoch 1:  86%|████████▌ | 14500/16955 [00:57<00:09, 250.23it/s, loss=2.466, v_num=5073]\n",
      "Validating:  52%|█████▏    | 2639/5087 [00:04<00:02, 838.51it/s]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 14600/16955 [00:58<00:09, 251.40it/s, loss=2.466, v_num=5073]\n",
      "Epoch 1:  87%|████████▋ | 14700/16955 [00:58<00:08, 252.56it/s, loss=2.466, v_num=5073]\n",
      "Epoch 1:  87%|████████▋ | 14800/16955 [00:58<00:08, 253.72it/s, loss=2.466, v_num=5073]\n",
      "Epoch 1:  88%|████████▊ | 14900/16955 [00:58<00:08, 254.85it/s, loss=2.466, v_num=5073]\n",
      "Validating:  60%|█████▉    | 3051/5087 [00:05<00:02, 777.36it/s]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 15000/16955 [00:58<00:07, 255.99it/s, loss=2.466, v_num=5073]\n",
      "Epoch 1:  89%|████████▉ | 15100/16955 [00:58<00:07, 257.16it/s, loss=2.466, v_num=5073]\n",
      "Epoch 1:  90%|████████▉ | 15200/16955 [00:58<00:06, 258.34it/s, loss=2.466, v_num=5073]\n",
      "Epoch 1:  90%|█████████ | 15300/16955 [00:58<00:06, 259.51it/s, loss=2.466, v_num=5073]\n",
      "Epoch 1:  91%|█████████ | 15400/16955 [00:59<00:05, 260.70it/s, loss=2.466, v_num=5073]\n",
      "Epoch 1:  91%|█████████▏| 15500/16955 [00:59<00:05, 261.87it/s, loss=2.466, v_num=5073]\n",
      "Validating:  71%|███████▏  | 3634/5087 [00:05<00:01, 835.28it/s]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 15600/16955 [00:59<00:05, 263.01it/s, loss=2.466, v_num=5073]\n",
      "Epoch 1:  93%|█████████▎| 15700/16955 [00:59<00:04, 264.18it/s, loss=2.466, v_num=5073]\n",
      "Epoch 1:  93%|█████████▎| 15800/16955 [00:59<00:04, 265.31it/s, loss=2.466, v_num=5073]\n",
      "Epoch 1:  94%|█████████▍| 15900/16955 [00:59<00:03, 266.43it/s, loss=2.466, v_num=5073]\n",
      "Epoch 1:  94%|█████████▍| 16000/16955 [00:59<00:03, 267.56it/s, loss=2.466, v_num=5073]\n",
      "Validating:  81%|████████▏ | 4138/5087 [00:06<00:01, 814.78it/s]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 16100/16955 [00:59<00:03, 268.66it/s, loss=2.466, v_num=5073]\n",
      "Epoch 1:  96%|█████████▌| 16200/16955 [01:00<00:02, 269.79it/s, loss=2.466, v_num=5073]\n",
      "Epoch 1:  96%|█████████▌| 16300/16955 [01:00<00:02, 270.93it/s, loss=2.466, v_num=5073]\n",
      "Epoch 1:  97%|█████████▋| 16400/16955 [01:00<00:02, 272.05it/s, loss=2.466, v_num=5073]\n",
      "Epoch 1:  97%|█████████▋| 16500/16955 [01:00<00:01, 273.11it/s, loss=2.466, v_num=5073]\n",
      "Validating:  91%|█████████▏| 4642/5087 [00:07<00:00, 796.68it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 16600/16955 [01:00<00:01, 274.20it/s, loss=2.466, v_num=5073]\n",
      "Epoch 1:  98%|█████████▊| 16700/16955 [01:00<00:00, 275.29it/s, loss=2.466, v_num=5073]\n",
      "Epoch 1:  99%|█████████▉| 16800/16955 [01:00<00:00, 276.40it/s, loss=2.466, v_num=5073]\n",
      "Epoch 1: 100%|█████████▉| 16900/16955 [01:00<00:00, 277.51it/s, loss=2.466, v_num=5073]\n",
      "Validating: 100%|█████████▉| 5065/5087 [00:07<00:00, 830.68it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: avg_val_loss reached 2.45847 (best 2.45847), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v5.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 16955/16955 [01:01<00:00, 276.87it/s, loss=2.466, v_num=5073]\n",
      "Epoch 2:  70%|██████▉   | 11868/16955 [00:54<00:23, 217.31it/s, loss=2.462, v_num=5073]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2:  70%|███████   | 11900/16955 [00:56<00:23, 211.97it/s, loss=2.462, v_num=5073]\n",
      "Epoch 2:  71%|███████   | 12000/16955 [00:56<00:23, 213.27it/s, loss=2.462, v_num=5073]\n",
      "Validating:   3%|▎         | 142/5087 [00:01<59:10,  1.39it/s] \u001b[A\n",
      "Epoch 2:  71%|███████▏  | 12100/16955 [00:56<00:22, 214.58it/s, loss=2.462, v_num=5073]\n",
      "Epoch 2:  72%|███████▏  | 12200/16955 [00:56<00:22, 215.86it/s, loss=2.462, v_num=5073]\n",
      "Epoch 2:  73%|███████▎  | 12300/16955 [00:56<00:21, 217.13it/s, loss=2.462, v_num=5073]\n",
      "Epoch 2:  73%|███████▎  | 12400/16955 [00:56<00:20, 218.40it/s, loss=2.462, v_num=5073]\n",
      "Validating:  11%|█         | 535/5087 [00:02<09:14,  8.21it/s]\u001b[A\n",
      "Epoch 2:  74%|███████▎  | 12500/16955 [00:56<00:20, 219.64it/s, loss=2.462, v_num=5073]\n",
      "Epoch 2:  74%|███████▍  | 12600/16955 [00:57<00:19, 220.91it/s, loss=2.462, v_num=5073]\n",
      "Epoch 2:  75%|███████▍  | 12700/16955 [00:57<00:19, 222.16it/s, loss=2.462, v_num=5073]\n",
      "Validating:  17%|█▋        | 848/5087 [00:02<02:08, 33.09it/s]\u001b[A\n",
      "Epoch 2:  75%|███████▌  | 12800/16955 [00:57<00:18, 223.41it/s, loss=2.462, v_num=5073]\n",
      "Epoch 2:  76%|███████▌  | 12900/16955 [00:57<00:18, 224.68it/s, loss=2.462, v_num=5073]\n",
      "Epoch 2:  77%|███████▋  | 13000/16955 [00:57<00:17, 225.94it/s, loss=2.462, v_num=5073]\n",
      "Epoch 2:  77%|███████▋  | 13100/16955 [00:57<00:16, 227.16it/s, loss=2.462, v_num=5073]\n",
      "Epoch 2:  78%|███████▊  | 13200/16955 [00:57<00:16, 228.40it/s, loss=2.462, v_num=5073]\n",
      "Validating:  26%|██▌       | 1335/5087 [00:03<00:17, 214.37it/s]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 13300/16955 [00:57<00:15, 229.65it/s, loss=2.462, v_num=5073]\n",
      "Epoch 2:  79%|███████▉  | 13400/16955 [00:58<00:15, 230.89it/s, loss=2.462, v_num=5073]\n",
      "Epoch 2:  80%|███████▉  | 13500/16955 [00:58<00:14, 232.12it/s, loss=2.462, v_num=5073]\n",
      "Epoch 2:  80%|████████  | 13600/16955 [00:58<00:14, 233.33it/s, loss=2.462, v_num=5073]\n",
      "Validating:  34%|███▍      | 1748/5087 [00:03<00:06, 545.69it/s]\u001b[A\n",
      "Epoch 2:  81%|████████  | 13700/16955 [00:58<00:13, 234.51it/s, loss=2.462, v_num=5073]\n",
      "Epoch 2:  81%|████████▏ | 13800/16955 [00:58<00:13, 235.72it/s, loss=2.462, v_num=5073]\n",
      "Epoch 2:  82%|████████▏ | 13900/16955 [00:58<00:12, 236.94it/s, loss=2.462, v_num=5073]\n",
      "Epoch 2:  83%|████████▎ | 14000/16955 [00:58<00:12, 238.15it/s, loss=2.462, v_num=5073]\n",
      "Epoch 2:  83%|████████▎ | 14100/16955 [00:58<00:11, 239.34it/s, loss=2.462, v_num=5073]\n",
      "Validating:  44%|████▍     | 2238/5087 [00:04<00:03, 758.91it/s]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 14200/16955 [00:59<00:11, 240.53it/s, loss=2.462, v_num=5073]\n",
      "Epoch 2:  84%|████████▍ | 14300/16955 [00:59<00:10, 241.70it/s, loss=2.462, v_num=5073]\n",
      "Epoch 2:  85%|████████▍ | 14400/16955 [00:59<00:10, 242.88it/s, loss=2.462, v_num=5073]\n",
      "Epoch 2:  86%|████████▌ | 14500/16955 [00:59<00:10, 244.05it/s, loss=2.462, v_num=5073]\n",
      "Validating:  52%|█████▏    | 2645/5087 [00:04<00:03, 793.89it/s]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 14600/16955 [00:59<00:09, 245.21it/s, loss=2.462, v_num=5073]\n",
      "Epoch 2:  87%|████████▋ | 14700/16955 [00:59<00:09, 246.36it/s, loss=2.462, v_num=5073]\n",
      "Epoch 2:  87%|████████▋ | 14800/16955 [00:59<00:08, 247.55it/s, loss=2.462, v_num=5073]\n",
      "Epoch 2:  88%|████████▊ | 14900/16955 [00:59<00:08, 248.73it/s, loss=2.462, v_num=5073]\n",
      "Epoch 2:  88%|████████▊ | 15000/16955 [01:00<00:07, 249.90it/s, loss=2.462, v_num=5073]\n",
      "Validating:  62%|██████▏   | 3144/5087 [00:05<00:02, 824.85it/s]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 15100/16955 [01:00<00:07, 251.01it/s, loss=2.462, v_num=5073]\n",
      "Epoch 2:  90%|████████▉ | 15200/16955 [01:00<00:06, 252.15it/s, loss=2.462, v_num=5073]\n",
      "Epoch 2:  90%|█████████ | 15300/16955 [01:00<00:06, 253.29it/s, loss=2.462, v_num=5073]\n",
      "Epoch 2:  91%|█████████ | 15400/16955 [01:00<00:06, 254.41it/s, loss=2.462, v_num=5073]\n",
      "Epoch 2:  91%|█████████▏| 15500/16955 [01:00<00:05, 255.55it/s, loss=2.462, v_num=5073]\n",
      "Validating:  71%|███████▏  | 3637/5087 [00:06<00:01, 800.04it/s]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 15600/16955 [01:00<00:05, 256.67it/s, loss=2.462, v_num=5073]\n",
      "Epoch 2:  93%|█████████▎| 15700/16955 [01:00<00:04, 257.81it/s, loss=2.462, v_num=5073]\n",
      "Epoch 2:  93%|█████████▎| 15800/16955 [01:01<00:04, 258.95it/s, loss=2.462, v_num=5073]\n",
      "Epoch 2:  94%|█████████▍| 15900/16955 [01:01<00:04, 260.07it/s, loss=2.462, v_num=5073]\n",
      "Epoch 2:  94%|█████████▍| 16000/16955 [01:01<00:03, 261.18it/s, loss=2.462, v_num=5073]\n",
      "Validating:  81%|████████▏ | 4141/5087 [00:06<00:01, 822.29it/s]\u001b[A\n",
      "Epoch 2:  95%|█████████▍| 16100/16955 [01:01<00:03, 262.28it/s, loss=2.462, v_num=5073]\n",
      "Epoch 2:  96%|█████████▌| 16200/16955 [01:01<00:02, 263.40it/s, loss=2.462, v_num=5073]\n",
      "Epoch 2:  96%|█████████▌| 16300/16955 [01:01<00:02, 264.51it/s, loss=2.462, v_num=5073]\n",
      "Epoch 2:  97%|█████████▋| 16400/16955 [01:01<00:02, 265.61it/s, loss=2.462, v_num=5073]\n",
      "Epoch 2:  97%|█████████▋| 16500/16955 [01:01<00:01, 266.67it/s, loss=2.462, v_num=5073]\n",
      "Validating:  91%|█████████ | 4641/5087 [00:07<00:00, 804.44it/s]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 16600/16955 [01:02<00:01, 267.74it/s, loss=2.462, v_num=5073]\n",
      "Epoch 2:  98%|█████████▊| 16700/16955 [01:02<00:00, 268.83it/s, loss=2.462, v_num=5073]\n",
      "Epoch 2:  99%|█████████▉| 16800/16955 [01:02<00:00, 269.90it/s, loss=2.462, v_num=5073]\n",
      "Epoch 2: 100%|█████████▉| 16900/16955 [01:02<00:00, 270.94it/s, loss=2.462, v_num=5073]\n",
      "Validating:  99%|█████████▉| 5051/5087 [00:07<00:00, 788.71it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: avg_val_loss reached 2.45708 (best 2.45708), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v3.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 16955/16955 [01:02<00:00, 270.35it/s, loss=2.462, v_num=5073]\n",
      "Epoch 3:  70%|██████▉   | 11868/16955 [00:54<00:23, 218.29it/s, loss=2.461, v_num=5073]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 3:  70%|███████   | 11900/16955 [00:55<00:23, 213.47it/s, loss=2.461, v_num=5073]\n",
      "Epoch 3:  71%|███████   | 12000/16955 [00:55<00:23, 214.83it/s, loss=2.461, v_num=5073]\n",
      "Validating:   3%|▎         | 144/5087 [00:01<52:39,  1.56it/s] \u001b[A\n",
      "Epoch 3:  71%|███████▏  | 12100/16955 [00:55<00:22, 216.14it/s, loss=2.461, v_num=5073]\n",
      "Epoch 3:  72%|███████▏  | 12200/16955 [00:56<00:21, 217.46it/s, loss=2.461, v_num=5073]\n",
      "Epoch 3:  73%|███████▎  | 12300/16955 [00:56<00:21, 218.76it/s, loss=2.461, v_num=5073]\n",
      "Epoch 3:  73%|███████▎  | 12400/16955 [00:56<00:20, 220.08it/s, loss=2.461, v_num=5073]\n",
      "Epoch 3:  74%|███████▎  | 12500/16955 [00:56<00:20, 221.37it/s, loss=2.461, v_num=5073]\n",
      "Validating:  13%|█▎        | 640/5087 [00:02<05:39, 13.11it/s]\u001b[A\n",
      "Epoch 3:  74%|███████▍  | 12600/16955 [00:56<00:19, 222.66it/s, loss=2.461, v_num=5073]\n",
      "Epoch 3:  75%|███████▍  | 12700/16955 [00:56<00:18, 223.97it/s, loss=2.461, v_num=5073]\n",
      "Epoch 3:  75%|███████▌  | 12800/16955 [00:56<00:18, 225.26it/s, loss=2.461, v_num=5073]\n",
      "Epoch 3:  76%|███████▌  | 12900/16955 [00:56<00:17, 226.54it/s, loss=2.461, v_num=5073]\n",
      "Epoch 3:  77%|███████▋  | 13000/16955 [00:57<00:17, 227.83it/s, loss=2.461, v_num=5073]\n",
      "Epoch 3:  77%|███████▋  | 13100/16955 [00:57<00:16, 229.12it/s, loss=2.461, v_num=5073]\n",
      "Validating:  24%|██▍       | 1236/5087 [00:02<00:28, 135.80it/s]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 13200/16955 [00:57<00:16, 230.38it/s, loss=2.461, v_num=5073]\n",
      "Epoch 3:  78%|███████▊  | 13300/16955 [00:57<00:15, 231.64it/s, loss=2.461, v_num=5073]\n",
      "Epoch 3:  79%|███████▉  | 13400/16955 [00:57<00:15, 232.90it/s, loss=2.461, v_num=5073]\n",
      "Epoch 3:  80%|███████▉  | 13500/16955 [00:57<00:14, 234.13it/s, loss=2.461, v_num=5073]\n",
      "Epoch 3:  80%|████████  | 13600/16955 [00:57<00:14, 235.35it/s, loss=2.461, v_num=5073]\n",
      "Validating:  34%|███▍      | 1742/5087 [00:03<00:06, 512.18it/s]\u001b[A\n",
      "Epoch 3:  81%|████████  | 13700/16955 [00:57<00:13, 236.56it/s, loss=2.461, v_num=5073]\n",
      "Epoch 3:  81%|████████▏ | 13800/16955 [00:58<00:13, 237.76it/s, loss=2.461, v_num=5073]\n",
      "Epoch 3:  82%|████████▏ | 13900/16955 [00:58<00:12, 238.96it/s, loss=2.461, v_num=5073]\n",
      "Epoch 3:  83%|████████▎ | 14000/16955 [00:58<00:12, 240.15it/s, loss=2.461, v_num=5073]\n",
      "Validating:  42%|████▏     | 2145/5087 [00:03<00:04, 714.60it/s]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 14100/16955 [00:58<00:11, 241.34it/s, loss=2.461, v_num=5073]\n",
      "Epoch 3:  84%|████████▍ | 14200/16955 [00:58<00:11, 242.52it/s, loss=2.461, v_num=5073]\n",
      "Epoch 3:  84%|████████▍ | 14300/16955 [00:58<00:10, 243.69it/s, loss=2.461, v_num=5073]\n",
      "Epoch 3:  85%|████████▍ | 14400/16955 [00:58<00:10, 244.90it/s, loss=2.461, v_num=5073]\n",
      "Epoch 3:  86%|████████▌ | 14500/16955 [00:58<00:09, 246.10it/s, loss=2.461, v_num=5073]\n",
      "Validating:  52%|█████▏    | 2640/5087 [00:04<00:03, 800.99it/s]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 14600/16955 [00:59<00:09, 247.27it/s, loss=2.461, v_num=5073]\n",
      "Epoch 3:  87%|████████▋ | 14700/16955 [00:59<00:09, 248.44it/s, loss=2.461, v_num=5073]\n",
      "Epoch 3:  87%|████████▋ | 14800/16955 [00:59<00:08, 249.64it/s, loss=2.461, v_num=5073]\n",
      "Epoch 3:  88%|████████▊ | 14900/16955 [00:59<00:08, 250.80it/s, loss=2.461, v_num=5073]\n",
      "Epoch 3:  88%|████████▊ | 15000/16955 [00:59<00:07, 251.97it/s, loss=2.461, v_num=5073]\n",
      "Validating:  62%|██████▏   | 3137/5087 [00:05<00:02, 812.48it/s]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 15100/16955 [00:59<00:07, 253.09it/s, loss=2.461, v_num=5073]\n",
      "Epoch 3:  90%|████████▉ | 15200/16955 [00:59<00:06, 254.22it/s, loss=2.461, v_num=5073]\n",
      "Epoch 3:  90%|█████████ | 15300/16955 [00:59<00:06, 255.38it/s, loss=2.461, v_num=5073]\n",
      "Epoch 3:  91%|█████████ | 15400/16955 [01:00<00:06, 256.51it/s, loss=2.461, v_num=5073]\n",
      "Validating:  70%|██████▉   | 3544/5087 [00:05<00:01, 803.75it/s]\u001b[A\n",
      "Epoch 3:  91%|█████████▏| 15500/16955 [01:00<00:05, 257.66it/s, loss=2.461, v_num=5073]\n",
      "Epoch 3:  92%|█████████▏| 15600/16955 [01:00<00:05, 258.76it/s, loss=2.461, v_num=5073]\n",
      "Epoch 3:  93%|█████████▎| 15700/16955 [01:00<00:04, 259.89it/s, loss=2.461, v_num=5073]\n",
      "Epoch 3:  93%|█████████▎| 15800/16955 [01:00<00:04, 261.01it/s, loss=2.461, v_num=5073]\n",
      "Epoch 3:  94%|█████████▍| 15900/16955 [01:00<00:04, 262.13it/s, loss=2.461, v_num=5073]\n",
      "Validating:  79%|███████▉  | 4036/5087 [00:06<00:01, 806.21it/s]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 16000/16955 [01:00<00:03, 263.22it/s, loss=2.461, v_num=5073]\n",
      "Epoch 3:  95%|█████████▍| 16100/16955 [01:00<00:03, 264.35it/s, loss=2.461, v_num=5073]\n",
      "Epoch 3:  96%|█████████▌| 16200/16955 [01:01<00:02, 265.46it/s, loss=2.461, v_num=5073]\n",
      "Epoch 3:  96%|█████████▌| 16300/16955 [01:01<00:02, 266.57it/s, loss=2.461, v_num=5073]\n",
      "Validating:  87%|████████▋ | 4449/5087 [00:06<00:00, 811.98it/s]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 16400/16955 [01:01<00:02, 267.62it/s, loss=2.461, v_num=5073]\n",
      "Epoch 3:  97%|█████████▋| 16500/16955 [01:01<00:01, 268.71it/s, loss=2.461, v_num=5073]\n",
      "Epoch 3:  98%|█████████▊| 16600/16955 [01:01<00:01, 269.77it/s, loss=2.461, v_num=5073]\n",
      "Epoch 3:  98%|█████████▊| 16700/16955 [01:01<00:00, 270.85it/s, loss=2.461, v_num=5073]\n",
      "Epoch 3:  99%|█████████▉| 16800/16955 [01:01<00:00, 271.92it/s, loss=2.461, v_num=5073]\n",
      "Validating:  97%|█████████▋| 4935/5087 [00:07<00:00, 794.51it/s]\u001b[A\n",
      "Epoch 3: 100%|█████████▉| 16900/16955 [01:01<00:00, 272.97it/s, loss=2.461, v_num=5073]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: avg_val_loss reached 2.45388 (best 2.45388), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v5.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 16955/16955 [01:02<00:00, 272.37it/s, loss=2.461, v_num=5073]\n",
      "Epoch 4:  70%|██████▉   | 11868/16955 [00:55<00:23, 215.24it/s, loss=2.455, v_num=5073]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 4:  70%|███████   | 11900/16955 [00:56<00:24, 210.47it/s, loss=2.455, v_num=5073]\n",
      "Epoch 4:  71%|███████   | 12000/16955 [00:56<00:23, 211.77it/s, loss=2.455, v_num=5073]\n",
      "Validating:   3%|▎         | 139/5087 [00:01<53:59,  1.53it/s] \u001b[A\n",
      "Epoch 4:  71%|███████▏  | 12100/16955 [00:56<00:22, 213.05it/s, loss=2.455, v_num=5073]\n",
      "Epoch 4:  72%|███████▏  | 12200/16955 [00:56<00:22, 214.33it/s, loss=2.455, v_num=5073]\n",
      "Epoch 4:  73%|███████▎  | 12300/16955 [00:57<00:21, 215.60it/s, loss=2.455, v_num=5073]\n",
      "Validating:   9%|▉         | 454/5087 [00:01<12:12,  6.32it/s]\u001b[A\n",
      "Epoch 4:  73%|███████▎  | 12400/16955 [00:57<00:21, 216.86it/s, loss=2.455, v_num=5073]\n",
      "Epoch 4:  74%|███████▎  | 12500/16955 [00:57<00:20, 218.14it/s, loss=2.455, v_num=5073]\n",
      "Epoch 4:  74%|███████▍  | 12600/16955 [00:57<00:19, 219.43it/s, loss=2.455, v_num=5073]\n",
      "Epoch 4:  75%|███████▍  | 12700/16955 [00:57<00:19, 220.70it/s, loss=2.455, v_num=5073]\n",
      "Epoch 4:  75%|███████▌  | 12800/16955 [00:57<00:18, 221.95it/s, loss=2.455, v_num=5073]\n",
      "Validating:  18%|█▊        | 938/5087 [00:02<01:21, 50.75it/s]\u001b[A\n",
      "Epoch 4:  76%|███████▌  | 12900/16955 [00:57<00:18, 223.19it/s, loss=2.455, v_num=5073]\n",
      "Epoch 4:  77%|███████▋  | 13000/16955 [00:57<00:17, 224.45it/s, loss=2.455, v_num=5073]\n",
      "Epoch 4:  77%|███████▋  | 13100/16955 [00:58<00:17, 225.69it/s, loss=2.455, v_num=5073]\n",
      "Epoch 4:  78%|███████▊  | 13200/16955 [00:58<00:16, 226.94it/s, loss=2.455, v_num=5073]\n",
      "Validating:  26%|██▋       | 1345/5087 [00:03<00:16, 230.39it/s]\u001b[A\n",
      "Epoch 4:  78%|███████▊  | 13300/16955 [00:58<00:16, 228.16it/s, loss=2.455, v_num=5073]\n",
      "Epoch 4:  79%|███████▉  | 13400/16955 [00:58<00:15, 229.40it/s, loss=2.455, v_num=5073]\n",
      "Epoch 4:  80%|███████▉  | 13500/16955 [00:58<00:14, 230.63it/s, loss=2.455, v_num=5073]\n",
      "Epoch 4:  80%|████████  | 13600/16955 [00:58<00:14, 231.84it/s, loss=2.455, v_num=5073]\n",
      "Epoch 4:  81%|████████  | 13700/16955 [00:58<00:13, 233.04it/s, loss=2.455, v_num=5073]\n",
      "Validating:  36%|███▌      | 1837/5087 [00:03<00:05, 617.33it/s]\u001b[A\n",
      "Epoch 4:  81%|████████▏ | 13800/16955 [00:58<00:13, 234.24it/s, loss=2.455, v_num=5073]\n",
      "Epoch 4:  82%|████████▏ | 13900/16955 [00:59<00:12, 235.45it/s, loss=2.455, v_num=5073]\n",
      "Epoch 4:  83%|████████▎ | 14000/16955 [00:59<00:12, 236.65it/s, loss=2.455, v_num=5073]\n",
      "Epoch 4:  83%|████████▎ | 14100/16955 [00:59<00:12, 237.83it/s, loss=2.455, v_num=5073]\n",
      "Validating:  44%|████▍     | 2247/5087 [00:04<00:03, 755.41it/s]\u001b[A\n",
      "Epoch 4:  84%|████████▍ | 14200/16955 [00:59<00:11, 239.00it/s, loss=2.455, v_num=5073]\n",
      "Epoch 4:  84%|████████▍ | 14300/16955 [00:59<00:11, 240.18it/s, loss=2.455, v_num=5073]\n",
      "Epoch 4:  85%|████████▍ | 14400/16955 [00:59<00:10, 241.34it/s, loss=2.455, v_num=5073]\n",
      "Epoch 4:  86%|████████▌ | 14500/16955 [00:59<00:10, 242.48it/s, loss=2.455, v_num=5073]\n",
      "Validating:  52%|█████▏    | 2652/5087 [00:04<00:03, 765.12it/s]\u001b[A\n",
      "Epoch 4:  86%|████████▌ | 14600/16955 [00:59<00:09, 243.59it/s, loss=2.455, v_num=5073]\n",
      "Epoch 4:  87%|████████▋ | 14700/16955 [01:00<00:09, 244.74it/s, loss=2.455, v_num=5073]\n",
      "Epoch 4:  87%|████████▋ | 14800/16955 [01:00<00:08, 245.89it/s, loss=2.455, v_num=5073]\n",
      "Epoch 4:  88%|████████▊ | 14900/16955 [01:00<00:08, 247.03it/s, loss=2.455, v_num=5073]\n",
      "Validating:  60%|█████▉    | 3045/5087 [00:05<00:02, 775.95it/s]\u001b[A\n",
      "Epoch 4:  88%|████████▊ | 15000/16955 [01:00<00:07, 248.17it/s, loss=2.455, v_num=5073]\n",
      "Epoch 4:  89%|████████▉ | 15100/16955 [01:00<00:07, 249.30it/s, loss=2.455, v_num=5073]\n",
      "Epoch 4:  90%|████████▉ | 15200/16955 [01:00<00:07, 250.41it/s, loss=2.455, v_num=5073]\n",
      "Epoch 4:  90%|█████████ | 15300/16955 [01:00<00:06, 251.52it/s, loss=2.455, v_num=5073]\n",
      "Validating:  68%|██████▊   | 3442/5087 [00:05<00:02, 773.38it/s]\u001b[A\n",
      "Epoch 4:  91%|█████████ | 15400/16955 [01:00<00:06, 252.63it/s, loss=2.455, v_num=5073]\n",
      "Epoch 4:  91%|█████████▏| 15500/16955 [01:01<00:05, 253.72it/s, loss=2.455, v_num=5073]\n",
      "Epoch 4:  92%|█████████▏| 15600/16955 [01:01<00:05, 254.81it/s, loss=2.455, v_num=5073]\n",
      "Epoch 4:  93%|█████████▎| 15700/16955 [01:01<00:04, 255.90it/s, loss=2.455, v_num=5073]\n",
      "Validating:  75%|███████▌  | 3837/5087 [00:06<00:01, 765.99it/s]\u001b[A\n",
      "Epoch 4:  93%|█████████▎| 15800/16955 [01:01<00:04, 257.00it/s, loss=2.455, v_num=5073]\n",
      "Epoch 4:  94%|█████████▍| 15900/16955 [01:01<00:04, 258.11it/s, loss=2.455, v_num=5073]\n",
      "Epoch 4:  94%|█████████▍| 16000/16955 [01:01<00:03, 259.18it/s, loss=2.455, v_num=5073]\n",
      "Epoch 4:  95%|█████████▍| 16100/16955 [01:01<00:03, 260.29it/s, loss=2.455, v_num=5073]\n",
      "Validating:  83%|████████▎ | 4240/5087 [00:06<00:01, 791.90it/s]\u001b[A\n",
      "Epoch 4:  96%|█████████▌| 16200/16955 [01:01<00:02, 261.38it/s, loss=2.455, v_num=5073]\n",
      "Epoch 4:  96%|█████████▌| 16300/16955 [01:02<00:02, 262.49it/s, loss=2.455, v_num=5073]\n",
      "Epoch 4:  97%|█████████▋| 16400/16955 [01:02<00:02, 263.58it/s, loss=2.455, v_num=5073]\n",
      "Epoch 4:  97%|█████████▋| 16500/16955 [01:02<00:01, 264.66it/s, loss=2.455, v_num=5073]\n",
      "Epoch 4:  98%|█████████▊| 16600/16955 [01:02<00:01, 265.70it/s, loss=2.455, v_num=5073]\n",
      "Validating:  93%|█████████▎| 4734/5087 [00:07<00:00, 782.68it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 16700/16955 [01:02<00:00, 266.73it/s, loss=2.455, v_num=5073]\n",
      "Epoch 4:  99%|█████████▉| 16800/16955 [01:02<00:00, 267.81it/s, loss=2.455, v_num=5073]\n",
      "Epoch 4: 100%|█████████▉| 16900/16955 [01:02<00:00, 268.87it/s, loss=2.455, v_num=5073]\n",
      "Validating:  99%|█████████▉| 5056/5087 [00:07<00:00, 798.39it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: avg_val_loss reached 2.45364 (best 2.45364), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v3.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 16955/16955 [01:03<00:00, 268.25it/s, loss=2.455, v_num=5073]\n",
      "Epoch 5:  70%|██████▉   | 11868/16955 [00:54<00:23, 218.09it/s, loss=2.455, v_num=5073]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 5:  70%|███████   | 11900/16955 [00:55<00:23, 213.07it/s, loss=2.455, v_num=5073]\n",
      "Epoch 5:  71%|███████   | 12000/16955 [00:55<00:23, 214.44it/s, loss=2.455, v_num=5073]\n",
      "Validating:   3%|▎         | 147/5087 [00:01<54:47,  1.50it/s] \u001b[A\n",
      "Epoch 5:  71%|███████▏  | 12100/16955 [00:56<00:22, 215.28it/s, loss=2.455, v_num=5073]\n",
      "Epoch 5:  72%|███████▏  | 12200/16955 [00:56<00:21, 216.61it/s, loss=2.455, v_num=5073]\n",
      "Epoch 5:  73%|███████▎  | 12300/16955 [00:56<00:21, 217.92it/s, loss=2.455, v_num=5073]\n",
      "Validating:   9%|▊         | 438/5087 [00:02<12:28,  6.21it/s]\u001b[A\n",
      "Epoch 5:  73%|███████▎  | 12400/16955 [00:56<00:20, 219.20it/s, loss=2.455, v_num=5073]\n",
      "Epoch 5:  74%|███████▎  | 12500/16955 [00:56<00:20, 220.48it/s, loss=2.455, v_num=5073]\n",
      "Epoch 5:  74%|███████▍  | 12600/16955 [00:56<00:19, 221.78it/s, loss=2.455, v_num=5073]\n",
      "Epoch 5:  75%|███████▍  | 12700/16955 [00:56<00:19, 223.07it/s, loss=2.455, v_num=5073]\n",
      "Epoch 5:  75%|███████▌  | 12800/16955 [00:57<00:18, 224.36it/s, loss=2.455, v_num=5073]\n",
      "Validating:  18%|█▊        | 934/5087 [00:02<01:23, 49.97it/s]\u001b[A\n",
      "Epoch 5:  76%|███████▌  | 12900/16955 [00:57<00:17, 225.62it/s, loss=2.455, v_num=5073]\n",
      "Epoch 5:  77%|███████▋  | 13000/16955 [00:57<00:17, 226.86it/s, loss=2.455, v_num=5073]\n",
      "Epoch 5:  77%|███████▋  | 13100/16955 [00:57<00:16, 228.13it/s, loss=2.455, v_num=5073]\n",
      "Epoch 5:  78%|███████▊  | 13200/16955 [00:57<00:16, 229.35it/s, loss=2.455, v_num=5073]\n",
      "Validating:  26%|██▋       | 1346/5087 [00:03<00:16, 226.00it/s]\u001b[A\n",
      "Epoch 5:  78%|███████▊  | 13300/16955 [00:57<00:15, 230.54it/s, loss=2.455, v_num=5073]\n",
      "Epoch 5:  79%|███████▉  | 13400/16955 [00:57<00:15, 231.78it/s, loss=2.455, v_num=5073]\n",
      "Epoch 5:  80%|███████▉  | 13500/16955 [00:57<00:14, 232.99it/s, loss=2.455, v_num=5073]\n",
      "Epoch 5:  80%|████████  | 13600/16955 [00:58<00:14, 234.23it/s, loss=2.455, v_num=5073]\n",
      "Epoch 5:  81%|████████  | 13700/16955 [00:58<00:13, 235.46it/s, loss=2.455, v_num=5073]\n",
      "Validating:  36%|███▌      | 1832/5087 [00:03<00:05, 619.77it/s]\u001b[A\n",
      "Epoch 5:  81%|████████▏ | 13800/16955 [00:58<00:13, 236.68it/s, loss=2.455, v_num=5073]\n",
      "Epoch 5:  82%|████████▏ | 13900/16955 [00:58<00:12, 237.91it/s, loss=2.455, v_num=5073]\n",
      "Epoch 5:  83%|████████▎ | 14000/16955 [00:58<00:12, 239.10it/s, loss=2.455, v_num=5073]\n",
      "Epoch 5:  83%|████████▎ | 14100/16955 [00:58<00:11, 240.29it/s, loss=2.455, v_num=5073]\n",
      "Epoch 5:  84%|████████▍ | 14200/16955 [00:58<00:11, 241.51it/s, loss=2.455, v_num=5073]\n",
      "Validating:  46%|████▌     | 2333/5087 [00:04<00:03, 786.62it/s]\u001b[A\n",
      "Epoch 5:  84%|████████▍ | 14300/16955 [00:58<00:10, 242.71it/s, loss=2.455, v_num=5073]\n",
      "Epoch 5:  85%|████████▍ | 14400/16955 [00:59<00:10, 243.92it/s, loss=2.455, v_num=5073]\n",
      "Epoch 5:  86%|████████▌ | 14500/16955 [00:59<00:10, 245.06it/s, loss=2.455, v_num=5073]\n",
      "Epoch 5:  86%|████████▌ | 14600/16955 [00:59<00:09, 246.25it/s, loss=2.455, v_num=5073]\n",
      "Epoch 5:  87%|████████▋ | 14700/16955 [00:59<00:09, 247.44it/s, loss=2.455, v_num=5073]\n",
      "Validating:  56%|█████▌    | 2837/5087 [00:04<00:02, 817.10it/s]\u001b[A\n",
      "Epoch 5:  87%|████████▋ | 14800/16955 [00:59<00:08, 248.61it/s, loss=2.455, v_num=5073]\n",
      "Epoch 5:  88%|████████▊ | 14900/16955 [00:59<00:08, 249.80it/s, loss=2.455, v_num=5073]\n",
      "Epoch 5:  88%|████████▊ | 15000/16955 [00:59<00:07, 250.95it/s, loss=2.455, v_num=5073]\n",
      "Epoch 5:  89%|████████▉ | 15100/16955 [00:59<00:07, 252.08it/s, loss=2.455, v_num=5073]\n",
      "Epoch 5:  90%|████████▉ | 15200/16955 [01:00<00:06, 253.22it/s, loss=2.455, v_num=5073]\n",
      "Validating:  66%|██████▌   | 3335/5087 [00:05<00:02, 801.33it/s]\u001b[A\n",
      "Epoch 5:  90%|█████████ | 15300/16955 [01:00<00:06, 254.37it/s, loss=2.455, v_num=5073]\n",
      "Epoch 5:  91%|█████████ | 15400/16955 [01:00<00:06, 255.53it/s, loss=2.455, v_num=5073]\n",
      "Epoch 5:  91%|█████████▏| 15500/16955 [01:00<00:05, 256.69it/s, loss=2.455, v_num=5073]\n",
      "Epoch 5:  92%|█████████▏| 15600/16955 [01:00<00:05, 257.85it/s, loss=2.455, v_num=5073]\n",
      "Epoch 5:  93%|█████████▎| 15700/16955 [01:00<00:04, 258.99it/s, loss=2.455, v_num=5073]\n",
      "Validating:  76%|███████▌  | 3843/5087 [00:06<00:01, 834.29it/s]\u001b[A\n",
      "Epoch 5:  93%|█████████▎| 15800/16955 [01:00<00:04, 260.09it/s, loss=2.455, v_num=5073]\n",
      "Epoch 5:  94%|█████████▍| 15900/16955 [01:00<00:04, 261.22it/s, loss=2.455, v_num=5073]\n",
      "Epoch 5:  94%|█████████▍| 16000/16955 [01:00<00:03, 262.35it/s, loss=2.455, v_num=5073]\n",
      "Epoch 5:  95%|█████████▍| 16100/16955 [01:01<00:03, 263.48it/s, loss=2.455, v_num=5073]\n",
      "Epoch 5:  96%|█████████▌| 16200/16955 [01:01<00:02, 264.61it/s, loss=2.455, v_num=5073]\n",
      "Epoch 5:  96%|█████████▌| 16300/16955 [01:01<00:02, 265.73it/s, loss=2.455, v_num=5073]\n",
      "Validating:  87%|████████▋ | 4437/5087 [00:06<00:00, 833.83it/s]\u001b[A\n",
      "Epoch 5:  97%|█████████▋| 16400/16955 [01:01<00:02, 266.82it/s, loss=2.455, v_num=5073]\n",
      "Epoch 5:  97%|█████████▋| 16500/16955 [01:01<00:01, 267.94it/s, loss=2.455, v_num=5073]\n",
      "Epoch 5:  98%|█████████▊| 16600/16955 [01:01<00:01, 269.03it/s, loss=2.455, v_num=5073]\n",
      "Epoch 5:  98%|█████████▊| 16700/16955 [01:01<00:00, 270.13it/s, loss=2.455, v_num=5073]\n",
      "Epoch 5:  99%|█████████▉| 16800/16955 [01:01<00:00, 271.22it/s, loss=2.455, v_num=5073]\n",
      "Validating:  97%|█████████▋| 4946/5087 [00:07<00:00, 825.58it/s]\u001b[A\n",
      "Epoch 5: 100%|█████████▉| 16900/16955 [01:02<00:00, 272.26it/s, loss=2.455, v_num=5073]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: avg_val_loss reached 2.45259 (best 2.45259), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v5.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 16955/16955 [01:02<00:00, 271.49it/s, loss=2.455, v_num=5073]\n",
      "Epoch 6:  70%|██████▉   | 11868/16955 [00:52<00:22, 226.35it/s, loss=2.450, v_num=5073]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 6:  70%|███████   | 11900/16955 [00:54<00:22, 220.16it/s, loss=2.450, v_num=5073]\n",
      "Epoch 6:  71%|███████   | 12000/16955 [00:54<00:22, 221.55it/s, loss=2.450, v_num=5073]\n",
      "Epoch 6:  71%|███████▏  | 12100/16955 [00:54<00:21, 222.92it/s, loss=2.450, v_num=5073]\n",
      "Validating:   5%|▍         | 236/5087 [00:01<43:04,  1.88it/s]  \u001b[A\n",
      "Epoch 6:  72%|███████▏  | 12200/16955 [00:54<00:21, 224.27it/s, loss=2.450, v_num=5073]\n",
      "Epoch 6:  73%|███████▎  | 12300/16955 [00:54<00:20, 225.63it/s, loss=2.450, v_num=5073]\n",
      "Epoch 6:  73%|███████▎  | 12400/16955 [00:54<00:20, 226.98it/s, loss=2.450, v_num=5073]\n",
      "Epoch 6:  74%|███████▎  | 12500/16955 [00:54<00:19, 228.32it/s, loss=2.450, v_num=5073]\n",
      "Epoch 6:  74%|███████▍  | 12600/16955 [00:54<00:18, 229.66it/s, loss=2.450, v_num=5073]\n",
      "Epoch 6:  75%|███████▍  | 12700/16955 [00:54<00:18, 230.95it/s, loss=2.450, v_num=5073]\n",
      "Validating:  16%|█▋        | 833/5087 [00:02<03:11, 22.23it/s]\u001b[A\n",
      "Epoch 6:  75%|███████▌  | 12800/16955 [00:55<00:17, 232.23it/s, loss=2.450, v_num=5073]\n",
      "Epoch 6:  76%|███████▌  | 12900/16955 [00:55<00:17, 233.55it/s, loss=2.450, v_num=5073]\n",
      "Epoch 6:  77%|███████▋  | 13000/16955 [00:55<00:16, 234.85it/s, loss=2.450, v_num=5073]\n",
      "Epoch 6:  77%|███████▋  | 13100/16955 [00:55<00:16, 236.15it/s, loss=2.450, v_num=5073]\n",
      "Epoch 6:  78%|███████▊  | 13200/16955 [00:55<00:15, 237.45it/s, loss=2.450, v_num=5073]\n",
      "Validating:  26%|██▋       | 1339/5087 [00:03<00:23, 157.57it/s]\u001b[A\n",
      "Epoch 6:  78%|███████▊  | 13300/16955 [00:55<00:15, 238.71it/s, loss=2.450, v_num=5073]\n",
      "Epoch 6:  79%|███████▉  | 13400/16955 [00:55<00:14, 239.99it/s, loss=2.450, v_num=5073]\n",
      "Epoch 6:  80%|███████▉  | 13500/16955 [00:55<00:14, 241.27it/s, loss=2.450, v_num=5073]\n",
      "Epoch 6:  80%|████████  | 13600/16955 [00:56<00:13, 242.53it/s, loss=2.450, v_num=5073]\n",
      "Epoch 6:  81%|████████  | 13700/16955 [00:56<00:13, 243.78it/s, loss=2.450, v_num=5073]\n",
      "Validating:  36%|███▌      | 1840/5087 [00:03<00:05, 547.94it/s]\u001b[A\n",
      "Epoch 6:  81%|████████▏ | 13800/16955 [00:56<00:12, 244.97it/s, loss=2.450, v_num=5073]\n",
      "Epoch 6:  82%|████████▏ | 13900/16955 [00:56<00:12, 246.11it/s, loss=2.450, v_num=5073]\n",
      "Epoch 6:  83%|████████▎ | 14000/16955 [00:56<00:11, 247.33it/s, loss=2.450, v_num=5073]\n",
      "Epoch 6:  83%|████████▎ | 14100/16955 [00:56<00:11, 248.56it/s, loss=2.450, v_num=5073]\n",
      "Validating:  44%|████▍     | 2243/5087 [00:04<00:03, 723.52it/s]\u001b[A\n",
      "Epoch 6:  84%|████████▍ | 14200/16955 [00:56<00:11, 249.76it/s, loss=2.450, v_num=5073]\n",
      "Epoch 6:  84%|████████▍ | 14300/16955 [00:56<00:10, 250.97it/s, loss=2.450, v_num=5073]\n",
      "Epoch 6:  85%|████████▍ | 14400/16955 [00:57<00:10, 252.19it/s, loss=2.450, v_num=5073]\n",
      "Epoch 6:  86%|████████▌ | 14500/16955 [00:57<00:09, 253.38it/s, loss=2.450, v_num=5073]\n",
      "Validating:  52%|█████▏    | 2647/5087 [00:04<00:03, 788.31it/s]\u001b[A\n",
      "Epoch 6:  86%|████████▌ | 14600/16955 [00:57<00:09, 254.57it/s, loss=2.450, v_num=5073]\n",
      "Epoch 6:  87%|████████▋ | 14700/16955 [00:57<00:08, 255.75it/s, loss=2.450, v_num=5073]\n",
      "Epoch 6:  87%|████████▋ | 14800/16955 [00:57<00:08, 256.91it/s, loss=2.450, v_num=5073]\n",
      "Epoch 6:  88%|████████▊ | 14900/16955 [00:57<00:07, 258.08it/s, loss=2.450, v_num=5073]\n",
      "Epoch 6:  88%|████████▊ | 15000/16955 [00:57<00:07, 259.26it/s, loss=2.450, v_num=5073]\n",
      "Validating:  62%|██████▏   | 3132/5087 [00:05<00:02, 793.01it/s]\u001b[A\n",
      "Epoch 6:  89%|████████▉ | 15100/16955 [00:57<00:07, 260.44it/s, loss=2.450, v_num=5073]\n",
      "Epoch 6:  90%|████████▉ | 15200/16955 [00:58<00:06, 261.61it/s, loss=2.450, v_num=5073]\n",
      "Epoch 6:  90%|█████████ | 15300/16955 [00:58<00:06, 262.78it/s, loss=2.450, v_num=5073]\n",
      "Epoch 6:  91%|█████████ | 15400/16955 [00:58<00:05, 263.94it/s, loss=2.450, v_num=5073]\n",
      "Validating:  70%|██████▉   | 3544/5087 [00:05<00:01, 805.39it/s]\u001b[A\n",
      "Epoch 6:  91%|█████████▏| 15500/16955 [00:58<00:05, 265.09it/s, loss=2.450, v_num=5073]\n",
      "Epoch 6:  92%|█████████▏| 15600/16955 [00:58<00:05, 266.23it/s, loss=2.450, v_num=5073]\n",
      "Epoch 6:  93%|█████████▎| 15700/16955 [00:58<00:04, 267.35it/s, loss=2.450, v_num=5073]\n",
      "Epoch 6:  93%|█████████▎| 15800/16955 [00:58<00:04, 268.50it/s, loss=2.450, v_num=5073]\n",
      "Epoch 6:  94%|█████████▍| 15900/16955 [00:58<00:03, 269.69it/s, loss=2.450, v_num=5073]\n",
      "Validating:  80%|███████▉  | 4045/5087 [00:06<00:01, 829.06it/s]\u001b[A\n",
      "Epoch 6:  94%|█████████▍| 16000/16955 [00:59<00:03, 270.80it/s, loss=2.450, v_num=5073]\n",
      "Epoch 6:  95%|█████████▍| 16100/16955 [00:59<00:03, 271.96it/s, loss=2.450, v_num=5073]\n",
      "Epoch 6:  96%|█████████▌| 16200/16955 [00:59<00:02, 273.12it/s, loss=2.450, v_num=5073]\n",
      "Epoch 6:  96%|█████████▌| 16300/16955 [00:59<00:02, 274.25it/s, loss=2.450, v_num=5073]\n",
      "Epoch 6:  97%|█████████▋| 16400/16955 [00:59<00:02, 275.36it/s, loss=2.450, v_num=5073]\n",
      "Epoch 6:  97%|█████████▋| 16500/16955 [00:59<00:01, 276.49it/s, loss=2.450, v_num=5073]\n",
      "Validating:  91%|█████████▏| 4644/5087 [00:07<00:00, 826.14it/s]\u001b[A\n",
      "Epoch 6:  98%|█████████▊| 16600/16955 [00:59<00:01, 277.57it/s, loss=2.450, v_num=5073]\n",
      "Epoch 6:  98%|█████████▊| 16700/16955 [00:59<00:00, 278.65it/s, loss=2.450, v_num=5073]\n",
      "Epoch 6:  99%|█████████▉| 16800/16955 [01:00<00:00, 279.72it/s, loss=2.450, v_num=5073]\n",
      "Epoch 6: 100%|█████████▉| 16900/16955 [01:00<00:00, 280.78it/s, loss=2.450, v_num=5073]\n",
      "Validating:  99%|█████████▉| 5052/5087 [00:07<00:00, 780.39it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: avg_val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 16955/16955 [01:00<00:00, 280.00it/s, loss=2.450, v_num=5073]\n",
      "Epoch 7:  70%|██████▉   | 11868/16955 [00:53<00:22, 221.50it/s, loss=2.455, v_num=5073]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 7:  70%|███████   | 11900/16955 [00:55<00:23, 215.36it/s, loss=2.455, v_num=5073]\n",
      "Epoch 7:  71%|███████   | 12000/16955 [00:55<00:22, 216.71it/s, loss=2.455, v_num=5073]\n",
      "Validating:   3%|▎         | 138/5087 [00:01<1:04:43,  1.27it/s]\u001b[A\n",
      "Epoch 7:  71%|███████▏  | 12100/16955 [00:55<00:22, 218.02it/s, loss=2.455, v_num=5073]\n",
      "Epoch 7:  72%|███████▏  | 12200/16955 [00:55<00:21, 219.34it/s, loss=2.455, v_num=5073]\n",
      "Epoch 7:  73%|███████▎  | 12300/16955 [00:55<00:21, 220.66it/s, loss=2.455, v_num=5073]\n",
      "Epoch 7:  73%|███████▎  | 12400/16955 [00:55<00:20, 221.94it/s, loss=2.455, v_num=5073]\n",
      "Validating:  11%|█         | 544/5087 [00:02<10:03,  7.52it/s]\u001b[A\n",
      "Epoch 7:  74%|███████▎  | 12500/16955 [00:55<00:19, 223.24it/s, loss=2.455, v_num=5073]\n",
      "Epoch 7:  74%|███████▍  | 12600/16955 [00:56<00:19, 224.55it/s, loss=2.455, v_num=5073]\n",
      "Epoch 7:  75%|███████▍  | 12700/16955 [00:56<00:18, 225.83it/s, loss=2.455, v_num=5073]\n",
      "Epoch 7:  75%|███████▌  | 12800/16955 [00:56<00:18, 227.11it/s, loss=2.455, v_num=5073]\n",
      "Epoch 7:  76%|███████▌  | 12900/16955 [00:56<00:17, 228.40it/s, loss=2.455, v_num=5073]\n",
      "Validating:  20%|██        | 1039/5087 [00:02<01:07, 59.82it/s]\u001b[A\n",
      "Epoch 7:  77%|███████▋  | 13000/16955 [00:56<00:17, 229.68it/s, loss=2.455, v_num=5073]\n",
      "Epoch 7:  77%|███████▋  | 13100/16955 [00:56<00:16, 230.92it/s, loss=2.455, v_num=5073]\n",
      "Epoch 7:  78%|███████▊  | 13200/16955 [00:56<00:16, 232.18it/s, loss=2.455, v_num=5073]\n",
      "Epoch 7:  78%|███████▊  | 13300/16955 [00:56<00:15, 233.47it/s, loss=2.455, v_num=5073]\n",
      "Epoch 7:  79%|███████▉  | 13400/16955 [00:57<00:15, 234.73it/s, loss=2.455, v_num=5073]\n",
      "Validating:  30%|███       | 1544/5087 [00:03<00:10, 329.47it/s]\u001b[A\n",
      "Epoch 7:  80%|███████▉  | 13500/16955 [00:57<00:14, 235.98it/s, loss=2.455, v_num=5073]\n",
      "Epoch 7:  80%|████████  | 13600/16955 [00:57<00:14, 237.21it/s, loss=2.455, v_num=5073]\n",
      "Epoch 7:  81%|████████  | 13700/16955 [00:57<00:13, 238.45it/s, loss=2.455, v_num=5073]\n",
      "Epoch 7:  81%|████████▏ | 13800/16955 [00:57<00:13, 239.71it/s, loss=2.455, v_num=5073]\n",
      "Epoch 7:  82%|████████▏ | 13900/16955 [00:57<00:12, 240.93it/s, loss=2.455, v_num=5073]\n",
      "Epoch 7:  83%|████████▎ | 14000/16955 [00:57<00:12, 242.17it/s, loss=2.455, v_num=5073]\n",
      "Validating:  42%|████▏     | 2137/5087 [00:04<00:03, 739.24it/s]\u001b[A\n",
      "Epoch 7:  83%|████████▎ | 14100/16955 [00:57<00:11, 243.40it/s, loss=2.455, v_num=5073]\n",
      "Epoch 7:  84%|████████▍ | 14200/16955 [00:58<00:11, 244.63it/s, loss=2.455, v_num=5073]\n",
      "Epoch 7:  84%|████████▍ | 14300/16955 [00:58<00:10, 245.84it/s, loss=2.455, v_num=5073]\n",
      "Epoch 7:  85%|████████▍ | 14400/16955 [00:58<00:10, 247.06it/s, loss=2.455, v_num=5073]\n",
      "Epoch 7:  86%|████████▌ | 14500/16955 [00:58<00:09, 248.26it/s, loss=2.455, v_num=5073]\n",
      "Epoch 7:  86%|████████▌ | 14600/16955 [00:58<00:09, 249.49it/s, loss=2.455, v_num=5073]\n",
      "Validating:  54%|█████▍    | 2739/5087 [00:04<00:02, 840.48it/s]\u001b[A\n",
      "Epoch 7:  87%|████████▋ | 14700/16955 [00:58<00:08, 250.70it/s, loss=2.455, v_num=5073]\n",
      "Epoch 7:  87%|████████▋ | 14800/16955 [00:58<00:08, 251.90it/s, loss=2.455, v_num=5073]\n",
      "Epoch 7:  88%|████████▊ | 14900/16955 [00:58<00:08, 253.10it/s, loss=2.455, v_num=5073]\n",
      "Epoch 7:  88%|████████▊ | 15000/16955 [00:58<00:07, 254.28it/s, loss=2.455, v_num=5073]\n",
      "Epoch 7:  89%|████████▉ | 15100/16955 [00:59<00:07, 255.47it/s, loss=2.455, v_num=5073]\n",
      "Epoch 7:  90%|████████▉ | 15200/16955 [00:59<00:06, 256.66it/s, loss=2.455, v_num=5073]\n",
      "Epoch 7:  90%|█████████ | 15300/16955 [00:59<00:06, 257.84it/s, loss=2.455, v_num=5073]\n",
      "Validating:  67%|██████▋   | 3432/5087 [00:05<00:01, 850.45it/s]\u001b[A\n",
      "Epoch 7:  91%|█████████ | 15400/16955 [00:59<00:06, 259.01it/s, loss=2.455, v_num=5073]\n",
      "Epoch 7:  91%|█████████▏| 15500/16955 [00:59<00:05, 260.16it/s, loss=2.455, v_num=5073]\n",
      "Epoch 7:  92%|█████████▏| 15600/16955 [00:59<00:05, 261.33it/s, loss=2.455, v_num=5073]\n",
      "Epoch 7:  93%|█████████▎| 15700/16955 [00:59<00:04, 262.46it/s, loss=2.455, v_num=5073]\n",
      "Epoch 7:  93%|█████████▎| 15800/16955 [00:59<00:04, 263.62it/s, loss=2.455, v_num=5073]\n",
      "Validating:  78%|███████▊  | 3945/5087 [00:06<00:01, 604.90it/s]\u001b[A\n",
      "Epoch 7:  94%|█████████▍| 15900/16955 [01:00<00:03, 264.18it/s, loss=2.455, v_num=5073]\n",
      "Epoch 7:  94%|█████████▍| 16000/16955 [01:00<00:03, 265.34it/s, loss=2.455, v_num=5073]\n",
      "Epoch 7:  95%|█████████▍| 16100/16955 [01:00<00:03, 266.47it/s, loss=2.455, v_num=5073]\n",
      "Epoch 7:  96%|█████████▌| 16200/16955 [01:00<00:02, 267.62it/s, loss=2.455, v_num=5073]\n",
      "Epoch 7:  96%|█████████▌| 16300/16955 [01:00<00:02, 268.74it/s, loss=2.455, v_num=5073]\n",
      "Epoch 7:  97%|█████████▋| 16400/16955 [01:00<00:02, 269.87it/s, loss=2.455, v_num=5073]\n",
      "Validating:  89%|████████▉ | 4544/5087 [00:07<00:00, 822.31it/s]\u001b[A\n",
      "Epoch 7:  97%|█████████▋| 16500/16955 [01:00<00:01, 270.95it/s, loss=2.455, v_num=5073]\n",
      "Epoch 7:  98%|█████████▊| 16600/16955 [01:01<00:01, 272.04it/s, loss=2.455, v_num=5073]\n",
      "Epoch 7:  98%|█████████▊| 16700/16955 [01:01<00:00, 273.13it/s, loss=2.455, v_num=5073]\n",
      "Epoch 7:  99%|█████████▉| 16800/16955 [01:01<00:00, 274.18it/s, loss=2.455, v_num=5073]\n",
      "Epoch 7: 100%|█████████▉| 16900/16955 [01:01<00:00, 275.24it/s, loss=2.455, v_num=5073]\n",
      "Validating:  99%|█████████▉| 5037/5087 [00:07<00:00, 789.18it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: avg_val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 16955/16955 [01:01<00:00, 274.59it/s, loss=2.455, v_num=5073]\n",
      "Epoch 8:  70%|██████▉   | 11868/16955 [00:52<00:22, 224.23it/s, loss=2.445, v_num=5073]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 8:  70%|███████   | 11900/16955 [00:54<00:23, 219.12it/s, loss=2.445, v_num=5073]\n",
      "Epoch 8:  71%|███████   | 12000/16955 [00:54<00:22, 220.50it/s, loss=2.445, v_num=5073]\n",
      "Epoch 8:  71%|███████▏  | 12100/16955 [00:54<00:21, 221.86it/s, loss=2.445, v_num=5073]\n",
      "Validating:   5%|▍         | 237/5087 [00:01<36:32,  2.21it/s]\u001b[A\n",
      "Epoch 8:  72%|███████▏  | 12200/16955 [00:54<00:21, 223.20it/s, loss=2.445, v_num=5073]\n",
      "Epoch 8:  73%|███████▎  | 12300/16955 [00:54<00:20, 224.53it/s, loss=2.445, v_num=5073]\n",
      "Epoch 8:  73%|███████▎  | 12400/16955 [00:54<00:20, 225.86it/s, loss=2.445, v_num=5073]\n",
      "Epoch 8:  74%|███████▎  | 12500/16955 [00:55<00:19, 227.19it/s, loss=2.445, v_num=5073]\n",
      "Epoch 8:  74%|███████▍  | 12600/16955 [00:55<00:19, 228.53it/s, loss=2.445, v_num=5073]\n",
      "Validating:  15%|█▍        | 745/5087 [00:02<03:55, 18.44it/s]\u001b[A\n",
      "Epoch 8:  75%|███████▍  | 12700/16955 [00:55<00:18, 229.84it/s, loss=2.445, v_num=5073]\n",
      "Epoch 8:  75%|███████▌  | 12800/16955 [00:55<00:17, 231.16it/s, loss=2.445, v_num=5073]\n",
      "Epoch 8:  76%|███████▌  | 12900/16955 [00:55<00:17, 232.42it/s, loss=2.445, v_num=5073]\n",
      "Epoch 8:  77%|███████▋  | 13000/16955 [00:55<00:16, 233.72it/s, loss=2.445, v_num=5073]\n",
      "Epoch 8:  77%|███████▋  | 13100/16955 [00:55<00:16, 235.00it/s, loss=2.445, v_num=5073]\n",
      "Validating:  25%|██▍       | 1248/5087 [00:02<00:28, 133.91it/s]\u001b[A\n",
      "Epoch 8:  78%|███████▊  | 13200/16955 [00:55<00:15, 236.24it/s, loss=2.445, v_num=5073]\n",
      "Epoch 8:  78%|███████▊  | 13300/16955 [00:56<00:15, 237.50it/s, loss=2.445, v_num=5073]\n",
      "Epoch 8:  79%|███████▉  | 13400/16955 [00:56<00:14, 238.75it/s, loss=2.445, v_num=5073]\n",
      "Epoch 8:  80%|███████▉  | 13500/16955 [00:56<00:14, 240.00it/s, loss=2.445, v_num=5073]\n",
      "Epoch 8:  80%|████████  | 13600/16955 [00:56<00:13, 241.25it/s, loss=2.445, v_num=5073]\n",
      "Validating:  34%|███▍      | 1736/5087 [00:03<00:06, 504.50it/s]\u001b[A\n",
      "Epoch 8:  81%|████████  | 13700/16955 [00:56<00:13, 242.49it/s, loss=2.445, v_num=5073]\n",
      "Epoch 8:  81%|████████▏ | 13800/16955 [00:56<00:12, 243.71it/s, loss=2.445, v_num=5073]\n",
      "Epoch 8:  82%|████████▏ | 13900/16955 [00:56<00:12, 244.97it/s, loss=2.445, v_num=5073]\n",
      "Epoch 8:  83%|████████▎ | 14000/16955 [00:56<00:12, 246.22it/s, loss=2.445, v_num=5073]\n",
      "Epoch 8:  83%|████████▎ | 14100/16955 [00:56<00:11, 247.46it/s, loss=2.445, v_num=5073]\n",
      "Validating:  44%|████▍     | 2235/5087 [00:04<00:03, 770.09it/s]\u001b[A\n",
      "Epoch 8:  84%|████████▍ | 14200/16955 [00:57<00:11, 248.66it/s, loss=2.445, v_num=5073]\n",
      "Epoch 8:  84%|████████▍ | 14300/16955 [00:57<00:10, 249.85it/s, loss=2.445, v_num=5073]\n",
      "Epoch 8:  85%|████████▍ | 14400/16955 [00:57<00:10, 251.07it/s, loss=2.445, v_num=5073]\n",
      "Epoch 8:  86%|████████▌ | 14500/16955 [00:57<00:09, 252.26it/s, loss=2.445, v_num=5073]\n",
      "Validating:  52%|█████▏    | 2645/5087 [00:04<00:03, 791.60it/s]\u001b[A\n",
      "Epoch 8:  86%|████████▌ | 14600/16955 [00:57<00:09, 253.42it/s, loss=2.445, v_num=5073]\n",
      "Epoch 8:  87%|████████▋ | 14700/16955 [00:57<00:08, 254.61it/s, loss=2.445, v_num=5073]\n",
      "Epoch 8:  87%|████████▋ | 14800/16955 [00:57<00:08, 255.80it/s, loss=2.445, v_num=5073]\n",
      "Epoch 8:  88%|████████▊ | 14900/16955 [00:57<00:07, 256.97it/s, loss=2.445, v_num=5073]\n",
      "Epoch 8:  88%|████████▊ | 15000/16955 [00:58<00:07, 258.14it/s, loss=2.445, v_num=5073]\n",
      "Validating:  62%|██████▏   | 3132/5087 [00:05<00:02, 796.26it/s]\u001b[A\n",
      "Epoch 8:  89%|████████▉ | 15100/16955 [00:58<00:07, 259.30it/s, loss=2.445, v_num=5073]\n",
      "Epoch 8:  90%|████████▉ | 15200/16955 [00:58<00:06, 260.46it/s, loss=2.445, v_num=5073]\n",
      "Epoch 8:  90%|█████████ | 15300/16955 [00:58<00:06, 261.63it/s, loss=2.445, v_num=5073]\n",
      "Epoch 8:  91%|█████████ | 15400/16955 [00:58<00:05, 262.79it/s, loss=2.445, v_num=5073]\n",
      "Validating:  70%|██████▉   | 3540/5087 [00:05<00:01, 806.56it/s]\u001b[A\n",
      "Epoch 8:  91%|█████████▏| 15500/16955 [00:58<00:05, 263.89it/s, loss=2.445, v_num=5073]\n",
      "Epoch 8:  92%|█████████▏| 15600/16955 [00:58<00:05, 265.00it/s, loss=2.445, v_num=5073]\n",
      "Epoch 8:  93%|█████████▎| 15700/16955 [00:58<00:04, 266.11it/s, loss=2.445, v_num=5073]\n",
      "Epoch 8:  93%|█████████▎| 15800/16955 [00:59<00:04, 267.24it/s, loss=2.445, v_num=5073]\n",
      "Validating:  77%|███████▋  | 3938/5087 [00:06<00:01, 776.24it/s]\u001b[A\n",
      "Epoch 8:  94%|█████████▍| 15900/16955 [00:59<00:03, 268.35it/s, loss=2.445, v_num=5073]\n",
      "Epoch 8:  94%|█████████▍| 16000/16955 [00:59<00:03, 269.47it/s, loss=2.445, v_num=5073]\n",
      "Epoch 8:  95%|█████████▍| 16100/16955 [00:59<00:03, 270.60it/s, loss=2.445, v_num=5073]\n",
      "Epoch 8:  96%|█████████▌| 16200/16955 [00:59<00:02, 271.74it/s, loss=2.445, v_num=5073]\n",
      "Validating:  85%|████████▌ | 4347/5087 [00:06<00:00, 809.26it/s]\u001b[A\n",
      "Epoch 8:  96%|█████████▌| 16300/16955 [00:59<00:02, 272.84it/s, loss=2.445, v_num=5073]\n",
      "Epoch 8:  97%|█████████▋| 16400/16955 [00:59<00:02, 273.93it/s, loss=2.445, v_num=5073]\n",
      "Epoch 8:  97%|█████████▋| 16500/16955 [01:00<00:01, 274.98it/s, loss=2.445, v_num=5073]\n",
      "Epoch 8:  98%|█████████▊| 16600/16955 [01:00<00:01, 276.04it/s, loss=2.445, v_num=5073]\n",
      "Epoch 8:  98%|█████████▊| 16700/16955 [01:00<00:00, 277.13it/s, loss=2.445, v_num=5073]\n",
      "Validating:  95%|█████████▍| 4832/5087 [00:07<00:00, 777.54it/s]\u001b[A\n",
      "Epoch 8:  99%|█████████▉| 16800/16955 [01:00<00:00, 278.17it/s, loss=2.445, v_num=5073]\n",
      "Epoch 8: 100%|█████████▉| 16900/16955 [01:00<00:00, 279.22it/s, loss=2.445, v_num=5073]\n",
      "Validating: 100%|█████████▉| 5065/5087 [00:07<00:00, 766.09it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: avg_val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 16955/16955 [01:00<00:00, 278.48it/s, loss=2.445, v_num=5073]\n",
      "Epoch 8: 100%|██████████| 16955/16955 [01:01<00:00, 275.21it/s, loss=2.445, v_num=5073]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: ----------------------------------\n",
      "COMET INFO: Comet.ml OfflineExperiment Summary\n",
      "COMET INFO: ----------------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : [OfflineExperiment will get URL after upload]\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     avg_train_loss [9] : (2.437842607498169, 2.472731828689575)\n",
      "COMET INFO:     avg_val_loss [9]   : (2.452589988708496, 2.464033603668213)\n",
      "COMET INFO:   Others:\n",
      "COMET INFO:     offline_experiment : True\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     device           : cuda\n",
      "COMET INFO:     dropout          : 0.2\n",
      "COMET INFO:     logger           : <pytorch_lightning.loggers.comet.CometLogger object at 0x7fccf8f29dd0>\n",
      "COMET INFO:     lr               : 0.001\n",
      "COMET INFO:     max_epochs       : 30\n",
      "COMET INFO:     num_warmup_steps : 2000\n",
      "COMET INFO:     num_workers      : 12\n",
      "COMET INFO:     pin_memory       : True\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     code                     : 1 (5 KB)\n",
      "COMET INFO:     environment details      : 1\n",
      "COMET INFO:     filename                 : 1\n",
      "COMET INFO:     git metadata             : 1\n",
      "COMET INFO:     git-patch (uncompressed) : 1 (245 KB)\n",
      "COMET INFO:     installed packages       : 1\n",
      "COMET INFO:     notebook                 : 1\n",
      "COMET INFO:     os packages              : 1\n",
      "COMET INFO: ----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Starting saving the offline archive\n",
      "COMET INFO: To upload this offline experiment, run:\n",
      "    comet upload logs/8bbdd26a46a9480e9e4e44383f6e5073.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9min 18s, sys: 1min 39s, total: 10min 57s\n",
      "Wall time: 9min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EarlyStopping mode set to min for monitoring avg_val_loss.\n"
     ]
    }
   ],
   "source": [
    "sign_model = Model.load_from_checkpoint(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, hparams=hparams,\\\n",
    "                                   checkpoint_path=\"./checkpoints/model-outputs-v5.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (net): Net(\n",
       "    (fc1): Linear(in_features=768, out_features=128, bias=True)\n",
       "    (fc2): Linear(in_features=128, out_features=12, bias=True)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "    (loss_func): CrossEntropyLoss()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sign_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4239/4239 [00:03<00:00, 1075.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.157     0.073     0.100      9893\n",
      "           1      0.188     0.094     0.126     12961\n",
      "           2      0.173     0.108     0.133     12949\n",
      "           3      0.296     0.011     0.021      9801\n",
      "           4      0.498     0.012     0.022     10344\n",
      "           5      0.570     0.022     0.042     10708\n",
      "           6      0.094     0.838     0.170     12412\n",
      "           7      0.211     0.034     0.059     10757\n",
      "           8      0.208     0.006     0.012      9963\n",
      "           9      0.191     0.027     0.047     11370\n",
      "          10      0.392     0.018     0.035     12453\n",
      "          11      0.182     0.014     0.025     12022\n",
      "\n",
      "    accuracy                          0.113    135633\n",
      "   macro avg      0.263     0.105     0.066    135633\n",
      "weighted avg      0.259     0.113     0.069    135633\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pred = sign_model.predict_eval(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics are higher now, but still, the model is weak. To be fair, the task sounds a bit impossible, considering that it's hard to find any patterns which are specific for zodiac signs, especially in texts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's turn for age prediction model. Classes are not balanced, we'll try to deal with it. Repeating again prepararion routine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_class2idx = {k: v for v, k in enumerate(sorted(df2['age'].unique()))}\n",
    "age_idx2class = {v: k for k, v in age_class2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{13: 0,\n",
       " 14: 1,\n",
       " 15: 2,\n",
       " 16: 3,\n",
       " 17: 4,\n",
       " 23: 5,\n",
       " 24: 6,\n",
       " 25: 7,\n",
       " 26: 8,\n",
       " 27: 9,\n",
       " 33: 10,\n",
       " 34: 11,\n",
       " 35: 12,\n",
       " 36: 13,\n",
       " 37: 14,\n",
       " 38: 15,\n",
       " 39: 16,\n",
       " 40: 17,\n",
       " 41: 18,\n",
       " 42: 19,\n",
       " 43: 20,\n",
       " 44: 21,\n",
       " 45: 22,\n",
       " 46: 23,\n",
       " 47: 24,\n",
       " 48: 25}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_class2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['age'] = df2['age'].map(age_class2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2['vectors'].values\n",
    "y = df2['age'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=17)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.3, stratify=y_trainval, random_state=43)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As classes are highly disbalanced we want artificially increase number of times NN sees rare classes. So I provide weights for training instances to activate `WeightedRandomSampler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_distribution(y_label):\n",
    "    return dict(df2[y_label].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_list = torch.tensor(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_count = [i for i in get_class_distribution('age').values()]\n",
    "class_weights = 1./torch.tensor(class_count, dtype=torch.float) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights_all = class_weights[target_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.6968e-05, 2.3787e-04, 7.6728e-05,  ..., 1.3801e-05, 1.2532e-05,\n",
       "        2.1786e-05])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'fast_dev_run': True,\n",
    "    'pin_memory': True,\n",
    "    'device': device,\n",
    "    'num_workers': 12,\n",
    "    'shuffle': False,\n",
    "    'batch_size': 32,\n",
    "    'logger': comet_logger,\n",
    "    'weights': class_weights_all\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EarlyStopping mode set to min for monitoring avg_val_loss.\n"
     ]
    }
   ],
   "source": [
    "model = Model(X_train, y_train, X_val, y_val, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Running in fast_dev_run mode: will run a full train, val and test loop using a single batch\n",
      "\n",
      "  | Name | Type | Params\n",
      "------------------------------\n",
      "0 | net  | Net  | 101 K \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|█████     | 1/2 [00:03<00:03,  3.55s/it, loss=3.297, v_num=324d]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating: 100%|██████████| 1/1 [00:01<00:00,  1.14s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: avg_val_loss reached 3.29605 (best 3.29605), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v7.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 2/2 [00:05<00:00,  2.54s/it, loss=3.297, v_num=324d]\n",
      "Epoch 0: 100%|██████████| 2/2 [00:05<00:00,  2.65s/it, loss=3.297, v_num=324d]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Saving offline stats to disk before program termination (may take several seconds)\n",
      "COMET INFO: Starting saving the offline archive\n",
      "COMET INFO: To upload this offline experiment, run:\n",
      "    comet upload logs/8b08f162e2d844b2b226fc7cdd1a324d.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.17 s, sys: 2.61 s, total: 6.78 s\n",
      "Wall time: 7.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'pin_memory': True,\n",
    "    'device': device,\n",
    "    'num_workers': 12,\n",
    "    'logger': comet_logger,\n",
    "    'max_epochs': 30,\n",
    "    'lr': 1e-3,\n",
    "    'num_warmup_steps': 2000,\n",
    "    'dropout': 0.2,\n",
    "    'weights': class_weights_all,\n",
    "    'class_weights': class_weights\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EarlyStopping mode set to min for monitoring avg_val_loss.\n"
     ]
    }
   ],
   "source": [
    "model = Model(X_train, y_train, X_val, y_val, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (net): Net(\n",
       "    (fc1): Linear(in_features=768, out_features=128, bias=True)\n",
       "    (fc2): Linear(in_features=128, out_features=26, bias=True)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "    (loss_func): CrossEntropyLoss()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4239/4239 [00:03<00:00, 1110.54it/s]\n",
      "/home/payonear/Cases_recruit/netguru-case/myenv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.021     0.066     0.032      2607\n",
      "           1      0.035     0.169     0.057      5456\n",
      "           2      0.086     0.005     0.010      8314\n",
      "           3      0.119     0.016     0.028     14492\n",
      "           4      0.129     0.002     0.004     16107\n",
      "           5      0.104     0.002     0.004     14493\n",
      "           6      0.115     0.000     0.000     15959\n",
      "           7      0.096     0.009     0.017     13348\n",
      "           8      0.073     0.013     0.023     11014\n",
      "           9      0.068     0.036     0.048      9180\n",
      "          10      0.027     0.002     0.004      3498\n",
      "          11      0.036     0.018     0.024      4258\n",
      "          12      0.026     0.103     0.041      3481\n",
      "          13      0.020     0.022     0.021      2835\n",
      "          14      0.013     0.127     0.023      1853\n",
      "          15      0.009     0.001     0.001      1484\n",
      "          16      0.006     0.017     0.009      1092\n",
      "          17      0.009     0.253     0.018      1001\n",
      "          18      0.000     0.000     0.000       741\n",
      "          19      0.002     0.007     0.003       580\n",
      "          20      0.005     0.055     0.009       841\n",
      "          21      0.004     0.054     0.008       407\n",
      "          22      0.006     0.008     0.007       894\n",
      "          23      0.004     0.033     0.007       546\n",
      "          24      0.000     0.000     0.000       439\n",
      "          25      0.000     0.000     0.000       713\n",
      "\n",
      "    accuracy                          0.023    135633\n",
      "   macro avg      0.039     0.039     0.015    135633\n",
      "weighted avg      0.083     0.023     0.017    135633\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict_eval(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type | Params\n",
      "------------------------------\n",
      "0 | net  | Net  | 101 K \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  70%|██████▉   | 11868/16955 [00:54<00:23, 217.79it/s, loss=2.771, v_num=8cdd]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  70%|███████   | 11888/16955 [00:55<00:23, 213.63it/s, loss=2.771, v_num=8cdd]\n",
      "Epoch 0:  71%|███████   | 11967/16955 [00:55<00:23, 214.66it/s, loss=2.771, v_num=8cdd]\n",
      "Epoch 0:  71%|███████   | 12049/16955 [00:55<00:22, 215.74it/s, loss=2.771, v_num=8cdd]\n",
      "Epoch 0:  72%|███████▏  | 12131/16955 [00:55<00:22, 216.82it/s, loss=2.771, v_num=8cdd]\n",
      "Epoch 0:  72%|███████▏  | 12216/16955 [00:56<00:21, 217.95it/s, loss=2.771, v_num=8cdd]\n",
      "Epoch 0:  73%|███████▎  | 12304/16955 [00:56<00:21, 219.13it/s, loss=2.771, v_num=8cdd]\n",
      "Epoch 0:  73%|███████▎  | 12392/16955 [00:56<00:20, 220.25it/s, loss=2.771, v_num=8cdd]\n",
      "Epoch 0:  74%|███████▎  | 12480/16955 [00:56<00:20, 221.37it/s, loss=2.771, v_num=8cdd]\n",
      "Epoch 0:  74%|███████▍  | 12568/16955 [00:56<00:19, 222.46it/s, loss=2.771, v_num=8cdd]\n",
      "Validating:  14%|█▍        | 702/5087 [00:02<03:19, 21.96it/s]\u001b[A\n",
      "Epoch 0:  75%|███████▍  | 12656/16955 [00:56<00:19, 223.57it/s, loss=2.771, v_num=8cdd]\n",
      "Epoch 0:  75%|███████▌  | 12744/16955 [00:56<00:18, 224.70it/s, loss=2.771, v_num=8cdd]\n",
      "Epoch 0:  76%|███████▌  | 12832/16955 [00:56<00:18, 225.82it/s, loss=2.771, v_num=8cdd]\n",
      "Epoch 0:  76%|███████▌  | 12920/16955 [00:56<00:17, 226.95it/s, loss=2.771, v_num=8cdd]\n",
      "Epoch 0:  77%|███████▋  | 13008/16955 [00:57<00:17, 228.09it/s, loss=2.771, v_num=8cdd]\n",
      "Epoch 0:  77%|███████▋  | 13096/16955 [00:57<00:16, 229.22it/s, loss=2.771, v_num=8cdd]\n",
      "Epoch 0:  78%|███████▊  | 13184/16955 [00:57<00:16, 230.31it/s, loss=2.771, v_num=8cdd]\n",
      "Epoch 0:  78%|███████▊  | 13272/16955 [00:57<00:15, 231.36it/s, loss=2.771, v_num=8cdd]\n",
      "Epoch 0:  79%|███████▉  | 13360/16955 [00:57<00:15, 232.45it/s, loss=2.771, v_num=8cdd]\n",
      "Epoch 0:  79%|███████▉  | 13448/16955 [00:57<00:15, 233.52it/s, loss=2.771, v_num=8cdd]\n",
      "Epoch 0:  80%|███████▉  | 13536/16955 [00:57<00:14, 234.62it/s, loss=2.771, v_num=8cdd]\n",
      "Epoch 0:  80%|████████  | 13624/16955 [00:57<00:14, 235.69it/s, loss=2.771, v_num=8cdd]\n",
      "Epoch 0:  81%|████████  | 13712/16955 [00:57<00:13, 236.78it/s, loss=2.771, v_num=8cdd]\n",
      "Epoch 0:  81%|████████▏ | 13800/16955 [00:58<00:13, 237.86it/s, loss=2.771, v_num=8cdd]\n",
      "Epoch 0:  82%|████████▏ | 13888/16955 [00:58<00:12, 238.94it/s, loss=2.771, v_num=8cdd]\n",
      "Epoch 0:  82%|████████▏ | 13976/16955 [00:58<00:12, 240.00it/s, loss=2.771, v_num=8cdd]\n",
      "Validating:  41%|████▏     | 2110/5087 [00:03<00:03, 748.35it/s]\u001b[A\n",
      "Epoch 0:  83%|████████▎ | 14064/16955 [00:58<00:11, 241.05it/s, loss=2.771, v_num=8cdd]\n",
      "Epoch 0:  83%|████████▎ | 14152/16955 [00:58<00:11, 242.12it/s, loss=2.771, v_num=8cdd]\n",
      "Epoch 0:  84%|████████▍ | 14240/16955 [00:58<00:11, 243.19it/s, loss=2.771, v_num=8cdd]\n",
      "Epoch 0:  85%|████████▍ | 14328/16955 [00:58<00:10, 244.26it/s, loss=2.771, v_num=8cdd]\n",
      "Epoch 0:  85%|████████▌ | 14416/16955 [00:58<00:10, 245.32it/s, loss=2.771, v_num=8cdd]\n",
      "Epoch 0:  86%|████████▌ | 14504/16955 [00:58<00:09, 246.37it/s, loss=2.771, v_num=8cdd]\n",
      "Epoch 0:  86%|████████▌ | 14592/16955 [00:58<00:09, 247.41it/s, loss=2.771, v_num=8cdd]\n",
      "Epoch 0:  87%|████████▋ | 14680/16955 [00:59<00:09, 248.45it/s, loss=2.771, v_num=8cdd]\n",
      "Epoch 0:  87%|████████▋ | 14768/16955 [00:59<00:08, 249.46it/s, loss=2.771, v_num=8cdd]\n",
      "Epoch 0:  88%|████████▊ | 14856/16955 [00:59<00:08, 250.48it/s, loss=2.771, v_num=8cdd]\n",
      "Epoch 0:  88%|████████▊ | 14944/16955 [00:59<00:07, 251.50it/s, loss=2.771, v_num=8cdd]\n",
      "Epoch 0:  89%|████████▊ | 15032/16955 [00:59<00:07, 252.53it/s, loss=2.771, v_num=8cdd]\n",
      "Epoch 0:  89%|████████▉ | 15120/16955 [00:59<00:07, 253.53it/s, loss=2.771, v_num=8cdd]\n",
      "Epoch 0:  90%|████████▉ | 15208/16955 [00:59<00:06, 254.56it/s, loss=2.771, v_num=8cdd]\n",
      "Epoch 0:  90%|█████████ | 15296/16955 [00:59<00:06, 255.58it/s, loss=2.771, v_num=8cdd]\n",
      "Epoch 0:  91%|█████████ | 15384/16955 [00:59<00:06, 256.59it/s, loss=2.771, v_num=8cdd]\n",
      "Epoch 0:  91%|█████████▏| 15472/16955 [01:00<00:05, 257.62it/s, loss=2.771, v_num=8cdd]\n",
      "Epoch 0:  92%|█████████▏| 15560/16955 [01:00<00:05, 258.62it/s, loss=2.771, v_num=8cdd]\n",
      "Epoch 0:  92%|█████████▏| 15648/16955 [01:00<00:05, 259.62it/s, loss=2.771, v_num=8cdd]\n",
      "Epoch 0:  93%|█████████▎| 15736/16955 [01:00<00:04, 260.61it/s, loss=2.771, v_num=8cdd]\n",
      "Validating:  76%|███████▌  | 3869/5087 [00:05<00:01, 819.25it/s]\u001b[A\n",
      "Epoch 0:  93%|█████████▎| 15824/16955 [01:00<00:04, 261.59it/s, loss=2.771, v_num=8cdd]\n",
      "Epoch 0:  94%|█████████▍| 15912/16955 [01:00<00:03, 262.60it/s, loss=2.771, v_num=8cdd]\n",
      "Epoch 0:  94%|█████████▍| 16000/16955 [01:00<00:03, 263.57it/s, loss=2.771, v_num=8cdd]\n",
      "Epoch 0:  95%|█████████▍| 16088/16955 [01:00<00:03, 264.54it/s, loss=2.771, v_num=8cdd]\n",
      "Epoch 0:  95%|█████████▌| 16176/16955 [01:00<00:02, 265.53it/s, loss=2.771, v_num=8cdd]\n",
      "Epoch 0:  96%|█████████▌| 16264/16955 [01:01<00:02, 266.52it/s, loss=2.771, v_num=8cdd]\n",
      "Epoch 0:  96%|█████████▋| 16352/16955 [01:01<00:02, 267.49it/s, loss=2.771, v_num=8cdd]\n",
      "Epoch 0:  97%|█████████▋| 16440/16955 [01:01<00:01, 268.47it/s, loss=2.771, v_num=8cdd]\n",
      "Epoch 0:  97%|█████████▋| 16528/16955 [01:01<00:01, 269.43it/s, loss=2.771, v_num=8cdd]\n",
      "Epoch 0:  98%|█████████▊| 16616/16955 [01:01<00:01, 270.38it/s, loss=2.771, v_num=8cdd]\n",
      "Epoch 0:  99%|█████████▊| 16704/16955 [01:01<00:00, 271.35it/s, loss=2.771, v_num=8cdd]\n",
      "Epoch 0:  99%|█████████▉| 16792/16955 [01:01<00:00, 272.29it/s, loss=2.771, v_num=8cdd]\n",
      "Epoch 0: 100%|█████████▉| 16880/16955 [01:01<00:00, 273.25it/s, loss=2.771, v_num=8cdd]\n",
      "Validating:  99%|█████████▉| 5037/5087 [00:07<00:00, 809.76it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: avg_val_loss reached 2.99739 (best 2.99739), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v8.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 16955/16955 [01:02<00:00, 273.03it/s, loss=2.771, v_num=8cdd]\n",
      "Epoch 1:  70%|██████▉   | 11868/16955 [00:55<00:23, 215.72it/s, loss=2.489, v_num=8cdd]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1:  70%|███████   | 11880/16955 [00:56<00:23, 211.66it/s, loss=2.489, v_num=8cdd]\n",
      "Epoch 1:  71%|███████   | 11968/16955 [00:56<00:23, 212.83it/s, loss=2.489, v_num=8cdd]\n",
      "Epoch 1:  71%|███████   | 12056/16955 [00:56<00:22, 213.99it/s, loss=2.489, v_num=8cdd]\n",
      "Epoch 1:  72%|███████▏  | 12144/16955 [00:56<00:22, 215.15it/s, loss=2.489, v_num=8cdd]\n",
      "Epoch 1:  72%|███████▏  | 12232/16955 [00:56<00:21, 216.30it/s, loss=2.489, v_num=8cdd]\n",
      "Epoch 1:  73%|███████▎  | 12320/16955 [00:56<00:21, 217.43it/s, loss=2.489, v_num=8cdd]\n",
      "Epoch 1:  73%|███████▎  | 12408/16955 [00:56<00:20, 218.59it/s, loss=2.489, v_num=8cdd]\n",
      "Epoch 1:  74%|███████▎  | 12496/16955 [00:56<00:20, 219.72it/s, loss=2.489, v_num=8cdd]\n",
      "Epoch 1:  74%|███████▍  | 12584/16955 [00:56<00:19, 220.85it/s, loss=2.489, v_num=8cdd]\n",
      "Epoch 1:  75%|███████▍  | 12672/16955 [00:57<00:19, 221.96it/s, loss=2.489, v_num=8cdd]\n",
      "Epoch 1:  75%|███████▌  | 12760/16955 [00:57<00:18, 223.06it/s, loss=2.489, v_num=8cdd]\n",
      "Epoch 1:  76%|███████▌  | 12848/16955 [00:57<00:18, 224.18it/s, loss=2.489, v_num=8cdd]\n",
      "Epoch 1:  76%|███████▋  | 12936/16955 [00:57<00:17, 225.30it/s, loss=2.489, v_num=8cdd]\n",
      "Validating:  21%|██        | 1068/5087 [00:02<00:47, 84.94it/s]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 13024/16955 [00:57<00:17, 226.38it/s, loss=2.489, v_num=8cdd]\n",
      "Epoch 1:  77%|███████▋  | 13112/16955 [00:57<00:16, 227.47it/s, loss=2.489, v_num=8cdd]\n",
      "Epoch 1:  78%|███████▊  | 13200/16955 [00:57<00:16, 228.56it/s, loss=2.489, v_num=8cdd]\n",
      "Epoch 1:  78%|███████▊  | 13288/16955 [00:57<00:15, 229.64it/s, loss=2.489, v_num=8cdd]\n",
      "Epoch 1:  79%|███████▉  | 13376/16955 [00:57<00:15, 230.70it/s, loss=2.489, v_num=8cdd]\n",
      "Epoch 1:  79%|███████▉  | 13464/16955 [00:58<00:15, 231.78it/s, loss=2.489, v_num=8cdd]\n",
      "Epoch 1:  80%|███████▉  | 13552/16955 [00:58<00:14, 232.86it/s, loss=2.489, v_num=8cdd]\n",
      "Epoch 1:  80%|████████  | 13640/16955 [00:58<00:14, 233.94it/s, loss=2.489, v_num=8cdd]\n",
      "Epoch 1:  81%|████████  | 13728/16955 [00:58<00:13, 235.00it/s, loss=2.489, v_num=8cdd]\n",
      "Epoch 1:  81%|████████▏ | 13816/16955 [00:58<00:13, 236.06it/s, loss=2.489, v_num=8cdd]\n",
      "Epoch 1:  82%|████████▏ | 13904/16955 [00:58<00:12, 237.12it/s, loss=2.489, v_num=8cdd]\n",
      "Validating:  40%|████      | 2043/5087 [00:03<00:04, 712.34it/s]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 13992/16955 [00:58<00:12, 238.14it/s, loss=2.489, v_num=8cdd]\n",
      "Epoch 1:  83%|████████▎ | 14080/16955 [00:58<00:12, 239.18it/s, loss=2.489, v_num=8cdd]\n",
      "Epoch 1:  84%|████████▎ | 14168/16955 [00:58<00:11, 240.21it/s, loss=2.489, v_num=8cdd]\n",
      "Epoch 1:  84%|████████▍ | 14256/16955 [00:59<00:11, 241.24it/s, loss=2.489, v_num=8cdd]\n",
      "Epoch 1:  85%|████████▍ | 14344/16955 [00:59<00:10, 242.31it/s, loss=2.489, v_num=8cdd]\n",
      "Epoch 1:  85%|████████▌ | 14432/16955 [00:59<00:10, 243.34it/s, loss=2.489, v_num=8cdd]\n",
      "Epoch 1:  86%|████████▌ | 14520/16955 [00:59<00:09, 244.36it/s, loss=2.489, v_num=8cdd]\n",
      "Epoch 1:  86%|████████▌ | 14608/16955 [00:59<00:09, 245.41it/s, loss=2.489, v_num=8cdd]\n",
      "Epoch 1:  87%|████████▋ | 14696/16955 [00:59<00:09, 246.43it/s, loss=2.489, v_num=8cdd]\n",
      "Epoch 1:  87%|████████▋ | 14784/16955 [00:59<00:08, 247.43it/s, loss=2.489, v_num=8cdd]\n",
      "Epoch 1:  88%|████████▊ | 14872/16955 [00:59<00:08, 248.46it/s, loss=2.489, v_num=8cdd]\n",
      "Epoch 1:  88%|████████▊ | 14960/16955 [00:59<00:07, 249.46it/s, loss=2.489, v_num=8cdd]\n",
      "Validating:  61%|██████    | 3098/5087 [00:04<00:02, 792.04it/s]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 15048/16955 [01:00<00:07, 250.46it/s, loss=2.489, v_num=8cdd]\n",
      "Epoch 1:  89%|████████▉ | 15136/16955 [01:00<00:07, 251.46it/s, loss=2.489, v_num=8cdd]\n",
      "Epoch 1:  90%|████████▉ | 15224/16955 [01:00<00:06, 252.44it/s, loss=2.489, v_num=8cdd]\n",
      "Epoch 1:  90%|█████████ | 15312/16955 [01:00<00:06, 253.40it/s, loss=2.489, v_num=8cdd]\n",
      "Epoch 1:  91%|█████████ | 15400/16955 [01:00<00:06, 254.39it/s, loss=2.489, v_num=8cdd]\n",
      "Epoch 1:  91%|█████████▏| 15488/16955 [01:00<00:05, 255.36it/s, loss=2.489, v_num=8cdd]\n",
      "Epoch 1:  92%|█████████▏| 15576/16955 [01:00<00:05, 256.36it/s, loss=2.489, v_num=8cdd]\n",
      "Epoch 1:  92%|█████████▏| 15664/16955 [01:00<00:05, 257.35it/s, loss=2.489, v_num=8cdd]\n",
      "Epoch 1:  93%|█████████▎| 15752/16955 [01:00<00:04, 258.32it/s, loss=2.489, v_num=8cdd]\n",
      "Epoch 1:  93%|█████████▎| 15840/16955 [01:01<00:04, 259.29it/s, loss=2.489, v_num=8cdd]\n",
      "Epoch 1:  94%|█████████▍| 15928/16955 [01:01<00:03, 260.26it/s, loss=2.489, v_num=8cdd]\n",
      "Validating:  80%|███████▉  | 4064/5087 [00:06<00:01, 791.12it/s]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 16016/16955 [01:01<00:03, 261.23it/s, loss=2.489, v_num=8cdd]\n",
      "Epoch 1:  95%|█████████▍| 16104/16955 [01:01<00:03, 262.21it/s, loss=2.489, v_num=8cdd]\n",
      "Epoch 1:  95%|█████████▌| 16192/16955 [01:01<00:02, 263.19it/s, loss=2.489, v_num=8cdd]\n",
      "Epoch 1:  96%|█████████▌| 16280/16955 [01:01<00:02, 264.17it/s, loss=2.489, v_num=8cdd]\n",
      "Epoch 1:  97%|█████████▋| 16368/16955 [01:01<00:02, 265.13it/s, loss=2.489, v_num=8cdd]\n",
      "Epoch 1:  97%|█████████▋| 16456/16955 [01:01<00:01, 266.07it/s, loss=2.489, v_num=8cdd]\n",
      "Epoch 1:  98%|█████████▊| 16544/16955 [01:01<00:01, 267.02it/s, loss=2.489, v_num=8cdd]\n",
      "Epoch 1:  98%|█████████▊| 16632/16955 [01:02<00:01, 267.96it/s, loss=2.489, v_num=8cdd]\n",
      "Epoch 1:  99%|█████████▊| 16720/16955 [01:02<00:00, 268.91it/s, loss=2.489, v_num=8cdd]\n",
      "Epoch 1:  99%|█████████▉| 16808/16955 [01:02<00:00, 269.84it/s, loss=2.489, v_num=8cdd]\n",
      "Epoch 1: 100%|█████████▉| 16896/16955 [01:02<00:00, 270.78it/s, loss=2.489, v_num=8cdd]\n",
      "Validating:  99%|█████████▉| 5051/5087 [00:07<00:00, 798.73it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: avg_val_loss reached 2.89196 (best 2.89196), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v9.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 16955/16955 [01:02<00:00, 270.37it/s, loss=2.489, v_num=8cdd]\n",
      "Epoch 2:  70%|██████▉   | 11868/16955 [00:54<00:23, 218.21it/s, loss=2.514, v_num=8cdd]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2:  70%|███████   | 11880/16955 [00:55<00:23, 213.79it/s, loss=2.514, v_num=8cdd]\n",
      "Epoch 2:  71%|███████   | 11978/16955 [00:55<00:23, 215.16it/s, loss=2.514, v_num=8cdd]\n",
      "Epoch 2:  71%|███████   | 12076/16955 [00:55<00:22, 216.46it/s, loss=2.514, v_num=8cdd]\n",
      "Epoch 2:  72%|███████▏  | 12174/16955 [00:55<00:21, 217.75it/s, loss=2.514, v_num=8cdd]\n",
      "Validating:   6%|▌         | 311/5087 [00:01<21:32,  3.69it/s]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 12272/16955 [00:56<00:21, 219.04it/s, loss=2.514, v_num=8cdd]\n",
      "Epoch 2:  73%|███████▎  | 12370/16955 [00:56<00:20, 220.29it/s, loss=2.514, v_num=8cdd]\n",
      "Epoch 2:  74%|███████▎  | 12468/16955 [00:56<00:20, 221.54it/s, loss=2.514, v_num=8cdd]\n",
      "Epoch 2:  74%|███████▍  | 12566/16955 [00:56<00:19, 222.77it/s, loss=2.514, v_num=8cdd]\n",
      "Validating:  14%|█▍        | 707/5087 [00:02<03:23, 21.47it/s]\u001b[A\n",
      "Epoch 2:  75%|███████▍  | 12664/16955 [00:56<00:19, 224.00it/s, loss=2.514, v_num=8cdd]\n",
      "Epoch 2:  75%|███████▌  | 12762/16955 [00:56<00:18, 225.24it/s, loss=2.514, v_num=8cdd]\n",
      "Epoch 2:  76%|███████▌  | 12860/16955 [00:56<00:18, 226.49it/s, loss=2.514, v_num=8cdd]\n",
      "Epoch 2:  76%|███████▋  | 12958/16955 [00:56<00:17, 227.74it/s, loss=2.514, v_num=8cdd]\n",
      "Epoch 2:  77%|███████▋  | 13056/16955 [00:57<00:17, 228.98it/s, loss=2.514, v_num=8cdd]\n",
      "Validating:  23%|██▎       | 1192/5087 [00:02<00:25, 152.25it/s]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 13154/16955 [00:57<00:16, 230.21it/s, loss=2.514, v_num=8cdd]\n",
      "Epoch 2:  78%|███████▊  | 13252/16955 [00:57<00:16, 231.40it/s, loss=2.514, v_num=8cdd]\n",
      "Epoch 2:  79%|███████▊  | 13350/16955 [00:57<00:15, 232.61it/s, loss=2.514, v_num=8cdd]\n",
      "Epoch 2:  79%|███████▉  | 13448/16955 [00:57<00:14, 233.81it/s, loss=2.514, v_num=8cdd]\n",
      "Epoch 2:  80%|███████▉  | 13546/16955 [00:57<00:14, 234.99it/s, loss=2.514, v_num=8cdd]\n",
      "Validating:  33%|███▎      | 1679/5087 [00:03<00:06, 523.52it/s]\u001b[A\n",
      "Epoch 2:  80%|████████  | 13644/16955 [00:57<00:14, 236.18it/s, loss=2.514, v_num=8cdd]\n",
      "Epoch 2:  81%|████████  | 13742/16955 [00:57<00:13, 237.35it/s, loss=2.514, v_num=8cdd]\n",
      "Epoch 2:  82%|████████▏ | 13840/16955 [00:58<00:13, 238.57it/s, loss=2.514, v_num=8cdd]\n",
      "Epoch 2:  82%|████████▏ | 13938/16955 [00:58<00:12, 239.76it/s, loss=2.514, v_num=8cdd]\n",
      "Epoch 2:  83%|████████▎ | 14036/16955 [00:58<00:12, 240.93it/s, loss=2.514, v_num=8cdd]\n",
      "Validating:  43%|████▎     | 2170/5087 [00:03<00:03, 751.03it/s]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 14134/16955 [00:58<00:11, 242.11it/s, loss=2.514, v_num=8cdd]\n",
      "Epoch 2:  84%|████████▍ | 14232/16955 [00:58<00:11, 243.24it/s, loss=2.514, v_num=8cdd]\n",
      "Epoch 2:  85%|████████▍ | 14330/16955 [00:58<00:10, 244.36it/s, loss=2.514, v_num=8cdd]\n",
      "Epoch 2:  85%|████████▌ | 14428/16955 [00:58<00:10, 245.52it/s, loss=2.514, v_num=8cdd]\n",
      "Validating:  51%|█████     | 2571/5087 [00:04<00:03, 762.70it/s]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 14526/16955 [00:58<00:09, 246.66it/s, loss=2.514, v_num=8cdd]\n",
      "Epoch 2:  86%|████████▋ | 14624/16955 [00:59<00:09, 247.78it/s, loss=2.514, v_num=8cdd]\n",
      "Epoch 2:  87%|████████▋ | 14722/16955 [00:59<00:08, 248.92it/s, loss=2.514, v_num=8cdd]\n",
      "Epoch 2:  87%|████████▋ | 14820/16955 [00:59<00:08, 250.08it/s, loss=2.514, v_num=8cdd]\n",
      "Epoch 2:  88%|████████▊ | 14918/16955 [00:59<00:08, 251.24it/s, loss=2.514, v_num=8cdd]\n",
      "Validating:  60%|██████    | 3061/5087 [00:05<00:02, 803.70it/s]\u001b[A\n",
      "Epoch 2:  89%|████████▊ | 15016/16955 [00:59<00:07, 252.35it/s, loss=2.514, v_num=8cdd]\n",
      "Epoch 2:  89%|████████▉ | 15114/16955 [00:59<00:07, 253.46it/s, loss=2.514, v_num=8cdd]\n",
      "Epoch 2:  90%|████████▉ | 15212/16955 [00:59<00:06, 254.56it/s, loss=2.514, v_num=8cdd]\n",
      "Epoch 2:  90%|█████████ | 15310/16955 [00:59<00:06, 255.68it/s, loss=2.514, v_num=8cdd]\n",
      "Epoch 2:  91%|█████████ | 15408/16955 [00:59<00:06, 256.81it/s, loss=2.514, v_num=8cdd]\n",
      "Validating:  70%|██████▉   | 3547/5087 [00:05<00:01, 805.78it/s]\u001b[A\n",
      "Epoch 2:  91%|█████████▏| 15506/16955 [01:00<00:05, 257.93it/s, loss=2.514, v_num=8cdd]\n",
      "Epoch 2:  92%|█████████▏| 15604/16955 [01:00<00:05, 259.06it/s, loss=2.514, v_num=8cdd]\n",
      "Epoch 2:  93%|█████████▎| 15702/16955 [01:00<00:04, 260.18it/s, loss=2.514, v_num=8cdd]\n",
      "Epoch 2:  93%|█████████▎| 15800/16955 [01:00<00:04, 261.26it/s, loss=2.514, v_num=8cdd]\n",
      "Epoch 2:  94%|█████████▍| 15898/16955 [01:00<00:04, 262.37it/s, loss=2.514, v_num=8cdd]\n",
      "Epoch 2:  94%|█████████▍| 15996/16955 [01:00<00:03, 263.47it/s, loss=2.514, v_num=8cdd]\n",
      "Validating:  81%|████████  | 4130/5087 [00:06<00:01, 815.26it/s]\u001b[A\n",
      "Epoch 2:  95%|█████████▍| 16094/16955 [01:00<00:03, 264.57it/s, loss=2.514, v_num=8cdd]\n",
      "Epoch 2:  95%|█████████▌| 16192/16955 [01:00<00:02, 265.69it/s, loss=2.514, v_num=8cdd]\n",
      "Epoch 2:  96%|█████████▌| 16290/16955 [01:01<00:02, 266.75it/s, loss=2.514, v_num=8cdd]\n",
      "Epoch 2:  97%|█████████▋| 16388/16955 [01:01<00:02, 267.83it/s, loss=2.514, v_num=8cdd]\n",
      "Epoch 2:  97%|█████████▋| 16486/16955 [01:01<00:01, 268.91it/s, loss=2.514, v_num=8cdd]\n",
      "Epoch 2:  98%|█████████▊| 16584/16955 [01:01<00:01, 269.98it/s, loss=2.514, v_num=8cdd]\n",
      "Validating:  93%|█████████▎| 4722/5087 [00:07<00:00, 808.19it/s]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 16682/16955 [01:01<00:01, 271.03it/s, loss=2.514, v_num=8cdd]\n",
      "Epoch 2:  99%|█████████▉| 16780/16955 [01:01<00:00, 272.05it/s, loss=2.514, v_num=8cdd]\n",
      "Epoch 2: 100%|█████████▉| 16878/16955 [01:01<00:00, 273.09it/s, loss=2.514, v_num=8cdd]\n",
      "Validating:  99%|█████████▉| 5048/5087 [00:07<00:00, 778.44it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: avg_val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 16955/16955 [01:02<00:00, 272.84it/s, loss=2.514, v_num=8cdd]\n",
      "Epoch 3:  70%|██████▉   | 11868/16955 [00:54<00:23, 216.66it/s, loss=2.532, v_num=8cdd]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 1/5087 [00:01<1:41:23,  1.20s/it]\u001b[A\n",
      "Epoch 3:  71%|███████   | 11956/16955 [00:56<00:23, 213.07it/s, loss=2.532, v_num=8cdd]\n",
      "Epoch 3:  71%|███████   | 12054/16955 [00:56<00:22, 214.35it/s, loss=2.532, v_num=8cdd]\n",
      "Epoch 3:  72%|███████▏  | 12152/16955 [00:56<00:22, 215.58it/s, loss=2.532, v_num=8cdd]\n",
      "Validating:   6%|▌         | 291/5087 [00:01<23:02,  3.47it/s]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 12250/16955 [00:56<00:21, 216.81it/s, loss=2.532, v_num=8cdd]\n",
      "Epoch 3:  73%|███████▎  | 12348/16955 [00:56<00:21, 218.07it/s, loss=2.532, v_num=8cdd]\n",
      "Epoch 3:  73%|███████▎  | 12446/16955 [00:56<00:20, 219.32it/s, loss=2.532, v_num=8cdd]\n",
      "Epoch 3:  74%|███████▍  | 12544/16955 [00:56<00:19, 220.61it/s, loss=2.532, v_num=8cdd]\n",
      "Epoch 3:  75%|███████▍  | 12642/16955 [00:56<00:19, 221.86it/s, loss=2.532, v_num=8cdd]\n",
      "Validating:  15%|█▌        | 774/5087 [00:02<02:30, 28.58it/s]\u001b[A\n",
      "Epoch 3:  75%|███████▌  | 12740/16955 [00:57<00:18, 223.08it/s, loss=2.532, v_num=8cdd]\n",
      "Epoch 3:  76%|███████▌  | 12838/16955 [00:57<00:18, 224.31it/s, loss=2.532, v_num=8cdd]\n",
      "Epoch 3:  76%|███████▋  | 12936/16955 [00:57<00:17, 225.52it/s, loss=2.532, v_num=8cdd]\n",
      "Epoch 3:  77%|███████▋  | 13034/16955 [00:57<00:17, 226.74it/s, loss=2.532, v_num=8cdd]\n",
      "Validating:  23%|██▎       | 1176/5087 [00:02<00:27, 143.69it/s]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 13132/16955 [00:57<00:16, 227.94it/s, loss=2.532, v_num=8cdd]\n",
      "Epoch 3:  78%|███████▊  | 13230/16955 [00:57<00:16, 229.15it/s, loss=2.532, v_num=8cdd]\n",
      "Epoch 3:  79%|███████▊  | 13328/16955 [00:57<00:15, 230.33it/s, loss=2.532, v_num=8cdd]\n",
      "Epoch 3:  79%|███████▉  | 13426/16955 [00:57<00:15, 231.50it/s, loss=2.532, v_num=8cdd]\n",
      "Epoch 3:  80%|███████▉  | 13524/16955 [00:58<00:14, 232.71it/s, loss=2.532, v_num=8cdd]\n",
      "Validating:  33%|███▎      | 1656/5087 [00:03<00:06, 511.23it/s]\u001b[A\n",
      "Epoch 3:  80%|████████  | 13622/16955 [00:58<00:14, 233.88it/s, loss=2.532, v_num=8cdd]\n",
      "Epoch 3:  81%|████████  | 13720/16955 [00:58<00:13, 235.07it/s, loss=2.532, v_num=8cdd]\n",
      "Epoch 3:  81%|████████▏ | 13818/16955 [00:58<00:13, 236.24it/s, loss=2.532, v_num=8cdd]\n",
      "Epoch 3:  82%|████████▏ | 13916/16955 [00:58<00:12, 237.37it/s, loss=2.532, v_num=8cdd]\n",
      "Validating:  40%|████      | 2055/5087 [00:03<00:04, 699.14it/s]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 14014/16955 [00:58<00:12, 238.51it/s, loss=2.532, v_num=8cdd]\n",
      "Epoch 3:  83%|████████▎ | 14112/16955 [00:58<00:11, 239.66it/s, loss=2.532, v_num=8cdd]\n",
      "Epoch 3:  84%|████████▍ | 14210/16955 [00:59<00:11, 240.81it/s, loss=2.532, v_num=8cdd]\n",
      "Epoch 3:  84%|████████▍ | 14308/16955 [00:59<00:10, 241.98it/s, loss=2.532, v_num=8cdd]\n",
      "Validating:  48%|████▊     | 2447/5087 [00:04<00:03, 769.88it/s]\u001b[A\n",
      "Epoch 3:  85%|████████▍ | 14406/16955 [00:59<00:10, 243.09it/s, loss=2.532, v_num=8cdd]\n",
      "Epoch 3:  86%|████████▌ | 14504/16955 [00:59<00:10, 244.22it/s, loss=2.532, v_num=8cdd]\n",
      "Epoch 3:  86%|████████▌ | 14602/16955 [00:59<00:09, 245.40it/s, loss=2.532, v_num=8cdd]\n",
      "Epoch 3:  87%|████████▋ | 14700/16955 [00:59<00:09, 246.51it/s, loss=2.532, v_num=8cdd]\n",
      "Validating:  56%|█████▌    | 2845/5087 [00:04<00:02, 784.03it/s]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 14798/16955 [00:59<00:08, 247.62it/s, loss=2.532, v_num=8cdd]\n",
      "Epoch 3:  88%|████████▊ | 14896/16955 [00:59<00:08, 248.75it/s, loss=2.532, v_num=8cdd]\n",
      "Epoch 3:  88%|████████▊ | 14994/16955 [01:00<00:07, 249.88it/s, loss=2.532, v_num=8cdd]\n",
      "Epoch 3:  89%|████████▉ | 15092/16955 [01:00<00:07, 251.01it/s, loss=2.532, v_num=8cdd]\n",
      "Epoch 3:  90%|████████▉ | 15190/16955 [01:00<00:07, 252.09it/s, loss=2.532, v_num=8cdd]\n",
      "Validating:  65%|██████▌   | 3325/5087 [00:05<00:02, 775.97it/s]\u001b[A\n",
      "Epoch 3:  90%|█████████ | 15288/16955 [01:00<00:06, 253.14it/s, loss=2.532, v_num=8cdd]\n",
      "Epoch 3:  91%|█████████ | 15386/16955 [01:00<00:06, 254.23it/s, loss=2.532, v_num=8cdd]\n",
      "Epoch 3:  91%|█████████▏| 15484/16955 [01:00<00:05, 255.35it/s, loss=2.532, v_num=8cdd]\n",
      "Epoch 3:  92%|█████████▏| 15582/16955 [01:00<00:05, 256.46it/s, loss=2.532, v_num=8cdd]\n",
      "Validating:  73%|███████▎  | 3722/5087 [00:05<00:01, 789.14it/s]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 15680/16955 [01:00<00:04, 257.55it/s, loss=2.532, v_num=8cdd]\n",
      "Epoch 3:  93%|█████████▎| 15778/16955 [01:01<00:04, 258.64it/s, loss=2.532, v_num=8cdd]\n",
      "Epoch 3:  94%|█████████▎| 15876/16955 [01:01<00:04, 259.67it/s, loss=2.532, v_num=8cdd]\n",
      "Epoch 3:  94%|█████████▍| 15974/16955 [01:01<00:03, 260.74it/s, loss=2.532, v_num=8cdd]\n",
      "Validating:  81%|████████  | 4125/5087 [00:06<00:01, 770.19it/s]\u001b[A\n",
      "Epoch 3:  95%|█████████▍| 16072/16955 [01:01<00:03, 261.78it/s, loss=2.532, v_num=8cdd]\n",
      "Epoch 3:  95%|█████████▌| 16170/16955 [01:01<00:02, 262.85it/s, loss=2.532, v_num=8cdd]\n",
      "Epoch 3:  96%|█████████▌| 16268/16955 [01:01<00:02, 263.89it/s, loss=2.532, v_num=8cdd]\n",
      "Epoch 3:  97%|█████████▋| 16366/16955 [01:01<00:02, 264.94it/s, loss=2.532, v_num=8cdd]\n",
      "Epoch 3:  97%|█████████▋| 16464/16955 [01:01<00:01, 266.00it/s, loss=2.532, v_num=8cdd]\n",
      "Validating:  90%|█████████ | 4601/5087 [00:07<00:00, 784.61it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 16562/16955 [01:02<00:01, 267.06it/s, loss=2.532, v_num=8cdd]\n",
      "Epoch 3:  98%|█████████▊| 16660/16955 [01:02<00:01, 268.13it/s, loss=2.532, v_num=8cdd]\n",
      "Epoch 3:  99%|█████████▉| 16758/16955 [01:02<00:00, 269.21it/s, loss=2.532, v_num=8cdd]\n",
      "Epoch 3:  99%|█████████▉| 16856/16955 [01:02<00:00, 270.24it/s, loss=2.532, v_num=8cdd]\n",
      "Epoch 3: 100%|█████████▉| 16954/16955 [01:02<00:00, 271.30it/s, loss=2.532, v_num=8cdd]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: avg_val_loss reached 2.85683 (best 2.85683), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v8.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 16955/16955 [01:02<00:00, 270.17it/s, loss=2.532, v_num=8cdd]\n",
      "Epoch 4:  70%|██████▉   | 11868/16955 [00:54<00:23, 215.79it/s, loss=2.494, v_num=8cdd]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 1/5087 [00:01<1:48:40,  1.28s/it]\u001b[A\n",
      "Epoch 4:  71%|███████   | 11956/16955 [00:56<00:23, 211.95it/s, loss=2.494, v_num=8cdd]\n",
      "Epoch 4:  71%|███████   | 12054/16955 [00:56<00:22, 213.21it/s, loss=2.494, v_num=8cdd]\n",
      "Epoch 4:  72%|███████▏  | 12152/16955 [00:56<00:22, 214.48it/s, loss=2.494, v_num=8cdd]\n",
      "Epoch 4:  72%|███████▏  | 12250/16955 [00:56<00:21, 215.75it/s, loss=2.494, v_num=8cdd]\n",
      "Validating:   8%|▊         | 385/5087 [00:01<16:58,  4.62it/s]\u001b[A\n",
      "Epoch 4:  73%|███████▎  | 12348/16955 [00:56<00:21, 216.99it/s, loss=2.494, v_num=8cdd]\n",
      "Epoch 4:  73%|███████▎  | 12446/16955 [00:57<00:20, 218.20it/s, loss=2.494, v_num=8cdd]\n",
      "Epoch 4:  74%|███████▍  | 12544/16955 [00:57<00:20, 219.47it/s, loss=2.494, v_num=8cdd]\n",
      "Epoch 4:  75%|███████▍  | 12642/16955 [00:57<00:19, 220.72it/s, loss=2.494, v_num=8cdd]\n",
      "Validating:  15%|█▌        | 782/5087 [00:02<02:41, 26.71it/s]\u001b[A\n",
      "Epoch 4:  75%|███████▌  | 12740/16955 [00:57<00:18, 221.93it/s, loss=2.494, v_num=8cdd]\n",
      "Epoch 4:  76%|███████▌  | 12838/16955 [00:57<00:18, 223.14it/s, loss=2.494, v_num=8cdd]\n",
      "Epoch 4:  76%|███████▋  | 12936/16955 [00:57<00:17, 224.38it/s, loss=2.494, v_num=8cdd]\n",
      "Epoch 4:  77%|███████▋  | 13034/16955 [00:57<00:17, 225.61it/s, loss=2.494, v_num=8cdd]\n",
      "Epoch 4:  77%|███████▋  | 13132/16955 [00:57<00:16, 226.84it/s, loss=2.494, v_num=8cdd]\n",
      "Validating:  25%|██▍       | 1266/5087 [00:02<00:20, 182.08it/s]\u001b[A\n",
      "Epoch 4:  78%|███████▊  | 13230/16955 [00:58<00:16, 228.03it/s, loss=2.494, v_num=8cdd]\n",
      "Epoch 4:  79%|███████▊  | 13328/16955 [00:58<00:15, 229.22it/s, loss=2.494, v_num=8cdd]\n",
      "Epoch 4:  79%|███████▉  | 13426/16955 [00:58<00:15, 230.43it/s, loss=2.494, v_num=8cdd]\n",
      "Epoch 4:  80%|███████▉  | 13524/16955 [00:58<00:14, 231.61it/s, loss=2.494, v_num=8cdd]\n",
      "Validating:  33%|███▎      | 1667/5087 [00:03<00:06, 504.79it/s]\u001b[A\n",
      "Epoch 4:  80%|████████  | 13622/16955 [00:58<00:14, 232.76it/s, loss=2.494, v_num=8cdd]\n",
      "Epoch 4:  81%|████████  | 13720/16955 [00:58<00:13, 233.91it/s, loss=2.494, v_num=8cdd]\n",
      "Epoch 4:  81%|████████▏ | 13818/16955 [00:58<00:13, 235.09it/s, loss=2.494, v_num=8cdd]\n",
      "Epoch 4:  82%|████████▏ | 13916/16955 [00:58<00:12, 236.28it/s, loss=2.494, v_num=8cdd]\n",
      "Epoch 4:  83%|████████▎ | 14014/16955 [00:59<00:12, 237.46it/s, loss=2.494, v_num=8cdd]\n",
      "Validating:  42%|████▏     | 2148/5087 [00:04<00:03, 743.16it/s]\u001b[A\n",
      "Epoch 4:  83%|████████▎ | 14112/16955 [00:59<00:11, 238.59it/s, loss=2.494, v_num=8cdd]\n",
      "Epoch 4:  84%|████████▍ | 14210/16955 [00:59<00:11, 239.74it/s, loss=2.494, v_num=8cdd]\n",
      "Epoch 4:  84%|████████▍ | 14308/16955 [00:59<00:10, 240.90it/s, loss=2.494, v_num=8cdd]\n",
      "Epoch 4:  85%|████████▍ | 14406/16955 [00:59<00:10, 242.05it/s, loss=2.494, v_num=8cdd]\n",
      "Validating:  50%|█████     | 2551/5087 [00:04<00:03, 776.26it/s]\u001b[A\n",
      "Epoch 4:  86%|████████▌ | 14504/16955 [00:59<00:10, 243.20it/s, loss=2.494, v_num=8cdd]\n",
      "Epoch 4:  86%|████████▌ | 14602/16955 [00:59<00:09, 244.33it/s, loss=2.494, v_num=8cdd]\n",
      "Epoch 4:  87%|████████▋ | 14700/16955 [00:59<00:09, 245.46it/s, loss=2.494, v_num=8cdd]\n",
      "Epoch 4:  87%|████████▋ | 14798/16955 [01:00<00:08, 246.57it/s, loss=2.494, v_num=8cdd]\n",
      "Epoch 4:  88%|████████▊ | 14896/16955 [01:00<00:08, 247.71it/s, loss=2.494, v_num=8cdd]\n",
      "Validating:  60%|█████▉    | 3041/5087 [00:05<00:02, 790.18it/s]\u001b[A\n",
      "Epoch 4:  88%|████████▊ | 14994/16955 [01:00<00:07, 248.83it/s, loss=2.494, v_num=8cdd]\n",
      "Epoch 4:  89%|████████▉ | 15092/16955 [01:00<00:07, 249.95it/s, loss=2.494, v_num=8cdd]\n",
      "Epoch 4:  90%|████████▉ | 15190/16955 [01:00<00:07, 251.06it/s, loss=2.494, v_num=8cdd]\n",
      "Epoch 4:  90%|█████████ | 15288/16955 [01:00<00:06, 252.18it/s, loss=2.494, v_num=8cdd]\n",
      "Epoch 4:  91%|█████████ | 15386/16955 [01:00<00:06, 253.30it/s, loss=2.494, v_num=8cdd]\n",
      "Validating:  69%|██████▉   | 3531/5087 [00:05<00:01, 804.97it/s]\u001b[A\n",
      "Epoch 4:  91%|█████████▏| 15484/16955 [01:00<00:05, 254.39it/s, loss=2.494, v_num=8cdd]\n",
      "Epoch 4:  92%|█████████▏| 15582/16955 [01:00<00:05, 255.50it/s, loss=2.494, v_num=8cdd]\n",
      "Epoch 4:  92%|█████████▏| 15680/16955 [01:01<00:04, 256.61it/s, loss=2.494, v_num=8cdd]\n",
      "Epoch 4:  93%|█████████▎| 15778/16955 [01:01<00:04, 257.70it/s, loss=2.494, v_num=8cdd]\n",
      "Epoch 4:  94%|█████████▎| 15876/16955 [01:01<00:04, 258.76it/s, loss=2.494, v_num=8cdd]\n",
      "Epoch 4:  94%|█████████▍| 15974/16955 [01:01<00:03, 259.85it/s, loss=2.494, v_num=8cdd]\n",
      "Validating:  81%|████████  | 4106/5087 [00:06<00:01, 787.57it/s]\u001b[A\n",
      "Epoch 4:  95%|█████████▍| 16072/16955 [01:01<00:03, 260.90it/s, loss=2.494, v_num=8cdd]\n",
      "Epoch 4:  95%|█████████▌| 16170/16955 [01:01<00:02, 261.97it/s, loss=2.494, v_num=8cdd]\n",
      "Epoch 4:  96%|█████████▌| 16268/16955 [01:01<00:02, 263.04it/s, loss=2.494, v_num=8cdd]\n",
      "Epoch 4:  97%|█████████▋| 16366/16955 [01:01<00:02, 264.10it/s, loss=2.494, v_num=8cdd]\n",
      "Validating:  89%|████████▊ | 4513/5087 [00:06<00:00, 799.53it/s]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 16464/16955 [01:02<00:01, 265.14it/s, loss=2.494, v_num=8cdd]\n",
      "Epoch 4:  98%|█████████▊| 16562/16955 [01:02<00:01, 266.21it/s, loss=2.494, v_num=8cdd]\n",
      "Epoch 4:  98%|█████████▊| 16660/16955 [01:02<00:01, 267.22it/s, loss=2.494, v_num=8cdd]\n",
      "Epoch 4:  99%|█████████▉| 16758/16955 [01:02<00:00, 268.26it/s, loss=2.494, v_num=8cdd]\n",
      "Epoch 4:  99%|█████████▉| 16856/16955 [01:02<00:00, 269.29it/s, loss=2.494, v_num=8cdd]\n",
      "Validating:  98%|█████████▊| 4992/5087 [00:07<00:00, 776.79it/s]\u001b[A\n",
      "Epoch 4: 100%|█████████▉| 16954/16955 [01:02<00:00, 270.30it/s, loss=2.494, v_num=8cdd]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: avg_val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 16955/16955 [01:02<00:00, 269.31it/s, loss=2.494, v_num=8cdd]\n",
      "Epoch 5:  70%|██████▉   | 11868/16955 [00:54<00:23, 215.83it/s, loss=2.382, v_num=8cdd]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 1/5087 [00:01<1:55:44,  1.37s/it]\u001b[A\n",
      "Epoch 5:  71%|███████   | 11956/16955 [00:56<00:23, 211.69it/s, loss=2.382, v_num=8cdd]\n",
      "Epoch 5:  71%|███████   | 12054/16955 [00:56<00:23, 212.97it/s, loss=2.382, v_num=8cdd]\n",
      "Epoch 5:  72%|███████▏  | 12152/16955 [00:56<00:22, 214.25it/s, loss=2.382, v_num=8cdd]\n",
      "Epoch 5:  72%|███████▏  | 12250/16955 [00:56<00:21, 215.50it/s, loss=2.382, v_num=8cdd]\n",
      "Validating:   8%|▊         | 390/5087 [00:01<18:02,  4.34it/s]\u001b[A\n",
      "Epoch 5:  73%|███████▎  | 12348/16955 [00:56<00:21, 216.73it/s, loss=2.382, v_num=8cdd]\n",
      "Epoch 5:  73%|███████▎  | 12446/16955 [00:57<00:20, 217.98it/s, loss=2.382, v_num=8cdd]\n",
      "Epoch 5:  74%|███████▍  | 12544/16955 [00:57<00:20, 219.24it/s, loss=2.382, v_num=8cdd]\n",
      "Epoch 5:  75%|███████▍  | 12642/16955 [00:57<00:19, 220.47it/s, loss=2.382, v_num=8cdd]\n",
      "Validating:  16%|█▌        | 789/5087 [00:02<02:51, 25.12it/s]\u001b[A\n",
      "Epoch 5:  75%|███████▌  | 12740/16955 [00:57<00:19, 221.69it/s, loss=2.382, v_num=8cdd]\n",
      "Epoch 5:  76%|███████▌  | 12838/16955 [00:57<00:18, 222.90it/s, loss=2.382, v_num=8cdd]\n",
      "Epoch 5:  76%|███████▋  | 12936/16955 [00:57<00:17, 224.13it/s, loss=2.382, v_num=8cdd]\n",
      "Epoch 5:  77%|███████▋  | 13034/16955 [00:57<00:17, 225.35it/s, loss=2.382, v_num=8cdd]\n",
      "Epoch 5:  77%|███████▋  | 13132/16955 [00:57<00:16, 226.58it/s, loss=2.382, v_num=8cdd]\n",
      "Validating:  25%|██▌       | 1273/5087 [00:02<00:22, 173.11it/s]\u001b[A\n",
      "Epoch 5:  78%|███████▊  | 13230/16955 [00:58<00:16, 227.79it/s, loss=2.382, v_num=8cdd]\n",
      "Epoch 5:  79%|███████▊  | 13328/16955 [00:58<00:15, 229.01it/s, loss=2.382, v_num=8cdd]\n",
      "Epoch 5:  79%|███████▉  | 13426/16955 [00:58<00:15, 230.20it/s, loss=2.382, v_num=8cdd]\n",
      "Epoch 5:  80%|███████▉  | 13524/16955 [00:58<00:14, 231.42it/s, loss=2.382, v_num=8cdd]\n",
      "Epoch 5:  80%|████████  | 13622/16955 [00:58<00:14, 232.64it/s, loss=2.382, v_num=8cdd]\n",
      "Epoch 5:  81%|████████  | 13720/16955 [00:58<00:13, 233.84it/s, loss=2.382, v_num=8cdd]\n",
      "Validating:  36%|███▋      | 1856/5087 [00:03<00:05, 634.20it/s]\u001b[A\n",
      "Epoch 5:  81%|████████▏ | 13818/16955 [00:58<00:13, 235.02it/s, loss=2.382, v_num=8cdd]\n",
      "Epoch 5:  82%|████████▏ | 13916/16955 [00:58<00:12, 236.22it/s, loss=2.382, v_num=8cdd]\n",
      "Epoch 5:  83%|████████▎ | 14014/16955 [00:59<00:12, 237.39it/s, loss=2.382, v_num=8cdd]\n",
      "Epoch 5:  83%|████████▎ | 14112/16955 [00:59<00:11, 238.57it/s, loss=2.382, v_num=8cdd]\n",
      "Epoch 5:  84%|████████▍ | 14210/16955 [00:59<00:11, 239.73it/s, loss=2.382, v_num=8cdd]\n",
      "Epoch 5:  84%|████████▍ | 14308/16955 [00:59<00:10, 240.85it/s, loss=2.382, v_num=8cdd]\n",
      "Validating:  48%|████▊     | 2440/5087 [00:04<00:03, 766.02it/s]\u001b[A\n",
      "Epoch 5:  85%|████████▍ | 14406/16955 [00:59<00:10, 242.01it/s, loss=2.382, v_num=8cdd]\n",
      "Epoch 5:  86%|████████▌ | 14504/16955 [00:59<00:10, 243.15it/s, loss=2.382, v_num=8cdd]\n",
      "Epoch 5:  86%|████████▌ | 14602/16955 [00:59<00:09, 244.31it/s, loss=2.382, v_num=8cdd]\n",
      "Epoch 5:  87%|████████▋ | 14700/16955 [00:59<00:09, 245.47it/s, loss=2.382, v_num=8cdd]\n",
      "Epoch 5:  87%|████████▋ | 14798/16955 [01:00<00:08, 246.62it/s, loss=2.382, v_num=8cdd]\n",
      "Validating:  58%|█████▊    | 2934/5087 [00:05<00:02, 812.38it/s]\u001b[A\n",
      "Epoch 5:  88%|████████▊ | 14896/16955 [01:00<00:08, 247.73it/s, loss=2.382, v_num=8cdd]\n",
      "Epoch 5:  88%|████████▊ | 14994/16955 [01:00<00:07, 248.88it/s, loss=2.382, v_num=8cdd]\n",
      "Epoch 5:  89%|████████▉ | 15092/16955 [01:00<00:07, 250.01it/s, loss=2.382, v_num=8cdd]\n",
      "Epoch 5:  90%|████████▉ | 15190/16955 [01:00<00:07, 251.12it/s, loss=2.382, v_num=8cdd]\n",
      "Epoch 5:  90%|█████████ | 15288/16955 [01:00<00:06, 252.20it/s, loss=2.382, v_num=8cdd]\n",
      "Validating:  67%|██████▋   | 3426/5087 [00:05<00:02, 789.57it/s]\u001b[A\n",
      "Epoch 5:  91%|█████████ | 15386/16955 [01:00<00:06, 253.31it/s, loss=2.382, v_num=8cdd]\n",
      "Epoch 5:  91%|█████████▏| 15484/16955 [01:00<00:05, 254.41it/s, loss=2.382, v_num=8cdd]\n",
      "Epoch 5:  92%|█████████▏| 15582/16955 [01:00<00:05, 255.52it/s, loss=2.382, v_num=8cdd]\n",
      "Epoch 5:  92%|█████████▏| 15680/16955 [01:01<00:04, 256.62it/s, loss=2.382, v_num=8cdd]\n",
      "Epoch 5:  93%|█████████▎| 15778/16955 [01:01<00:04, 257.68it/s, loss=2.382, v_num=8cdd]\n",
      "Validating:  77%|███████▋  | 3918/5087 [00:06<00:01, 787.41it/s]\u001b[A\n",
      "Epoch 5:  94%|█████████▎| 15876/16955 [01:01<00:04, 258.76it/s, loss=2.382, v_num=8cdd]\n",
      "Epoch 5:  94%|█████████▍| 15974/16955 [01:01<00:03, 259.87it/s, loss=2.382, v_num=8cdd]\n",
      "Epoch 5:  95%|█████████▍| 16072/16955 [01:01<00:03, 260.96it/s, loss=2.382, v_num=8cdd]\n",
      "Epoch 5:  95%|█████████▌| 16170/16955 [01:01<00:02, 262.03it/s, loss=2.382, v_num=8cdd]\n",
      "Epoch 5:  96%|█████████▌| 16268/16955 [01:01<00:02, 263.11it/s, loss=2.382, v_num=8cdd]\n",
      "Epoch 5:  97%|█████████▋| 16366/16955 [01:01<00:02, 264.20it/s, loss=2.382, v_num=8cdd]\n",
      "Validating:  89%|████████▊ | 4502/5087 [00:06<00:00, 820.92it/s]\u001b[A\n",
      "Epoch 5:  97%|█████████▋| 16464/16955 [01:02<00:01, 265.28it/s, loss=2.382, v_num=8cdd]\n",
      "Epoch 5:  98%|█████████▊| 16562/16955 [01:02<00:01, 266.34it/s, loss=2.382, v_num=8cdd]\n",
      "Epoch 5:  98%|█████████▊| 16660/16955 [01:02<00:01, 267.41it/s, loss=2.382, v_num=8cdd]\n",
      "Epoch 5:  99%|█████████▉| 16758/16955 [01:02<00:00, 268.47it/s, loss=2.382, v_num=8cdd]\n",
      "Epoch 5:  99%|█████████▉| 16856/16955 [01:02<00:00, 269.51it/s, loss=2.382, v_num=8cdd]\n",
      "Epoch 5: 100%|█████████▉| 16954/16955 [01:02<00:00, 270.57it/s, loss=2.382, v_num=8cdd]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: avg_val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 16955/16955 [01:02<00:00, 269.57it/s, loss=2.382, v_num=8cdd]\n",
      "Epoch 6:  70%|██████▉   | 11868/16955 [00:55<00:23, 213.89it/s, loss=2.348, v_num=8cdd]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 1/5087 [00:01<2:07:49,  1.51s/it]\u001b[A\n",
      "Epoch 6:  71%|███████   | 11956/16955 [00:57<00:23, 209.31it/s, loss=2.348, v_num=8cdd]\n",
      "Epoch 6:  71%|███████   | 12054/16955 [00:57<00:23, 210.56it/s, loss=2.348, v_num=8cdd]\n",
      "Epoch 6:  72%|███████▏  | 12152/16955 [00:57<00:22, 211.83it/s, loss=2.348, v_num=8cdd]\n",
      "Epoch 6:  72%|███████▏  | 12250/16955 [00:57<00:22, 213.10it/s, loss=2.348, v_num=8cdd]\n",
      "Validating:   8%|▊         | 394/5087 [00:02<19:54,  3.93it/s]\u001b[A\n",
      "Epoch 6:  73%|███████▎  | 12348/16955 [00:57<00:21, 214.35it/s, loss=2.348, v_num=8cdd]\n",
      "Epoch 6:  73%|███████▎  | 12446/16955 [00:57<00:20, 215.58it/s, loss=2.348, v_num=8cdd]\n",
      "Epoch 6:  74%|███████▍  | 12544/16955 [00:57<00:20, 216.79it/s, loss=2.348, v_num=8cdd]\n",
      "Epoch 6:  75%|███████▍  | 12642/16955 [00:57<00:19, 218.00it/s, loss=2.348, v_num=8cdd]\n",
      "Validating:  15%|█▌        | 783/5087 [00:02<03:08, 22.80it/s]\u001b[A\n",
      "Epoch 6:  75%|███████▌  | 12740/16955 [00:58<00:19, 219.20it/s, loss=2.348, v_num=8cdd]\n",
      "Epoch 6:  76%|███████▌  | 12838/16955 [00:58<00:18, 220.44it/s, loss=2.348, v_num=8cdd]\n",
      "Epoch 6:  76%|███████▋  | 12936/16955 [00:58<00:18, 221.67it/s, loss=2.348, v_num=8cdd]\n",
      "Epoch 6:  77%|███████▋  | 13034/16955 [00:58<00:17, 222.83it/s, loss=2.348, v_num=8cdd]\n",
      "Validating:  23%|██▎       | 1182/5087 [00:03<00:33, 118.32it/s]\u001b[A\n",
      "Epoch 6:  77%|███████▋  | 13132/16955 [00:58<00:17, 224.00it/s, loss=2.348, v_num=8cdd]\n",
      "Epoch 6:  78%|███████▊  | 13230/16955 [00:58<00:16, 225.17it/s, loss=2.348, v_num=8cdd]\n",
      "Epoch 6:  79%|███████▊  | 13328/16955 [00:58<00:16, 226.37it/s, loss=2.348, v_num=8cdd]\n",
      "Epoch 6:  79%|███████▉  | 13426/16955 [00:59<00:15, 227.56it/s, loss=2.348, v_num=8cdd]\n",
      "Epoch 6:  80%|███████▉  | 13524/16955 [00:59<00:14, 228.75it/s, loss=2.348, v_num=8cdd]\n",
      "Validating:  33%|███▎      | 1659/5087 [00:03<00:07, 475.69it/s]\u001b[A\n",
      "Epoch 6:  80%|████████  | 13622/16955 [00:59<00:14, 229.93it/s, loss=2.348, v_num=8cdd]\n",
      "Epoch 6:  81%|████████  | 13720/16955 [00:59<00:13, 231.12it/s, loss=2.348, v_num=8cdd]\n",
      "Epoch 6:  81%|████████▏ | 13818/16955 [00:59<00:13, 232.29it/s, loss=2.348, v_num=8cdd]\n",
      "Epoch 6:  82%|████████▏ | 13916/16955 [00:59<00:13, 233.46it/s, loss=2.348, v_num=8cdd]\n",
      "Epoch 6:  83%|████████▎ | 14014/16955 [00:59<00:12, 234.62it/s, loss=2.348, v_num=8cdd]\n",
      "Validating:  42%|████▏     | 2153/5087 [00:04<00:03, 743.81it/s]\u001b[A\n",
      "Epoch 6:  83%|████████▎ | 14112/16955 [00:59<00:12, 235.76it/s, loss=2.348, v_num=8cdd]\n",
      "Epoch 6:  84%|████████▍ | 14210/16955 [00:59<00:11, 236.86it/s, loss=2.348, v_num=8cdd]\n",
      "Epoch 6:  84%|████████▍ | 14308/16955 [01:00<00:11, 237.99it/s, loss=2.348, v_num=8cdd]\n",
      "Epoch 6:  85%|████████▍ | 14406/16955 [01:00<00:10, 239.10it/s, loss=2.348, v_num=8cdd]\n",
      "Validating:  50%|█████     | 2547/5087 [00:04<00:03, 746.10it/s]\u001b[A\n",
      "Epoch 6:  86%|████████▌ | 14504/16955 [01:00<00:10, 240.20it/s, loss=2.348, v_num=8cdd]\n",
      "Epoch 6:  86%|████████▌ | 14602/16955 [01:00<00:09, 241.35it/s, loss=2.348, v_num=8cdd]\n",
      "Epoch 6:  87%|████████▋ | 14700/16955 [01:00<00:09, 242.50it/s, loss=2.348, v_num=8cdd]\n",
      "Epoch 6:  87%|████████▋ | 14798/16955 [01:00<00:08, 243.65it/s, loss=2.348, v_num=8cdd]\n",
      "Epoch 6:  88%|████████▊ | 14896/16955 [01:00<00:08, 244.78it/s, loss=2.348, v_num=8cdd]\n",
      "Validating:  60%|█████▉    | 3040/5087 [00:05<00:02, 813.15it/s]\u001b[A\n",
      "Epoch 6:  88%|████████▊ | 14994/16955 [01:00<00:07, 245.91it/s, loss=2.348, v_num=8cdd]\n",
      "Epoch 6:  89%|████████▉ | 15092/16955 [01:01<00:07, 247.04it/s, loss=2.348, v_num=8cdd]\n",
      "Epoch 6:  90%|████████▉ | 15190/16955 [01:01<00:07, 248.15it/s, loss=2.348, v_num=8cdd]\n",
      "Epoch 6:  90%|█████████ | 15288/16955 [01:01<00:06, 249.21it/s, loss=2.348, v_num=8cdd]\n",
      "Epoch 6:  91%|█████████ | 15386/16955 [01:01<00:06, 250.28it/s, loss=2.348, v_num=8cdd]\n",
      "Epoch 6:  91%|█████████▏| 15484/16955 [01:01<00:05, 251.39it/s, loss=2.348, v_num=8cdd]\n",
      "Validating:  71%|███████   | 3616/5087 [00:06<00:01, 787.43it/s]\u001b[A\n",
      "Epoch 6:  92%|█████████▏| 15582/16955 [01:01<00:05, 252.49it/s, loss=2.348, v_num=8cdd]\n",
      "Epoch 6:  92%|█████████▏| 15680/16955 [01:01<00:05, 253.58it/s, loss=2.348, v_num=8cdd]\n",
      "Epoch 6:  93%|█████████▎| 15778/16955 [01:01<00:04, 254.68it/s, loss=2.348, v_num=8cdd]\n",
      "Epoch 6:  94%|█████████▎| 15876/16955 [01:02<00:04, 255.78it/s, loss=2.348, v_num=8cdd]\n",
      "Epoch 6:  94%|█████████▍| 15974/16955 [01:02<00:03, 256.86it/s, loss=2.348, v_num=8cdd]\n",
      "Validating:  81%|████████  | 4117/5087 [00:06<00:01, 818.45it/s]\u001b[A\n",
      "Epoch 6:  95%|█████████▍| 16072/16955 [01:02<00:03, 257.94it/s, loss=2.348, v_num=8cdd]\n",
      "Epoch 6:  95%|█████████▌| 16170/16955 [01:02<00:03, 259.01it/s, loss=2.348, v_num=8cdd]\n",
      "Epoch 6:  96%|█████████▌| 16268/16955 [01:02<00:02, 260.09it/s, loss=2.348, v_num=8cdd]\n",
      "Epoch 6:  97%|█████████▋| 16366/16955 [01:02<00:02, 261.15it/s, loss=2.348, v_num=8cdd]\n",
      "Epoch 6:  97%|█████████▋| 16464/16955 [01:02<00:01, 262.19it/s, loss=2.348, v_num=8cdd]\n",
      "Epoch 6:  98%|█████████▊| 16562/16955 [01:02<00:01, 263.26it/s, loss=2.348, v_num=8cdd]\n",
      "Validating:  92%|█████████▏| 4698/5087 [00:07<00:00, 812.00it/s]\u001b[A\n",
      "Epoch 6:  98%|█████████▊| 16660/16955 [01:03<00:01, 264.31it/s, loss=2.348, v_num=8cdd]\n",
      "Epoch 6:  99%|█████████▉| 16758/16955 [01:03<00:00, 265.33it/s, loss=2.348, v_num=8cdd]\n",
      "Epoch 6:  99%|█████████▉| 16856/16955 [01:03<00:00, 266.29it/s, loss=2.348, v_num=8cdd]\n",
      "Epoch 6: 100%|█████████▉| 16954/16955 [01:03<00:00, 267.31it/s, loss=2.348, v_num=8cdd]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: avg_val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 16955/16955 [01:03<00:00, 266.30it/s, loss=2.348, v_num=8cdd]\n",
      "Epoch 6: 100%|██████████| 16955/16955 [01:04<00:00, 263.28it/s, loss=2.348, v_num=8cdd]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Starting saving the offline archive\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: To upload this offline experiment, run:\n",
      "    comet upload logs/29e71d43977b4b718b5a0fec6f2c8cdd.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 30s, sys: 1min 12s, total: 8min 43s\n",
      "Wall time: 7min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EarlyStopping mode set to min for monitoring avg_val_loss.\n"
     ]
    }
   ],
   "source": [
    "age_model = Model.load_from_checkpoint(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, hparams=hparams, \\\n",
    "                                   checkpoint_path=\"./checkpoints/model-outputs-v8.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (net): Net(\n",
       "    (fc1): Linear(in_features=768, out_features=128, bias=True)\n",
       "    (fc2): Linear(in_features=128, out_features=26, bias=True)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "    (loss_func): CrossEntropyLoss()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4239/4239 [00:04<00:00, 1017.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.070     0.154     0.096      2607\n",
      "           1      0.120     0.415     0.186      5456\n",
      "           2      0.132     0.041     0.062      8314\n",
      "           3      0.168     0.066     0.095     14492\n",
      "           4      0.218     0.215     0.216     16107\n",
      "           5      0.163     0.032     0.054     14493\n",
      "           6      0.169     0.052     0.079     15959\n",
      "           7      0.153     0.077     0.102     13348\n",
      "           8      0.155     0.009     0.017     11014\n",
      "           9      0.104     0.017     0.029      9180\n",
      "          10      0.051     0.036     0.042      3498\n",
      "          11      0.237     0.178     0.204      4258\n",
      "          12      0.061     0.103     0.077      3481\n",
      "          13      0.066     0.071     0.069      2835\n",
      "          14      0.103     0.104     0.103      1853\n",
      "          15      0.038     0.206     0.064      1484\n",
      "          16      0.025     0.107     0.040      1092\n",
      "          17      0.073     0.296     0.117      1001\n",
      "          18      0.021     0.173     0.038       741\n",
      "          19      0.042     0.264     0.072       580\n",
      "          20      0.042     0.231     0.070       841\n",
      "          21      0.022     0.206     0.040       407\n",
      "          22      0.028     0.198     0.049       894\n",
      "          23      0.029     0.267     0.052       546\n",
      "          24      0.028     0.278     0.051       439\n",
      "          25      0.068     0.314     0.112       713\n",
      "\n",
      "    accuracy                          0.100    135633\n",
      "   macro avg      0.092     0.158     0.082    135633\n",
      "weighted avg      0.146     0.100     0.094    135633\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = age_model.predict_eval(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Averaged weighted F-1 Score equals 9.4% which is considerably better than for random model, still not satisfactory. But again, predicting text author's age is extremely complex task. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we remember, numerous records have not specified the topic. We probably not interested in predicting unknown industry. So I remove records with no topic specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_df = df2[df2.topic != 'indUnk'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(428278, 10)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again classes mapping and samples split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_class2idx = {k: v for v, k in enumerate(sorted(topic_df['topic'].unique()))}\n",
    "topic_idx2class = {v: k for k, v in topic_class2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accounting': 0,\n",
       " 'Advertising': 1,\n",
       " 'Agriculture': 2,\n",
       " 'Architecture': 3,\n",
       " 'Arts': 4,\n",
       " 'Automotive': 5,\n",
       " 'Banking': 6,\n",
       " 'Biotech': 7,\n",
       " 'BusinessServices': 8,\n",
       " 'Chemicals': 9,\n",
       " 'Communications-Media': 10,\n",
       " 'Construction': 11,\n",
       " 'Consulting': 12,\n",
       " 'Education': 13,\n",
       " 'Engineering': 14,\n",
       " 'Environment': 15,\n",
       " 'Fashion': 16,\n",
       " 'Government': 17,\n",
       " 'HumanResources': 18,\n",
       " 'Internet': 19,\n",
       " 'InvestmentBanking': 20,\n",
       " 'Law': 21,\n",
       " 'LawEnforcement-Security': 22,\n",
       " 'Manufacturing': 23,\n",
       " 'Maritime': 24,\n",
       " 'Marketing': 25,\n",
       " 'Military': 26,\n",
       " 'Museums-Libraries': 27,\n",
       " 'Non-Profit': 28,\n",
       " 'Publishing': 29,\n",
       " 'RealEstate': 30,\n",
       " 'Religion': 31,\n",
       " 'Science': 32,\n",
       " 'Sports-Recreation': 33,\n",
       " 'Student': 34,\n",
       " 'Technology': 35,\n",
       " 'Telecommunications': 36,\n",
       " 'Tourism': 37,\n",
       " 'Transportation': 38}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_class2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_df['topic'] = topic_df['topic'].map(topic_class2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = topic_df['vectors'].values\n",
    "y = topic_df['topic'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=17)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.3, stratify=y_trainval, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_list = torch.tensor(y_train)\n",
    "class_count = [i for i in get_class_distribution('topic').values()]\n",
    "class_weights = 1./torch.tensor(class_count, dtype=torch.float) \n",
    "class_weights_all = class_weights[target_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'fast_dev_run': True,\n",
    "    'pin_memory': True,\n",
    "    'device': device,\n",
    "    'num_workers': 12,\n",
    "    'shuffle': False,\n",
    "    'batch_size': 32,\n",
    "    'logger': comet_logger,\n",
    "    'weights': class_weights_all\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EarlyStopping mode set to min for monitoring avg_val_loss.\n"
     ]
    }
   ],
   "source": [
    "model = Model(X_train, y_train, X_val, y_val, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Running in fast_dev_run mode: will run a full train, val and test loop using a single batch\n",
      "\n",
      "  | Name | Type | Params\n",
      "------------------------------\n",
      "0 | net  | Net  | 103 K \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|█████     | 1/2 [00:02<00:02,  2.89s/it, loss=3.661, v_num=5b65]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating: 100%|██████████| 1/1 [00:01<00:00,  1.32s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: avg_val_loss reached 3.64806 (best 3.64806), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v9.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 2/2 [00:04<00:00,  2.22s/it, loss=3.661, v_num=5b65]\n",
      "Epoch 0: 100%|██████████| 2/2 [00:04<00:00,  2.33s/it, loss=3.661, v_num=5b65]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Starting saving the offline archive\n",
      "COMET INFO: To upload this offline experiment, run:\n",
      "    comet upload logs/e377f16ada9f4fb99076389bf20a5b65.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.69 s, sys: 3 s, total: 5.69 s\n",
      "Wall time: 6.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'pin_memory': True,\n",
    "    'device': device,\n",
    "    'num_workers': 12,\n",
    "    'logger': comet_logger,\n",
    "    'max_epochs': 30,\n",
    "    'lr': 1e-3,\n",
    "    'num_warmup_steps': 2000,\n",
    "    'dropout': 0.2,\n",
    "    'weights': class_weights_all\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EarlyStopping mode set to min for monitoring avg_val_loss.\n"
     ]
    }
   ],
   "source": [
    "model = Model(X_train, y_train, X_val, y_val, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (net): Net(\n",
       "    (fc1): Linear(in_features=768, out_features=128, bias=True)\n",
       "    (fc2): Linear(in_features=128, out_features=39, bias=True)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "    (loss_func): CrossEntropyLoss()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2677/2677 [00:02<00:00, 918.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000       764\n",
      "           1      0.010     0.004     0.006       931\n",
      "           2      0.002     0.016     0.003       246\n",
      "           3      0.003     0.034     0.005       325\n",
      "           4      0.070     0.351     0.117      6460\n",
      "           5      0.000     0.000     0.000       248\n",
      "           6      0.000     0.000     0.000       807\n",
      "           7      0.000     0.000     0.000       446\n",
      "           8      0.005     0.003     0.004       895\n",
      "           9      0.000     0.000     0.000       782\n",
      "          10      0.072     0.012     0.020      4003\n",
      "          11      0.000     0.000     0.000       218\n",
      "          12      0.000     0.000     0.000      1169\n",
      "          13      0.062     0.017     0.026      5917\n",
      "          14      0.000     0.000     0.000      2304\n",
      "          15      0.000     0.000     0.000       117\n",
      "          16      0.018     0.008     0.011       967\n",
      "          17      0.027     0.001     0.001      1368\n",
      "          18      0.017     0.005     0.008       601\n",
      "          19      0.000     0.000     0.000      3186\n",
      "          20      0.000     0.000     0.000       256\n",
      "          21      0.000     0.000     0.000      1792\n",
      "          22      0.003     0.051     0.006       373\n",
      "          23      0.000     0.000     0.000       441\n",
      "          24      0.001     0.109     0.001        55\n",
      "          25      0.009     0.098     0.017       942\n",
      "          26      0.005     0.016     0.008       621\n",
      "          27      0.005     0.040     0.009       618\n",
      "          28      0.019     0.001     0.002      2926\n",
      "          29      0.000     0.000     0.000      1542\n",
      "          30      0.000     0.000     0.000       573\n",
      "          31      0.011     0.001     0.002      1042\n",
      "          32      0.019     0.001     0.001      1443\n",
      "          33      0.008     0.023     0.012       604\n",
      "          34      0.378     0.058     0.101     30676\n",
      "          35      0.129     0.011     0.020      8372\n",
      "          36      0.008     0.031     0.013       775\n",
      "          37      0.000     0.000     0.000       387\n",
      "          38      0.007     0.017     0.010       464\n",
      "\n",
      "    accuracy                          0.053     85656\n",
      "   macro avg      0.023     0.023     0.010     85656\n",
      "weighted avg      0.163     0.053     0.051     85656\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/payonear/Cases_recruit/netguru-case/myenv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict_eval(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type | Params\n",
      "------------------------------\n",
      "0 | net  | Net  | 103 K \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  70%|██████▉   | 7495/10708 [00:35<00:15, 213.34it/s, loss=3.237, v_num=6055]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  70%|███████   | 7498/10708 [00:36<00:15, 206.54it/s, loss=3.237, v_num=6055]\n",
      "Epoch 0:  71%|███████   | 7574/10708 [00:36<00:15, 208.06it/s, loss=3.237, v_num=6055]\n",
      "Epoch 0:  71%|███████▏  | 7651/10708 [00:36<00:14, 209.60it/s, loss=3.237, v_num=6055]\n",
      "Epoch 0:  72%|███████▏  | 7735/10708 [00:36<00:14, 211.32it/s, loss=3.237, v_num=6055]\n",
      "Epoch 0:  73%|███████▎  | 7819/10708 [00:36<00:13, 212.97it/s, loss=3.237, v_num=6055]\n",
      "Epoch 0:  74%|███████▍  | 7903/10708 [00:36<00:13, 214.66it/s, loss=3.237, v_num=6055]\n",
      "Epoch 0:  75%|███████▍  | 7987/10708 [00:36<00:12, 216.33it/s, loss=3.237, v_num=6055]\n",
      "Epoch 0:  75%|███████▌  | 8071/10708 [00:37<00:12, 217.98it/s, loss=3.237, v_num=6055]\n",
      "Epoch 0:  76%|███████▌  | 8155/10708 [00:37<00:11, 219.63it/s, loss=3.237, v_num=6055]\n",
      "Epoch 0:  77%|███████▋  | 8240/10708 [00:37<00:11, 221.33it/s, loss=3.237, v_num=6055]\n",
      "Epoch 0:  78%|███████▊  | 8325/10708 [00:37<00:10, 223.00it/s, loss=3.237, v_num=6055]\n",
      "Epoch 0:  79%|███████▊  | 8410/10708 [00:37<00:10, 224.66it/s, loss=3.237, v_num=6055]\n",
      "Epoch 0:  79%|███████▉  | 8495/10708 [00:37<00:09, 226.27it/s, loss=3.237, v_num=6055]\n",
      "Epoch 0:  80%|████████  | 8580/10708 [00:37<00:09, 227.90it/s, loss=3.237, v_num=6055]\n",
      "Epoch 0:  81%|████████  | 8665/10708 [00:37<00:08, 229.53it/s, loss=3.237, v_num=6055]\n",
      "Epoch 0:  82%|████████▏ | 8750/10708 [00:37<00:08, 231.12it/s, loss=3.237, v_num=6055]\n",
      "Epoch 0:  83%|████████▎ | 8835/10708 [00:37<00:08, 232.72it/s, loss=3.237, v_num=6055]\n",
      "Epoch 0:  83%|████████▎ | 8920/10708 [00:38<00:07, 234.27it/s, loss=3.237, v_num=6055]\n",
      "Epoch 0:  84%|████████▍ | 9005/10708 [00:38<00:07, 235.84it/s, loss=3.237, v_num=6055]\n",
      "Epoch 0:  85%|████████▍ | 9090/10708 [00:38<00:06, 237.40it/s, loss=3.237, v_num=6055]\n",
      "Validating:  50%|████▉     | 1595/3213 [00:03<00:03, 462.14it/s]\u001b[A\n",
      "Epoch 0:  86%|████████▌ | 9175/10708 [00:38<00:06, 238.89it/s, loss=3.237, v_num=6055]\n",
      "Epoch 0:  86%|████████▋ | 9260/10708 [00:38<00:06, 240.46it/s, loss=3.237, v_num=6055]\n",
      "Epoch 0:  87%|████████▋ | 9345/10708 [00:38<00:05, 242.02it/s, loss=3.237, v_num=6055]\n",
      "Epoch 0:  88%|████████▊ | 9430/10708 [00:38<00:05, 243.57it/s, loss=3.237, v_num=6055]\n",
      "Epoch 0:  89%|████████▉ | 9515/10708 [00:38<00:04, 245.10it/s, loss=3.237, v_num=6055]\n",
      "Epoch 0:  90%|████████▉ | 9600/10708 [00:38<00:04, 246.64it/s, loss=3.237, v_num=6055]\n",
      "Epoch 0:  90%|█████████ | 9685/10708 [00:39<00:04, 248.18it/s, loss=3.237, v_num=6055]\n",
      "Epoch 0:  91%|█████████ | 9770/10708 [00:39<00:03, 249.71it/s, loss=3.237, v_num=6055]\n",
      "Epoch 0:  92%|█████████▏| 9855/10708 [00:39<00:03, 251.23it/s, loss=3.237, v_num=6055]\n",
      "Epoch 0:  93%|█████████▎| 9940/10708 [00:39<00:03, 252.75it/s, loss=3.237, v_num=6055]\n",
      "Epoch 0:  94%|█████████▎| 10025/10708 [00:39<00:02, 254.21it/s, loss=3.237, v_num=6055]\n",
      "Epoch 0:  94%|█████████▍| 10110/10708 [00:39<00:02, 255.69it/s, loss=3.237, v_num=6055]\n",
      "Epoch 0:  95%|█████████▌| 10195/10708 [00:39<00:01, 257.15it/s, loss=3.237, v_num=6055]\n",
      "Epoch 0:  96%|█████████▌| 10280/10708 [00:39<00:01, 258.61it/s, loss=3.237, v_num=6055]\n",
      "Epoch 0:  97%|█████████▋| 10365/10708 [00:39<00:01, 260.09it/s, loss=3.237, v_num=6055]\n",
      "Epoch 0:  98%|█████████▊| 10450/10708 [00:39<00:00, 261.51it/s, loss=3.237, v_num=6055]\n",
      "Epoch 0:  98%|█████████▊| 10535/10708 [00:40<00:00, 262.88it/s, loss=3.237, v_num=6055]\n",
      "Epoch 0:  99%|█████████▉| 10620/10708 [00:40<00:00, 264.33it/s, loss=3.237, v_num=6055]\n",
      "Epoch 0: 100%|█████████▉| 10705/10708 [00:40<00:00, 265.76it/s, loss=3.237, v_num=6055]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: avg_val_loss reached 3.43765 (best 3.43765), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v10.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 10708/10708 [00:40<00:00, 264.05it/s, loss=3.237, v_num=6055]\n",
      "Epoch 1:  70%|██████▉   | 7495/10708 [00:35<00:15, 213.62it/s, loss=3.069, v_num=6055] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 1/3213 [00:01<1:08:50,  1.29s/it]\u001b[A\n",
      "Epoch 1:  71%|███████   | 7565/10708 [00:36<00:15, 207.38it/s, loss=3.069, v_num=6055]\n",
      "Epoch 1:  71%|███████▏  | 7650/10708 [00:36<00:14, 209.10it/s, loss=3.069, v_num=6055]\n",
      "Epoch 1:  72%|███████▏  | 7735/10708 [00:36<00:14, 210.82it/s, loss=3.069, v_num=6055]\n",
      "Epoch 1:  73%|███████▎  | 7820/10708 [00:36<00:13, 212.54it/s, loss=3.069, v_num=6055]\n",
      "Epoch 1:  74%|███████▍  | 7905/10708 [00:36<00:13, 214.22it/s, loss=3.069, v_num=6055]\n",
      "Epoch 1:  75%|███████▍  | 7990/10708 [00:37<00:12, 215.89it/s, loss=3.069, v_num=6055]\n",
      "Epoch 1:  75%|███████▌  | 8075/10708 [00:37<00:12, 217.56it/s, loss=3.069, v_num=6055]\n",
      "Epoch 1:  76%|███████▌  | 8160/10708 [00:37<00:11, 219.22it/s, loss=3.069, v_num=6055]\n",
      "Epoch 1:  77%|███████▋  | 8245/10708 [00:37<00:11, 220.89it/s, loss=3.069, v_num=6055]\n",
      "Epoch 1:  78%|███████▊  | 8330/10708 [00:37<00:10, 222.56it/s, loss=3.069, v_num=6055]\n",
      "Epoch 1:  79%|███████▊  | 8416/10708 [00:37<00:10, 224.25it/s, loss=3.069, v_num=6055]\n",
      "Epoch 1:  79%|███████▉  | 8502/10708 [00:37<00:09, 225.92it/s, loss=3.069, v_num=6055]\n",
      "Epoch 1:  80%|████████  | 8588/10708 [00:37<00:09, 227.58it/s, loss=3.069, v_num=6055]\n",
      "Epoch 1:  81%|████████  | 8674/10708 [00:37<00:08, 229.20it/s, loss=3.069, v_num=6055]\n",
      "Epoch 1:  82%|████████▏ | 8760/10708 [00:37<00:08, 230.80it/s, loss=3.069, v_num=6055]\n",
      "Epoch 1:  83%|████████▎ | 8846/10708 [00:38<00:08, 232.40it/s, loss=3.069, v_num=6055]\n",
      "Epoch 1:  83%|████████▎ | 8932/10708 [00:38<00:07, 233.97it/s, loss=3.069, v_num=6055]\n",
      "Epoch 1:  84%|████████▍ | 9018/10708 [00:38<00:07, 235.57it/s, loss=3.069, v_num=6055]\n",
      "Epoch 1:  85%|████████▌ | 9104/10708 [00:38<00:06, 237.16it/s, loss=3.069, v_num=6055]\n",
      "Epoch 1:  86%|████████▌ | 9190/10708 [00:38<00:06, 238.73it/s, loss=3.069, v_num=6055]\n",
      "Epoch 1:  87%|████████▋ | 9276/10708 [00:38<00:05, 240.31it/s, loss=3.069, v_num=6055]\n",
      "Epoch 1:  87%|████████▋ | 9362/10708 [00:38<00:05, 241.88it/s, loss=3.069, v_num=6055]\n",
      "Epoch 1:  88%|████████▊ | 9448/10708 [00:38<00:05, 243.44it/s, loss=3.069, v_num=6055]\n",
      "Validating:  61%|██████    | 1953/3213 [00:03<00:01, 676.89it/s]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 9534/10708 [00:38<00:04, 244.92it/s, loss=3.069, v_num=6055]\n",
      "Epoch 1:  90%|████████▉ | 9620/10708 [00:39<00:04, 246.45it/s, loss=3.069, v_num=6055]\n",
      "Epoch 1:  91%|█████████ | 9706/10708 [00:39<00:04, 247.98it/s, loss=3.069, v_num=6055]\n",
      "Epoch 1:  91%|█████████▏| 9792/10708 [00:39<00:03, 249.50it/s, loss=3.069, v_num=6055]\n",
      "Epoch 1:  92%|█████████▏| 9878/10708 [00:39<00:03, 251.00it/s, loss=3.069, v_num=6055]\n",
      "Epoch 1:  93%|█████████▎| 9964/10708 [00:39<00:02, 252.49it/s, loss=3.069, v_num=6055]\n",
      "Epoch 1:  94%|█████████▍| 10050/10708 [00:39<00:02, 253.94it/s, loss=3.069, v_num=6055]\n",
      "Epoch 1:  95%|█████████▍| 10136/10708 [00:39<00:02, 255.40it/s, loss=3.069, v_num=6055]\n",
      "Epoch 1:  95%|█████████▌| 10222/10708 [00:39<00:01, 256.84it/s, loss=3.069, v_num=6055]\n",
      "Epoch 1:  96%|█████████▋| 10308/10708 [00:39<00:01, 258.30it/s, loss=3.069, v_num=6055]\n",
      "Epoch 1:  97%|█████████▋| 10394/10708 [00:40<00:01, 259.73it/s, loss=3.069, v_num=6055]\n",
      "Epoch 1:  98%|█████████▊| 10480/10708 [00:40<00:00, 261.14it/s, loss=3.069, v_num=6055]\n",
      "Epoch 1:  99%|█████████▊| 10566/10708 [00:40<00:00, 262.58it/s, loss=3.069, v_num=6055]\n",
      "Epoch 1:  99%|█████████▉| 10652/10708 [00:40<00:00, 264.02it/s, loss=3.069, v_num=6055]\n",
      "Validating:  98%|█████████▊| 3161/3213 [00:05<00:00, 786.47it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: avg_val_loss reached 3.43358 (best 3.43358), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v11.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 10708/10708 [00:40<00:00, 263.51it/s, loss=3.069, v_num=6055]\n",
      "Epoch 2:  70%|██████▉   | 7495/10708 [00:35<00:15, 209.98it/s, loss=2.971, v_num=6055] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2:  71%|███████   | 7568/10708 [00:37<00:15, 203.93it/s, loss=2.971, v_num=6055]\n",
      "Validating:   2%|▏         | 73/3213 [00:01<48:12,  1.09it/s] \u001b[A\n",
      "Epoch 2:  71%|███████▏  | 7654/10708 [00:37<00:14, 205.60it/s, loss=2.971, v_num=6055]\n",
      "Epoch 2:  72%|███████▏  | 7740/10708 [00:37<00:14, 207.33it/s, loss=2.971, v_num=6055]\n",
      "Epoch 2:  73%|███████▎  | 7826/10708 [00:37<00:13, 209.05it/s, loss=2.971, v_num=6055]\n",
      "Epoch 2:  74%|███████▍  | 7912/10708 [00:37<00:13, 210.76it/s, loss=2.971, v_num=6055]\n",
      "Epoch 2:  75%|███████▍  | 7998/10708 [00:37<00:12, 212.48it/s, loss=2.971, v_num=6055]\n",
      "Epoch 2:  75%|███████▌  | 8084/10708 [00:37<00:12, 214.18it/s, loss=2.971, v_num=6055]\n",
      "Epoch 2:  76%|███████▋  | 8170/10708 [00:37<00:11, 215.86it/s, loss=2.971, v_num=6055]\n",
      "Epoch 2:  77%|███████▋  | 8256/10708 [00:37<00:11, 217.53it/s, loss=2.971, v_num=6055]\n",
      "Epoch 2:  78%|███████▊  | 8342/10708 [00:38<00:10, 219.17it/s, loss=2.971, v_num=6055]\n",
      "Epoch 2:  79%|███████▊  | 8428/10708 [00:38<00:10, 220.81it/s, loss=2.971, v_num=6055]\n",
      "Epoch 2:  80%|███████▉  | 8514/10708 [00:38<00:09, 222.41it/s, loss=2.971, v_num=6055]\n",
      "Epoch 2:  80%|████████  | 8600/10708 [00:38<00:09, 223.98it/s, loss=2.971, v_num=6055]\n",
      "Epoch 2:  81%|████████  | 8686/10708 [00:38<00:08, 225.54it/s, loss=2.971, v_num=6055]\n",
      "Epoch 2:  82%|████████▏ | 8772/10708 [00:38<00:08, 227.12it/s, loss=2.971, v_num=6055]\n",
      "Epoch 2:  83%|████████▎ | 8858/10708 [00:38<00:08, 228.70it/s, loss=2.971, v_num=6055]\n",
      "Validating:  43%|████▎     | 1368/3213 [00:03<00:08, 229.38it/s]\u001b[A\n",
      "Epoch 2:  84%|████████▎ | 8944/10708 [00:38<00:07, 230.24it/s, loss=2.971, v_num=6055]\n",
      "Epoch 2:  84%|████████▍ | 9030/10708 [00:38<00:07, 231.82it/s, loss=2.971, v_num=6055]\n",
      "Epoch 2:  85%|████████▌ | 9116/10708 [00:39<00:06, 233.34it/s, loss=2.971, v_num=6055]\n",
      "Epoch 2:  86%|████████▌ | 9202/10708 [00:39<00:06, 234.92it/s, loss=2.971, v_num=6055]\n",
      "Epoch 2:  87%|████████▋ | 9288/10708 [00:39<00:06, 236.51it/s, loss=2.971, v_num=6055]\n",
      "Epoch 2:  88%|████████▊ | 9374/10708 [00:39<00:05, 238.04it/s, loss=2.971, v_num=6055]\n",
      "Epoch 2:  88%|████████▊ | 9460/10708 [00:39<00:05, 239.55it/s, loss=2.971, v_num=6055]\n",
      "Epoch 2:  89%|████████▉ | 9546/10708 [00:39<00:04, 241.10it/s, loss=2.971, v_num=6055]\n",
      "Epoch 2:  90%|████████▉ | 9632/10708 [00:39<00:04, 242.57it/s, loss=2.971, v_num=6055]\n",
      "Epoch 2:  91%|█████████ | 9718/10708 [00:39<00:04, 244.07it/s, loss=2.971, v_num=6055]\n",
      "Epoch 2:  92%|█████████▏| 9804/10708 [00:39<00:03, 245.54it/s, loss=2.971, v_num=6055]\n",
      "Epoch 2:  92%|█████████▏| 9890/10708 [00:40<00:03, 246.99it/s, loss=2.971, v_num=6055]\n",
      "Epoch 2:  93%|█████████▎| 9976/10708 [00:40<00:02, 248.39it/s, loss=2.971, v_num=6055]\n",
      "Epoch 2:  94%|█████████▍| 10062/10708 [00:40<00:02, 249.82it/s, loss=2.971, v_num=6055]\n",
      "Validating:  80%|███████▉  | 2570/3213 [00:04<00:00, 742.45it/s]\u001b[A\n",
      "Epoch 2:  95%|█████████▍| 10148/10708 [00:40<00:02, 251.24it/s, loss=2.971, v_num=6055]\n",
      "Epoch 2:  96%|█████████▌| 10234/10708 [00:40<00:01, 252.68it/s, loss=2.971, v_num=6055]\n",
      "Epoch 2:  96%|█████████▋| 10320/10708 [00:40<00:01, 254.14it/s, loss=2.971, v_num=6055]\n",
      "Epoch 2:  97%|█████████▋| 10406/10708 [00:40<00:01, 255.62it/s, loss=2.971, v_num=6055]\n",
      "Epoch 2:  98%|█████████▊| 10492/10708 [00:40<00:00, 257.07it/s, loss=2.971, v_num=6055]\n",
      "Epoch 2:  99%|█████████▉| 10578/10708 [00:40<00:00, 258.53it/s, loss=2.971, v_num=6055]\n",
      "Epoch 2: 100%|█████████▉| 10664/10708 [00:41<00:00, 259.99it/s, loss=2.971, v_num=6055]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: avg_val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 10708/10708 [00:41<00:00, 259.35it/s, loss=2.971, v_num=6055]\n",
      "Epoch 3:  70%|██████▉   | 7495/10708 [00:35<00:15, 211.91it/s, loss=2.814, v_num=6055] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 1/3213 [00:01<1:03:05,  1.18s/it]\u001b[A\n",
      "Epoch 3:  71%|███████   | 7568/10708 [00:36<00:15, 206.44it/s, loss=2.814, v_num=6055]\n",
      "Epoch 3:  71%|███████▏  | 7654/10708 [00:36<00:14, 208.20it/s, loss=2.814, v_num=6055]\n",
      "Epoch 3:  72%|███████▏  | 7740/10708 [00:36<00:14, 209.88it/s, loss=2.814, v_num=6055]\n",
      "Epoch 3:  73%|███████▎  | 7826/10708 [00:36<00:13, 211.59it/s, loss=2.814, v_num=6055]\n",
      "Epoch 3:  74%|███████▍  | 7912/10708 [00:37<00:13, 213.29it/s, loss=2.814, v_num=6055]\n",
      "Epoch 3:  75%|███████▍  | 7998/10708 [00:37<00:12, 214.99it/s, loss=2.814, v_num=6055]\n",
      "Epoch 3:  75%|███████▌  | 8084/10708 [00:37<00:12, 216.70it/s, loss=2.814, v_num=6055]\n",
      "Epoch 3:  76%|███████▋  | 8170/10708 [00:37<00:11, 218.36it/s, loss=2.814, v_num=6055]\n",
      "Epoch 3:  77%|███████▋  | 8256/10708 [00:37<00:11, 220.00it/s, loss=2.814, v_num=6055]\n",
      "Epoch 3:  78%|███████▊  | 8342/10708 [00:37<00:10, 221.66it/s, loss=2.814, v_num=6055]\n",
      "Epoch 3:  79%|███████▊  | 8428/10708 [00:37<00:10, 223.30it/s, loss=2.814, v_num=6055]\n",
      "Epoch 3:  80%|███████▉  | 8514/10708 [00:37<00:09, 224.93it/s, loss=2.814, v_num=6055]\n",
      "Validating:  32%|███▏      | 1022/3213 [00:02<00:27, 78.87it/s]\u001b[A\n",
      "Epoch 3:  80%|████████  | 8600/10708 [00:37<00:09, 226.52it/s, loss=2.814, v_num=6055]\n",
      "Epoch 3:  81%|████████  | 8686/10708 [00:38<00:08, 228.14it/s, loss=2.814, v_num=6055]\n",
      "Epoch 3:  82%|████████▏ | 8772/10708 [00:38<00:08, 229.77it/s, loss=2.814, v_num=6055]\n",
      "Epoch 3:  83%|████████▎ | 8858/10708 [00:38<00:07, 231.36it/s, loss=2.814, v_num=6055]\n",
      "Epoch 3:  84%|████████▎ | 8944/10708 [00:38<00:07, 232.95it/s, loss=2.814, v_num=6055]\n",
      "Epoch 3:  84%|████████▍ | 9030/10708 [00:38<00:07, 234.53it/s, loss=2.814, v_num=6055]\n",
      "Epoch 3:  85%|████████▌ | 9116/10708 [00:38<00:06, 236.07it/s, loss=2.814, v_num=6055]\n",
      "Epoch 3:  86%|████████▌ | 9202/10708 [00:38<00:06, 236.91it/s, loss=2.814, v_num=6055]\n",
      "Epoch 3:  87%|████████▋ | 9288/10708 [00:38<00:05, 238.45it/s, loss=2.814, v_num=6055]\n",
      "Epoch 3:  88%|████████▊ | 9374/10708 [00:39<00:05, 239.93it/s, loss=2.814, v_num=6055]\n",
      "Epoch 3:  88%|████████▊ | 9460/10708 [00:39<00:05, 241.46it/s, loss=2.814, v_num=6055]\n",
      "Epoch 3:  89%|████████▉ | 9546/10708 [00:39<00:04, 243.00it/s, loss=2.814, v_num=6055]\n",
      "Epoch 3:  90%|████████▉ | 9633/10708 [00:39<00:04, 244.59it/s, loss=2.814, v_num=6055]\n",
      "Epoch 3:  91%|█████████ | 9720/10708 [00:39<00:04, 246.11it/s, loss=2.814, v_num=6055]\n",
      "Validating:  69%|██████▉   | 2226/3213 [00:04<00:01, 743.64it/s]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 9807/10708 [00:39<00:03, 247.60it/s, loss=2.814, v_num=6055]\n",
      "Epoch 3:  92%|█████████▏| 9894/10708 [00:39<00:03, 249.13it/s, loss=2.814, v_num=6055]\n",
      "Epoch 3:  93%|█████████▎| 9981/10708 [00:39<00:02, 250.65it/s, loss=2.814, v_num=6055]\n",
      "Epoch 3:  94%|█████████▍| 10068/10708 [00:39<00:02, 252.15it/s, loss=2.814, v_num=6055]\n",
      "Epoch 3:  95%|█████████▍| 10155/10708 [00:40<00:02, 253.67it/s, loss=2.814, v_num=6055]\n",
      "Epoch 3:  96%|█████████▌| 10242/10708 [00:40<00:01, 255.12it/s, loss=2.814, v_num=6055]\n",
      "Epoch 3:  96%|█████████▋| 10329/10708 [00:40<00:01, 256.57it/s, loss=2.814, v_num=6055]\n",
      "Epoch 3:  97%|█████████▋| 10416/10708 [00:40<00:01, 258.03it/s, loss=2.814, v_num=6055]\n",
      "Epoch 3:  98%|█████████▊| 10503/10708 [00:40<00:00, 259.50it/s, loss=2.814, v_num=6055]\n",
      "Epoch 3:  99%|█████████▉| 10590/10708 [00:40<00:00, 260.96it/s, loss=2.814, v_num=6055]\n",
      "Epoch 3: 100%|█████████▉| 10677/10708 [00:40<00:00, 262.44it/s, loss=2.814, v_num=6055]\n",
      "Validating: 100%|█████████▉| 3211/3213 [00:05<00:00, 821.06it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: avg_val_loss reached 3.35545 (best 3.35545), saving model to /home/payonear/Cases_recruit/netguru-case/checkpoints/model-outputs-v10.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 10708/10708 [00:40<00:00, 261.52it/s, loss=2.814, v_num=6055]\n",
      "Epoch 4:  70%|██████▉   | 7495/10708 [00:35<00:15, 211.46it/s, loss=2.788, v_num=6055] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 1/3213 [00:01<1:01:13,  1.14s/it]\u001b[A\n",
      "Epoch 4:  71%|███████   | 7569/10708 [00:36<00:15, 206.22it/s, loss=2.788, v_num=6055]\n",
      "Epoch 4:  71%|███████▏  | 7656/10708 [00:36<00:14, 207.98it/s, loss=2.788, v_num=6055]\n",
      "Epoch 4:  72%|███████▏  | 7743/10708 [00:36<00:14, 209.72it/s, loss=2.788, v_num=6055]\n",
      "Epoch 4:  73%|███████▎  | 7830/10708 [00:37<00:13, 211.42it/s, loss=2.788, v_num=6055]\n",
      "Epoch 4:  74%|███████▍  | 7917/10708 [00:37<00:13, 213.16it/s, loss=2.788, v_num=6055]\n",
      "Epoch 4:  75%|███████▍  | 8004/10708 [00:37<00:12, 214.90it/s, loss=2.788, v_num=6055]\n",
      "Epoch 4:  76%|███████▌  | 8091/10708 [00:37<00:12, 216.61it/s, loss=2.788, v_num=6055]\n",
      "Epoch 4:  76%|███████▋  | 8178/10708 [00:37<00:11, 218.29it/s, loss=2.788, v_num=6055]\n",
      "Epoch 4:  77%|███████▋  | 8265/10708 [00:37<00:11, 219.99it/s, loss=2.788, v_num=6055]\n",
      "Epoch 4:  78%|███████▊  | 8352/10708 [00:37<00:10, 221.71it/s, loss=2.788, v_num=6055]\n",
      "Epoch 4:  79%|███████▉  | 8439/10708 [00:37<00:10, 223.42it/s, loss=2.788, v_num=6055]\n",
      "Epoch 4:  80%|███████▉  | 8526/10708 [00:37<00:09, 225.09it/s, loss=2.788, v_num=6055]\n",
      "Epoch 4:  80%|████████  | 8613/10708 [00:37<00:09, 226.78it/s, loss=2.788, v_num=6055]\n",
      "Epoch 4:  81%|████████  | 8700/10708 [00:38<00:08, 228.41it/s, loss=2.788, v_num=6055]\n",
      "Epoch 4:  82%|████████▏ | 8787/10708 [00:38<00:08, 230.05it/s, loss=2.788, v_num=6055]\n",
      "Epoch 4:  83%|████████▎ | 8874/10708 [00:38<00:07, 231.70it/s, loss=2.788, v_num=6055]\n",
      "Epoch 4:  84%|████████▎ | 8961/10708 [00:38<00:07, 233.33it/s, loss=2.788, v_num=6055]\n",
      "Validating:  46%|████▌     | 1466/3213 [00:02<00:05, 325.75it/s]\u001b[A\n",
      "Epoch 4:  84%|████████▍ | 9048/10708 [00:38<00:07, 234.93it/s, loss=2.788, v_num=6055]\n",
      "Epoch 4:  85%|████████▌ | 9135/10708 [00:38<00:06, 236.55it/s, loss=2.788, v_num=6055]\n",
      "Epoch 4:  86%|████████▌ | 9222/10708 [00:38<00:06, 238.16it/s, loss=2.788, v_num=6055]\n",
      "Epoch 4:  87%|████████▋ | 9309/10708 [00:38<00:05, 239.75it/s, loss=2.788, v_num=6055]\n",
      "Epoch 4:  88%|████████▊ | 9396/10708 [00:38<00:05, 241.32it/s, loss=2.788, v_num=6055]\n",
      "Epoch 4:  89%|████████▊ | 9483/10708 [00:39<00:05, 242.88it/s, loss=2.788, v_num=6055]\n",
      "Epoch 4:  89%|████████▉ | 9570/10708 [00:39<00:04, 244.39it/s, loss=2.788, v_num=6055]\n",
      "Epoch 4:  90%|█████████ | 9657/10708 [00:39<00:04, 245.93it/s, loss=2.788, v_num=6055]\n",
      "Epoch 4:  91%|█████████ | 9744/10708 [00:39<00:03, 247.45it/s, loss=2.788, v_num=6055]\n",
      "Epoch 4:  92%|█████████▏| 9831/10708 [00:39<00:03, 248.98it/s, loss=2.788, v_num=6055]\n",
      "Epoch 4:  93%|█████████▎| 9918/10708 [00:39<00:03, 250.47it/s, loss=2.788, v_num=6055]\n",
      "Epoch 4:  93%|█████████▎| 10005/10708 [00:39<00:02, 251.97it/s, loss=2.788, v_num=6055]\n",
      "Epoch 4:  94%|█████████▍| 10092/10708 [00:39<00:02, 253.49it/s, loss=2.788, v_num=6055]\n",
      "Epoch 4:  95%|█████████▌| 10179/10708 [00:39<00:02, 254.92it/s, loss=2.788, v_num=6055]\n",
      "Epoch 4:  96%|█████████▌| 10266/10708 [00:40<00:01, 256.37it/s, loss=2.788, v_num=6055]\n",
      "Validating:  86%|████████▌ | 2771/3213 [00:04<00:00, 768.95it/s]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 10353/10708 [00:40<00:01, 257.82it/s, loss=2.788, v_num=6055]\n",
      "Epoch 4:  97%|█████████▋| 10440/10708 [00:40<00:01, 259.30it/s, loss=2.788, v_num=6055]\n",
      "Epoch 4:  98%|█████████▊| 10527/10708 [00:40<00:00, 260.75it/s, loss=2.788, v_num=6055]\n",
      "Epoch 4:  99%|█████████▉| 10614/10708 [00:40<00:00, 262.18it/s, loss=2.788, v_num=6055]\n",
      "Epoch 4: 100%|█████████▉| 10701/10708 [00:40<00:00, 263.67it/s, loss=2.788, v_num=6055]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: avg_val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 10708/10708 [00:40<00:00, 262.39it/s, loss=2.788, v_num=6055]\n",
      "Epoch 5:  70%|██████▉   | 7495/10708 [00:35<00:15, 212.38it/s, loss=2.843, v_num=6055] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 1/3213 [00:01<1:06:45,  1.25s/it]\u001b[A\n",
      "Epoch 5:  71%|███████   | 7569/10708 [00:36<00:15, 206.55it/s, loss=2.843, v_num=6055]\n",
      "Epoch 5:  71%|███████▏  | 7656/10708 [00:36<00:14, 208.30it/s, loss=2.843, v_num=6055]\n",
      "Epoch 5:  72%|███████▏  | 7743/10708 [00:36<00:14, 210.02it/s, loss=2.843, v_num=6055]\n",
      "Epoch 5:  73%|███████▎  | 7830/10708 [00:36<00:13, 211.79it/s, loss=2.843, v_num=6055]\n",
      "Epoch 5:  74%|███████▍  | 7917/10708 [00:37<00:13, 213.54it/s, loss=2.843, v_num=6055]\n",
      "Epoch 5:  75%|███████▍  | 8004/10708 [00:37<00:12, 215.26it/s, loss=2.843, v_num=6055]\n",
      "Epoch 5:  76%|███████▌  | 8091/10708 [00:37<00:12, 216.98it/s, loss=2.843, v_num=6055]\n",
      "Epoch 5:  76%|███████▋  | 8178/10708 [00:37<00:11, 218.70it/s, loss=2.843, v_num=6055]\n",
      "Epoch 5:  77%|███████▋  | 8265/10708 [00:37<00:11, 220.41it/s, loss=2.843, v_num=6055]\n",
      "Epoch 5:  78%|███████▊  | 8352/10708 [00:37<00:10, 222.12it/s, loss=2.843, v_num=6055]\n",
      "Epoch 5:  79%|███████▉  | 8439/10708 [00:37<00:10, 223.82it/s, loss=2.843, v_num=6055]\n",
      "Epoch 5:  80%|███████▉  | 8526/10708 [00:37<00:09, 225.48it/s, loss=2.843, v_num=6055]\n",
      "Epoch 5:  80%|████████  | 8613/10708 [00:37<00:09, 227.14it/s, loss=2.843, v_num=6055]\n",
      "Epoch 5:  81%|████████  | 8700/10708 [00:38<00:08, 228.74it/s, loss=2.843, v_num=6055]\n",
      "Epoch 5:  82%|████████▏ | 8787/10708 [00:38<00:08, 230.37it/s, loss=2.843, v_num=6055]\n",
      "Epoch 5:  83%|████████▎ | 8874/10708 [00:38<00:07, 231.99it/s, loss=2.843, v_num=6055]\n",
      "Validating:  43%|████▎     | 1383/3213 [00:02<00:07, 240.83it/s]\u001b[A\n",
      "Epoch 5:  84%|████████▎ | 8961/10708 [00:38<00:07, 233.59it/s, loss=2.843, v_num=6055]\n",
      "Epoch 5:  84%|████████▍ | 9048/10708 [00:38<00:07, 235.15it/s, loss=2.843, v_num=6055]\n",
      "Epoch 5:  85%|████████▌ | 9135/10708 [00:38<00:06, 236.73it/s, loss=2.843, v_num=6055]\n",
      "Epoch 5:  86%|████████▌ | 9222/10708 [00:38<00:06, 238.34it/s, loss=2.843, v_num=6055]\n",
      "Epoch 5:  87%|████████▋ | 9309/10708 [00:38<00:05, 239.92it/s, loss=2.843, v_num=6055]\n",
      "Epoch 5:  88%|████████▊ | 9396/10708 [00:38<00:05, 241.48it/s, loss=2.843, v_num=6055]\n",
      "Epoch 5:  89%|████████▊ | 9483/10708 [00:39<00:05, 243.01it/s, loss=2.843, v_num=6055]\n",
      "Epoch 5:  89%|████████▉ | 9570/10708 [00:39<00:04, 244.55it/s, loss=2.843, v_num=6055]\n",
      "Epoch 5:  90%|█████████ | 9657/10708 [00:39<00:04, 246.12it/s, loss=2.843, v_num=6055]\n",
      "Epoch 5:  91%|█████████ | 9744/10708 [00:39<00:03, 247.66it/s, loss=2.843, v_num=6055]\n",
      "Epoch 5:  92%|█████████▏| 9831/10708 [00:39<00:03, 249.21it/s, loss=2.843, v_num=6055]\n",
      "Epoch 5:  93%|█████████▎| 9918/10708 [00:39<00:03, 250.74it/s, loss=2.843, v_num=6055]\n",
      "Epoch 5:  93%|█████████▎| 10005/10708 [00:39<00:02, 252.30it/s, loss=2.843, v_num=6055]\n",
      "Epoch 5:  94%|█████████▍| 10092/10708 [00:39<00:02, 253.81it/s, loss=2.843, v_num=6055]\n",
      "Epoch 5:  95%|█████████▌| 10179/10708 [00:39<00:02, 255.32it/s, loss=2.843, v_num=6055]\n",
      "Epoch 5:  96%|█████████▌| 10266/10708 [00:39<00:01, 256.79it/s, loss=2.843, v_num=6055]\n",
      "Epoch 5:  97%|█████████▋| 10353/10708 [00:40<00:01, 258.29it/s, loss=2.843, v_num=6055]\n",
      "Epoch 5:  97%|█████████▋| 10440/10708 [00:40<00:01, 259.77it/s, loss=2.843, v_num=6055]\n",
      "Validating:  92%|█████████▏| 2945/3213 [00:04<00:00, 811.81it/s]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 10527/10708 [00:40<00:00, 261.19it/s, loss=2.843, v_num=6055]\n",
      "Epoch 5:  99%|█████████▉| 10614/10708 [00:40<00:00, 262.64it/s, loss=2.843, v_num=6055]\n",
      "Epoch 5: 100%|█████████▉| 10701/10708 [00:40<00:00, 264.12it/s, loss=2.843, v_num=6055]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: avg_val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 10708/10708 [00:40<00:00, 262.86it/s, loss=2.843, v_num=6055]\n",
      "Epoch 6:  70%|██████▉   | 7495/10708 [00:35<00:15, 212.08it/s, loss=2.703, v_num=6055] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 1/3213 [00:01<1:04:31,  1.21s/it]\u001b[A\n",
      "Epoch 6:  71%|███████   | 7569/10708 [00:36<00:15, 206.46it/s, loss=2.703, v_num=6055]\n",
      "Epoch 6:  71%|███████▏  | 7656/10708 [00:36<00:14, 208.21it/s, loss=2.703, v_num=6055]\n",
      "Epoch 6:  72%|███████▏  | 7743/10708 [00:36<00:14, 209.93it/s, loss=2.703, v_num=6055]\n",
      "Epoch 6:  73%|███████▎  | 7830/10708 [00:36<00:13, 211.67it/s, loss=2.703, v_num=6055]\n",
      "Epoch 6:  74%|███████▍  | 7917/10708 [00:37<00:13, 213.37it/s, loss=2.703, v_num=6055]\n",
      "Epoch 6:  75%|███████▍  | 8004/10708 [00:37<00:12, 215.06it/s, loss=2.703, v_num=6055]\n",
      "Epoch 6:  76%|███████▌  | 8091/10708 [00:37<00:12, 216.77it/s, loss=2.703, v_num=6055]\n",
      "Epoch 6:  76%|███████▋  | 8178/10708 [00:37<00:11, 218.46it/s, loss=2.703, v_num=6055]\n",
      "Epoch 6:  77%|███████▋  | 8265/10708 [00:37<00:11, 220.14it/s, loss=2.703, v_num=6055]\n",
      "Validating:  24%|██▍       | 775/3213 [00:02<01:26, 28.34it/s]\u001b[A\n",
      "Epoch 6:  78%|███████▊  | 8352/10708 [00:37<00:10, 221.77it/s, loss=2.703, v_num=6055]\n",
      "Epoch 6:  79%|███████▉  | 8439/10708 [00:37<00:10, 223.38it/s, loss=2.703, v_num=6055]\n",
      "Epoch 6:  80%|███████▉  | 8526/10708 [00:37<00:09, 225.00it/s, loss=2.703, v_num=6055]\n",
      "Epoch 6:  80%|████████  | 8613/10708 [00:38<00:09, 226.62it/s, loss=2.703, v_num=6055]\n",
      "Epoch 6:  81%|████████  | 8700/10708 [00:38<00:08, 228.24it/s, loss=2.703, v_num=6055]\n",
      "Epoch 6:  82%|████████▏ | 8787/10708 [00:38<00:08, 229.87it/s, loss=2.703, v_num=6055]\n",
      "Epoch 6:  83%|████████▎ | 8874/10708 [00:38<00:07, 231.48it/s, loss=2.703, v_num=6055]\n",
      "Epoch 6:  84%|████████▎ | 8961/10708 [00:38<00:07, 233.07it/s, loss=2.703, v_num=6055]\n",
      "Epoch 6:  84%|████████▍ | 9048/10708 [00:38<00:07, 234.63it/s, loss=2.703, v_num=6055]\n",
      "Epoch 6:  85%|████████▌ | 9135/10708 [00:38<00:06, 236.22it/s, loss=2.703, v_num=6055]\n",
      "Validating:  51%|█████     | 1642/3213 [00:03<00:03, 513.33it/s]\u001b[A\n",
      "Epoch 6:  86%|████████▌ | 9222/10708 [00:38<00:06, 237.82it/s, loss=2.703, v_num=6055]\n",
      "Epoch 6:  87%|████████▋ | 9309/10708 [00:38<00:05, 239.44it/s, loss=2.703, v_num=6055]\n",
      "Epoch 6:  88%|████████▊ | 9396/10708 [00:38<00:05, 241.02it/s, loss=2.703, v_num=6055]\n",
      "Epoch 6:  89%|████████▊ | 9483/10708 [00:39<00:05, 242.58it/s, loss=2.703, v_num=6055]\n",
      "Epoch 6:  89%|████████▉ | 9570/10708 [00:39<00:04, 244.09it/s, loss=2.703, v_num=6055]\n",
      "Epoch 6:  90%|█████████ | 9657/10708 [00:39<00:04, 245.62it/s, loss=2.703, v_num=6055]\n",
      "Epoch 6:  91%|█████████ | 9744/10708 [00:39<00:03, 247.12it/s, loss=2.703, v_num=6055]\n",
      "Epoch 6:  92%|█████████▏| 9831/10708 [00:39<00:03, 248.63it/s, loss=2.703, v_num=6055]\n",
      "Epoch 6:  93%|█████████▎| 9918/10708 [00:39<00:03, 250.17it/s, loss=2.703, v_num=6055]\n",
      "Epoch 6:  93%|█████████▎| 10005/10708 [00:39<00:02, 251.68it/s, loss=2.703, v_num=6055]\n",
      "Epoch 6:  94%|█████████▍| 10092/10708 [00:39<00:02, 253.16it/s, loss=2.703, v_num=6055]\n",
      "Epoch 6:  95%|█████████▌| 10179/10708 [00:39<00:02, 254.65it/s, loss=2.703, v_num=6055]\n",
      "Epoch 6:  96%|█████████▌| 10266/10708 [00:40<00:01, 256.14it/s, loss=2.703, v_num=6055]\n",
      "Epoch 6:  97%|█████████▋| 10353/10708 [00:40<00:01, 257.64it/s, loss=2.703, v_num=6055]\n",
      "Epoch 6:  97%|█████████▋| 10440/10708 [00:40<00:01, 259.14it/s, loss=2.703, v_num=6055]\n",
      "Epoch 6:  98%|█████████▊| 10527/10708 [00:40<00:00, 260.56it/s, loss=2.703, v_num=6055]\n",
      "Epoch 6:  99%|█████████▉| 10614/10708 [00:40<00:00, 261.99it/s, loss=2.703, v_num=6055]\n",
      "Validating:  97%|█████████▋| 3123/3213 [00:05<00:00, 791.06it/s]\u001b[A\n",
      "Epoch 6: 100%|█████████▉| 10701/10708 [00:40<00:00, 263.37it/s, loss=2.703, v_num=6055]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: avg_val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 10708/10708 [00:40<00:00, 262.08it/s, loss=2.703, v_num=6055]\n",
      "Epoch 6: 100%|██████████| 10708/10708 [00:41<00:00, 259.16it/s, loss=2.703, v_num=6055]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Starting saving the offline archive\n",
      "COMET INFO: To upload this offline experiment, run:\n",
      "    comet upload logs/466e84a957834a0bb355078ab8166055.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 46s, sys: 52.7 s, total: 5min 39s\n",
      "Wall time: 4min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EarlyStopping mode set to min for monitoring avg_val_loss.\n"
     ]
    }
   ],
   "source": [
    "topic_model = Model.load_from_checkpoint(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, hparams=hparams, \\\n",
    "                                   checkpoint_path=\"./checkpoints/model-outputs-v10.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (net): Net(\n",
       "    (fc1): Linear(in_features=768, out_features=128, bias=True)\n",
       "    (fc2): Linear(in_features=128, out_features=39, bias=True)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "    (loss_func): CrossEntropyLoss()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2677/2677 [00:02<00:00, 1044.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.066     0.135     0.089       764\n",
      "           1      0.028     0.059     0.038       931\n",
      "           2      0.008     0.146     0.015       246\n",
      "           3      0.026     0.225     0.046       325\n",
      "           4      0.115     0.008     0.015      6460\n",
      "           5      0.009     0.149     0.017       248\n",
      "           6      0.041     0.064     0.050       807\n",
      "           7      0.020     0.161     0.036       446\n",
      "           8      0.075     0.099     0.085       895\n",
      "           9      0.035     0.072     0.047       782\n",
      "          10      0.080     0.009     0.017      4003\n",
      "          11      0.017     0.142     0.030       218\n",
      "          12      0.032     0.013     0.018      1169\n",
      "          13      0.260     0.009     0.017      5917\n",
      "          14      0.062     0.013     0.022      2304\n",
      "          15      0.008     0.060     0.014       117\n",
      "          16      0.050     0.149     0.075       967\n",
      "          17      0.039     0.021     0.028      1368\n",
      "          18      0.018     0.057     0.028       601\n",
      "          19      0.135     0.049     0.072      3186\n",
      "          20      0.014     0.133     0.026       256\n",
      "          21      0.117     0.099     0.107      1792\n",
      "          22      0.015     0.131     0.028       373\n",
      "          23      0.019     0.113     0.032       441\n",
      "          24      0.005     0.036     0.009        55\n",
      "          25      0.030     0.027     0.028       942\n",
      "          26      0.026     0.074     0.039       621\n",
      "          27      0.050     0.317     0.086       618\n",
      "          28      0.052     0.006     0.010      2926\n",
      "          29      0.073     0.229     0.111      1542\n",
      "          30      0.019     0.119     0.033       573\n",
      "          31      0.075     0.261     0.117      1042\n",
      "          32      0.053     0.032     0.040      1443\n",
      "          33      0.016     0.200     0.029       604\n",
      "          34      0.604     0.101     0.173     30676\n",
      "          35      0.293     0.025     0.047      8372\n",
      "          36      0.047     0.106     0.065       775\n",
      "          37      0.012     0.168     0.023       387\n",
      "          38      0.077     0.177     0.107       464\n",
      "\n",
      "    accuracy                          0.072     85656\n",
      "   macro avg      0.070     0.102     0.048     85656\n",
      "weighted avg      0.296     0.072     0.088     85656\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pred = topic_model.predict_eval(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model has learnt a bit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and alternative approaches\n",
    "\n",
    "So, in this notebook we built 4 models, predicting gender, zodiac sign, age and industry of post's author. For the first model we found out that text semantic allows us identify the gender of the author with accuray in 65% (F1-score - 65%). In case of age, zodiac sign and industry prediction tasks the models were not so successful. Why were we able to predict gender, but experienced hard time predicting all the other classes. So, imagine you have a task, the same as the model, you want to identify who wrote the post. Let's see an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"                 hey every one! like my new page? awsome eh? so any way i have soooooooooooooomuch to say! ok! #1 i broke up with my best friend but for some odd reason we are better friends than before! #2 next week monday is grad and my dress is amazing . #3 on june 15 its my birthday and thats only 6 days away!yippee! #4 i am going with my class to algonquin park on my birthday!:( #5 i ordered a great corsage for grad and its pink roses with black ribbon to match my dress #6 i am going to a class party at alyssa's house and (lane and caitlin don't tell sarah):) sarah isn't coming so i get to hang out with caitlin the whole time and see the guys in bathing suits thats alll bye!        \""
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[485088].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, trying to not look at the answer try to predict what is the gender of the author. You probably will succeed in this one, as there are some obvious patterns. Let's see what our model predicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = preprocess(df.iloc[485088].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = torch.Tensor(st.encode(text)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_gender = gender_model.eval()(vector)[0].cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9176142 , 0.08238575], dtype=float32)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'female'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_idx2class[predicted_gender.argmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model confidentaly predicts `female`, which is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'female'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[485088].gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try to predict the age or zodiac sign. You probaly will not pick up correct zodiac sign, but for the age you'll guess probably that this woman is rather young. Model thinks so as well, predicting age 17. And it's wrong in both cases. True age is 27 and sign is Virgo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_sign = sign_model.eval()(vector)[0].cpu().detach().numpy().argmax()\n",
    "predicted_age = age_model.eval()(vector)[0].cpu().detach().numpy().argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libra 17\n"
     ]
    }
   ],
   "source": [
    "print(sign_idx2class[predicted_sign], age_idx2class[predicted_age])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sign    Virgo\n",
       "age        27\n",
       "Name: 485088, dtype: object"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.gender == 'female'].iloc[231834][['sign', 'age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_sign = sign_model.eval()(vector)[0].cpu().detach().numpy()\n",
    "predicted_age = age_model.eval()(vector)[0].cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we can do is to look at probability distribution. We see. that model expects young woman as an author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(13, 0.10954411),\n",
       " (14, 0.21835598),\n",
       " (15, 0.15332097),\n",
       " (16, 0.16565101),\n",
       " (17, 0.24571995),\n",
       " (23, 0.03860785),\n",
       " (24, 0.011329638),\n",
       " (25, 0.02068015),\n",
       " (26, 0.007752688),\n",
       " (27, 0.009686214),\n",
       " (33, 0.0055164155),\n",
       " (34, 0.0017548457),\n",
       " (35, 0.0021529535),\n",
       " (36, 0.0040871017),\n",
       " (37, 0.0017296473),\n",
       " (38, 0.0010645707),\n",
       " (39, 0.001493069),\n",
       " (40, 0.00070819794),\n",
       " (41, 0.00062517624),\n",
       " (42, 2.1865038e-05),\n",
       " (43, 2.3538078e-05),\n",
       " (44, 2.7320391e-08),\n",
       " (45, 3.5826208e-05),\n",
       " (46, 0.00012575263),\n",
       " (47, 2.9213611e-08),\n",
       " (48, 1.2388433e-05)]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(age_idx2class[i], p) for i, p in enumerate(predicted_age)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about industry. To be fair, most of posts are barely connected to author's specialities. Like few random examples below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"           An excerpt from Ebert's review of the revival of 'Eyes Without a Face'...  *****  '....One of the tasks faced by serious filmgoers is to distinguish good films in disreputable genres. It is insufferable to claim you 'never' see horror movies (or Westerns, musicals, war movies, teenage romances or slasher pictures). You're presenting ignorance as taste.  The trick is to find the good ones. The French auteur critics did a lot of helpful spadework, resurrecting genres and rehabilitating reputations, but they were not always right -- and besides, you have to feel it for yourself. If a film holds my attention, it is in one way or another a good one. If it moves or delights me, it may be great. If I am distracted by its conventions, obligatory scenes and carelessness or lack of ambition, it deserves to be tossed back into the genre.'          \""
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_df.iloc[2567].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Technology'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_idx2class[topic_df.iloc[2567].topic]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's nothing in the post which points to technology job. Let's see one more example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"           Let's see how much longer I am listen on  urlLink Are They Hot or Not? ...  Once  urlLink Am I Hot of Not?  changed their scoring system, urlLink I  jumped to a 9.9.           \""
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_df.iloc[68799].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Technology'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_idx2class[topic_df.iloc[68799].topic]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, hard to find any pattern. But let's check smth we can predict ourselves. So, below's text most probably was written by a student. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"       I hope everyone is doing fine and things like that. :)   I love our class too. The different personalities and how people just blended in and complemented each other in ways we didnt know exist. It's amazing, how bonds can be forged, how friendships can link people over oceans, and how memories will forever be etched in the heart.   To each and everyone of you, thank you for being part of my life. No matter how small or big, trust me, somehow, you've influenced it in some little way. May the spirit of 4s2 always live in our hearts even as we all grow up into our dreams and future.           \""
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_df.iloc[243565].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Student'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_idx2class[topic_df.iloc[243565].topic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = preprocess(topic_df.iloc[243565].text)\n",
    "vector = torch.Tensor(st.encode(text)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sports-Recreation'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_topic = topic_model.eval()(vector)[0].cpu().detach().numpy()\n",
    "topic_idx2class[predicted_topic.argmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model fails predicting topic. But let's look at top of most probable classes. Reading the post we can clearly notice parts describing feelings, love, friendship, spirits living in heart which may be associated with religion or politics. The part about friendship over oceans may be associated with tourism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Sports-Recreation', 0.11650513),\n",
       " ('Tourism', 0.06152273),\n",
       " ('Government', 0.050910026),\n",
       " ('Religion', 0.05040999),\n",
       " ('Consulting', 0.04662161),\n",
       " ('Agriculture', 0.04395426),\n",
       " ('Student', 0.0424679),\n",
       " ('Non-Profit', 0.03279907),\n",
       " ('Science', 0.031032503),\n",
       " ('Advertising', 0.030757962)]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(topic_idx2class[i], p) for i, p in enumerate(predicted_topic)], key = lambda x: x[1], reverse = True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the next one. And again, model fails. Looking carefully we can notice, that there is no pattern showing the author is a student. But tennis is mentioned, which probably give the major vote here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"             It's Friday, the 2nd of August, Tennis is over and I am Free!!! I'm getting my highlights done today! Costs major Moolah though :p Oh well. I'm going to the Arthur Murray Freestyles in september! Again...Major Moolah is required. :p We're gonna be eating Bolagna sandwiches for a month...And the costumes...Oh goodness...and the hotel room...Make that a year. It could be worse though. Could be Oatmeal. Ick. NEwayz, I hope my highlights look good...Wherever ya'll are wish me luck. :) I'm gonna need it. ^_^         \""
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_df.iloc[56879].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Student'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_idx2class[topic_df.iloc[56879].topic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sports-Recreation'"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = preprocess(topic_df.iloc[56879].text)\n",
    "vector = torch.Tensor(st.encode(text)).to(device)\n",
    "predicted_topic = topic_model.eval()(vector)[0].cpu().detach().numpy()\n",
    "topic_idx2class[predicted_topic.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Sports-Recreation', 0.091831505),\n",
       " ('Government', 0.061524443),\n",
       " ('Science', 0.050450183),\n",
       " ('Publishing', 0.045896966),\n",
       " ('Communications-Media', 0.041699696),\n",
       " ('Fashion', 0.041312806),\n",
       " ('Chemicals', 0.037084825),\n",
       " ('Tourism', 0.03459721),\n",
       " ('Technology', 0.033953577),\n",
       " ('Arts', 0.03229286)]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(topic_idx2class[i], p) for i, p in enumerate(predicted_topic)], key = lambda x: x[1], reverse = True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the last example. We'll probably guess from the belows post, that the author is from technology sector and we'll be right. The model thinks that he/she is from banking sector. That's probably because of metntioned drachma and discounts. But science and technology are in the top, probably because of computers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"       Another DAy, another 9000 drachma... Well, I'm losing air in my right front tire, so I have to go to discount tires today. it'll be a nice break from the monotony of rebuilding this damn computer:)  catch you latah- T         \""
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_df.iloc[46878].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Technology'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_idx2class[topic_df.iloc[46878].topic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Banking'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = preprocess(topic_df.iloc[46878].text)\n",
    "vector = torch.Tensor(st.encode(text)).to(device)\n",
    "predicted_topic = topic_model.eval()(vector)[0].cpu().detach().numpy()\n",
    "topic_idx2class[predicted_topic.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Banking', 0.07936209),\n",
       " ('Science', 0.06607599),\n",
       " ('Technology', 0.05182893),\n",
       " ('Marketing', 0.04498312),\n",
       " ('Education', 0.044352498),\n",
       " ('Manufacturing', 0.044316046),\n",
       " ('Communications-Media', 0.042034157),\n",
       " ('Engineering', 0.03842016),\n",
       " ('Transportation', 0.03779666),\n",
       " ('Non-Profit', 0.03767147)]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(topic_idx2class[i], p) for i, p in enumerate(predicted_topic)], key = lambda x: x[1], reverse = True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Presented approach is not the only one of course. There are numerous possibilities. Let's start from the ways we may improve the one I used.\n",
    "* Hyperparameter optimization\n",
    "* Try out another loss function\n",
    "* Perform additional preprocessing of texts\n",
    "* Increase the depth of neural network\n",
    "\n",
    "Alternative approaches:\n",
    "* Use another embeddings (TF-IDF, Glove, W2V)\n",
    "* Use other classifiers (Random Forest, XGBoost, LGBM)\n",
    "* Try to build regression for predicting age\n",
    "* Try out topic modelling technics for industry prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
